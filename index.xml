<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Hamel&#39;s Blog</title>
<link>https://hamel.dev/</link>
<atom:link href="https://hamel.dev/index.xml" rel="self" type="application/rss+xml"/>
<description>A collection of technical blogs and talks on machine learning and data science.</description>
<image>
<url>https://hamel.dev/quarto.png</url>
<title>Hamel&#39;s Blog</title>
<link>https://hamel.dev/</link>
<height>86</height>
<width>144</width>
</image>
<generator>quarto-1.5.57</generator>
<lastBuildDate>Mon, 24 Mar 2025 07:00:00 GMT</lastBuildDate>
<item>
  <title>A Field Guide to Rapidly Improving AI Products</title>
  <dc:creator>Hamel Husain</dc:creator>
  <link>https://hamel.dev/blog/posts/field-guide/</link>
  <description><![CDATA[ 




<p>Most AI teams focus on the wrong things. Here’s a common scene from my consulting work:</p>
<div class="screenplay" style="border: 2px solid #ccc; border-radius: 5px; padding: 20px; font-family: Courier, monospace;">
<div style="margin-bottom: 15px;">
<div style="text-transform: uppercase; font-weight: bold;">
AI TEAM
</div>
<blockquote class="blockquote">
<p>
Here’s our agent architecture – we’ve got RAG here, a router there, and we’re using this new framework for…
</p>
</blockquote>
</div>
<div style="margin-bottom: 15px;">
<div style="text-transform: uppercase; font-weight: bold;">
ME
</div>
<blockquote class="blockquote">
<div style="font-style: italic;">
<p>
[Holding up my hand to pause the enthusiastic tech lead.]
</p>
</div>
<p>
“Can you show me how you’re measuring if any of this actually works?”
</p>
</blockquote>
</div>
<div style="margin-bottom: 15px;">
<div style="font-style: italic;">
… Room goes quiet
</div>
</div>
</div>
<p><br></p>
<p>This scene has played out dozens of times over the last two years. Teams invest weeks building complex AI systems, but can’t tell me if their changes are helping or hurting.</p>
<p>This isn’t surprising. With new tools and frameworks emerging weekly, it’s natural to focus on tangible things we can control – which vector database to use, which LLM provider to choose, which agent framework to adopt. But after helping 30+ companies build AI products, I’ve discovered the teams who succeed barely talk about tools at all. Instead, they obsess over measurement and iteration.</p>
<p>In this post, I’ll show you exactly how these successful teams operate. You’ll learn:</p>
<ol type="1">
<li>Why focusing on tools over process is killing your AI projects</li>
<li>How error analysis consistently reveals the highest-ROI improvements</li>
<li>Why a simple data viewer is your most important AI investment</li>
<li>How to empower domain experts (not just engineers) to improve your AI</li>
<li>Why synthetic data is more effective than you think</li>
<li>How to maintain trust in your evaluation system</li>
<li>Why your AI roadmap should count experiments, not features</li>
</ol>
<p>I’ll explain each of these topics with real examples. While every situation is unique, you’ll see patterns that apply regardless of your domain or team size.</p>
<p>Let’s start by examining the most common mistake I see teams make – one that derails AI projects before they even begin.</p>
<section id="the-most-common-mistake-focus-on-tools-over-process" class="level2">
<h2 class="anchored" data-anchor-id="the-most-common-mistake-focus-on-tools-over-process">1. The Most Common Mistake: Focus on Tools Over Process</h2>
<p>The “tools first” mindset runs deep in AI development. It’s not just about architecture diagrams and frameworks – even when teams try to be data-driven, they often reach for tools instead of process. Let me show you what this looks like in practice.</p>
<p>One client proudly showed me this evaluation dashboard:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/field-guide/images/dashboard.png" class="img-fluid figure-img"></p>
<figcaption>The kind of dashboard that foreshadows failure. I’ve <a href="https://hamel.dev/blog/posts/llm-judge/" target="_blank">written about this before</a>.</figcaption>
</figure>
</div>
<p>This is what I call the “tools trap” – the belief that adopting the right tools or frameworks (in this case, generic metrics) will solve your AI problems. It’s particularly dangerous because it feels like progress. But without meaningful measurement, you’re flying blind.</p>
<p>Generic metrics are worse than useless – they actively impede progress in three ways:</p>
<p>First, they create a <strong>false sense of measurement and progress</strong>. Teams think they’re data-driven because they have dashboards, but they’re tracking vanity metrics that don’t correlate with real user problems. I’ve seen teams celebrate improving their “helpfulness score” by 10% while their actual users were still struggling with basic tasks. It’s like optimizing your website’s load time while your checkout process is broken – you’re getting better at the wrong thing.</p>
<p>Second, too many metrics fragment your attention. Instead of focusing on the few metrics that matter for your specific use case, you’re trying to optimize multiple dimensions simultaneously. When everything is important, nothing is.</p>
<p>What’s the alternative? Building your own metrics and methods of evaluation in a data-driven way.</p>
<p>Many people are skeptical when I suggest they need custom metrics. “Look at your data” sounds simple, but what does it actually mean in practice? Let me share a story from Jacob, the founder of <a href="https://nurtureboss.io/">Nurture Boss</a>, a company building AI assistants for the apartment industry.</p>
<p>Jacob built a simple viewer that let his development team examine conversations between their AI and users. Next to each conversation was a space where they could add notes, listing all the failure modes they observed in an open-ended way. By parallelizing this work across developers, Jacob’s team quickly annotated dozens of conversations.</p>
<p>As team members scanned through these notes, clear patterns emerged. Through this process of error analysis, they discovered their AI was struggling with date handling – a seemingly simple task that was failing 66% of the time. Users would say “let’s schedule a tour two weeks from now” and the AI would suggest random dates, sometimes even in past years.</p>
<p>Instead of immediately reaching for new tools, they looked at actual conversation logs, categorized the types of date-handling failures, built specific tests to catch these issues, and measured improvement on these metrics.</p>
<p>The result? They improved their date handling success rate from 33% to 95%. The solution didn’t require new tools – it required understanding the problem.</p>
<p>So what does focusing on this annotation process give you? - Metrics specific to your task that you can actually measure - Systematic ways of improving those metrics - A sense of progress throughout every step of the way</p>
<p>I recommend watching Jacob explain this process himself:</p>
<div class="quarto-video"><iframe data-external="1" src="https://www.youtube.com/embed/e2i6JbU2R-s" width="800" height="450" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Your job is no longer about wrangling tools to work in your stack; it’s about creating processes that work for you and your team. And the most powerful process – the one that consistently delivers the highest ROI – is structured error analysis.</p>
</section>
<section id="everyone-skips-error-analysis-and-its-the-highest-roi-activity" class="level2">
<h2 class="anchored" data-anchor-id="everyone-skips-error-analysis-and-its-the-highest-roi-activity">2. Everyone Skips Error Analysis (And It’s The Highest ROI Activity)</h2>
<p>Now let’s dive deeper into how to conduct effective error analysis. It sounds boring – it’s not as exciting as trying the latest LLM or implementing a new agent framework. <strong>But it’s the single most valuable activity in AI development, and I’ve never seen a team regret investing in it.</strong> Let me show you how this played out at NurtureBoss.</p>
<p>When thinking about potential error types, you can take one of two approaches: “top-down” or “bottom-up.”</p>
<p>With a top-down approach, you start with evaluation metrics common in the AI community like “hallucination” or “toxicity,” plus metrics unique to your task. At NurtureBoss, they might have wanted to measure customer frustration since their AI chatbot interacts directly with apartment seekers.</p>
<p>Top-down is ok, but I find it’s better to start with a bottom-up approach. A bottom-up approach forces you to look at actual data and let the metrics naturally emerge. Let me describe how Jacob’s team implemented their bottom-up approach at NurtureBoss.</p>
<p>We started with a simple spreadsheet where each row represented a conversation. In one column, team members wrote open-ended notes on anything good or bad the AI did in that conversation, with each row annotated independently. This process revealed latent evaluation criteria that wouldn’t have emerged in a top-down approach.</p>
<p>Next, we fed annotations into a LLM and asked it to build a taxonomy of common failure modes. A second LLM call then mapped each row to a specific failure mode label. Finally, we created a pivot table of failure modes and counts. The results were striking: just three issues accounted for over 60% of all problems:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/field-guide/images/pivot.png" class="img-fluid figure-img" width="200"></p>
<figcaption>Excel Pivot Tables are a simple tool, but they work!</figcaption>
</figure>
</div>
<ul>
<li>Conversation flow issues: The AI would miss context or respond awkwardly to user queries or go off topic.</li>
<li>Handoff failures: The AI wasn’t recognizing when to transfer conversations to human agents</li>
<li>Rescheduling problems: The AI struggled with date handling and appointment modifications</li>
</ul>
<p>The impact was immediate. Jacob paused our evaluation work – not because it wasn’t valuable, but because they had uncovered so many actionable insights that his team needed several weeks just to implement fixes for the problems we’d already found. This simple exercise had revealed more concrete opportunities for improvement than they had discovered in all their previous attempts at measurement.</p>
<p>The key is combining systematic analysis with domain expertise. Technical teams often miss crucial business context, while business teams may lack the tools to analyze patterns systematically. The magic happens when you bring these perspectives together.</p>
<p>Let me share a concrete story about how top-down metrics in isolation can lead you astray, even when they feel perfectly customized to your use case.</p>
<p>A recruiting platform I consulted with was using AI to generate initial outreach emails to candidates. They tracked success using edit distance – measuring how much recruiters modified the AI’s output. This seemed like an ideal custom metric for their specific needs: less editing should mean better AI performance.</p>
<p>But when we conducted error analysis on specific examples with the goal of reducing edit distance, we discovered something startling: many recruiters on this platform were non-native speakers who were introducing grammatical errors and awkward phrasing into AI-generated text. When we showed both versions to hiring managers (the ultimate judges of quality), they consistently rated the less-edited AI versions as significantly better (which surprised me too). No dashboard or pre-defined metric would have caught this fundamental misalignment.</p>
<p>If you’d like to see error analysis in action, we recorded a <a href="https://youtu.be/qH1dZ8JLLdU">live walkthrough here</a>.</p>
<p>This brings us to a crucial question: How do you make it easy for teams to look at their data? The answer leads us to what I consider the most important investment any AI team can make…</p>
</section>
<section id="the-most-important-ai-investment-a-simple-data-viewer" class="level2">
<h2 class="anchored" data-anchor-id="the-most-important-ai-investment-a-simple-data-viewer">3. The Most Important AI Investment: A Simple Data Viewer</h2>
<p>The single most impactful investment I’ve seen AI teams make isn’t a fancy evaluation dashboard – it’s building a customized interface that lets anyone examine what their AI is actually doing. I emphasize <em>customized</em> because every domain has unique needs that off-the-shelf tools rarely address. When reviewing apartment leasing conversations, you need to see the full chat history and scheduling context. For real estate queries, you need the property details and source documents right there. Even small UX decisions – like where to place metadata or which filters to expose – can make the difference between a tool people actually use and one they avoid.</p>
<p>I’ve watched teams struggle with generic labeling interfaces, hunting through multiple systems just to understand a single interaction. The friction adds up: clicking through to different systems to see context, copying error descriptions into separate tracking sheets, switching between tools to verify information. This friction doesn’t just slow teams down – it actively discourages the kind of systematic analysis that catches subtle issues.</p>
<p>Teams with thoughtfully designed data viewers iterate 10x faster than those without them. And here’s the thing: <strong>these tools can be built in hours using AI-assisted development</strong> (like Cursor or Loveable). The investment is minimal compared to the returns.</p>
<p>Let me show you what I mean. Here’s the data viewer built for NurtureBoss (which we discussed earlier):</p>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/field-guide/images/nboss_filter.png" class="img-fluid figure-img"></p>
<figcaption>Search and filter sessions</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/field-guide/images/nboss_annotate.png" class="img-fluid figure-img"></p>
<figcaption>Annotate and add notes</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/field-guide/images/nboss_analysis.png" class="img-fluid figure-img"></p>
<figcaption>Aggregate and count errors</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>Here’s what makes a good data annotation tool:</p>
<ol type="1">
<li>Show all context in one place. Don’t make users hunt through different systems to understand what happened.<br>
</li>
<li>Make feedback trivial to capture. One-click correct/incorrect buttons beat lengthy forms.</li>
<li>Capture open-ended feedback. This lets you capture nuanced issues that don’t fit into a pre-defined taxonomy.</li>
<li>Enable quick filtering and sorting. Teams need to easily dive into specific error types. In the example above, NurtureBoss can quickly filter by the channel (voice, text, chat) or the specific property they want to look at quickly.</li>
<li>Have hotkeys that allow users to navigate between data examples and annotate without clicking.</li>
</ol>
<p>It doesn’t matter what web frameworks you use - use whatever you are familiar with. Because I’m a python developer, my current favorite web framework is <a href="https://fastht.ml/docs/">FastHTML</a> coupled with <a href="https://www.answer.ai/posts/2025-01-15-monsterui.html">MonsterUI</a>, because it allows me to define the back-end and front-end code in one small python file.</p>
<p>The key is starting somewhere, even if it’s simple. I’ve found custom web apps provide the best experience, but if you’re just beginning, a spreadsheet is better than nothing. As your needs grow, you can evolve your tools accordingly.</p>
<p>This brings us to another counter-intuitive lesson: the people best positioned to improve your AI system are often the ones who know the least about AI.</p>
</section>
<section id="empower-domain-experts-to-write-prompts" class="level2">
<h2 class="anchored" data-anchor-id="empower-domain-experts-to-write-prompts">4. Empower Domain Experts To Write Prompts</h2>
<p>I recently worked with an education startup building an interactive learning platform with LLMs. Their product manager, a learning design expert, would create detailed PowerPoint decks explaining pedagogical principles and example dialogues. She’d present these to the engineering team, who would then translate her expertise into prompts.</p>
<p>But here’s the thing: prompts are just English. Having a learning expert communicate teaching principles through PowerPoint, only for engineers to translate that back into English prompts, created unnecessary friction. The most successful teams flip this model by giving domain experts tools to write and iterate on prompts directly.</p>
<section id="build-bridges-not-gatekeepers" class="level3">
<h3 class="anchored" data-anchor-id="build-bridges-not-gatekeepers">Build Bridges, Not Gatekeepers</h3>
<p>Prompt playgrounds are a great starting point for this. Tools like Arize, Langsmith and Braintrust let teams quickly test different prompts, feed in example datasets, and compare results. Here are some screenshots of these tools:</p>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="3">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/field-guide/images/pp_phoenix2.png" class="img-fluid figure-img"></p>
<figcaption>Arize Phoenix</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/field-guide/images/pp_langsmith.png" class="img-fluid figure-img"></p>
<figcaption>LangSmith</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/field-guide/images/pp_bt.png" class="img-fluid figure-img"></p>
<figcaption>Braintrust</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>But there’s a crucial next step that many teams miss: integrating prompt development into their application context. Most AI applications aren’t just prompts – They commonly involve RAG systems pulling from your knowledge base, agent orchestration coordinating multiple steps, and application-specific business logic. The most effective teams I’ve worked with go beyond standalone playgrounds. They build what I call <em><strong>integrated prompt environments</strong></em> – essentially admin versions of their actual user interface that expose prompt editing.</p>
<p>Here’s an illustration of what an integrated prompt environment might look like for a real estate AI assistant:</p>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/field-guide/images/ipe_before.png" class="img-fluid figure-img" width="700"></p>
<figcaption>The UI that users (real estate agents) see.</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/field-guide/images/ipe_after.png" class="img-fluid figure-img"></p>
<figcaption>The same UI, but with an “admin mode”used by the engineering &amp; product team to iterate on the prompt and debug issues.</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="tips-for-communicating-with-domain-experts" class="level3">
<h3 class="anchored" data-anchor-id="tips-for-communicating-with-domain-experts">Tips For Communicating With Domain Experts</h3>
<p>There’s another barrier that often prevents domain experts from contributing effectively: unnecessary jargon. I was working with an education startup where engineers, product managers, and learning specialists were talking past each other in meetings. The engineers kept saying, “We’re going to build an agent that does XYZ,” when really the job to be done was writing a prompt. This created an artificial barrier – the learning specialists, who were the actual domain experts, felt like they couldn’t contribute because they didn’t understand “agents.”</p>
<p>This happens everywhere. I’ve seen it with lawyers at legal tech companies, psychologists at mental health startups, and doctors at healthcare firms. The magic of LLMs is that they make AI accessible through natural language, but we often destroy that advantage by wrapping everything in technical terminology.</p>
<p>Here’s a simple example of how to translate common AI jargon:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 73%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th>Instead of saying…</th>
<th>Say…</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>“We’re implementing a RAG approach”</td>
<td>“We’re making sure the model has the right context to answer questions”</td>
</tr>
<tr class="even">
<td>“We need to prevent prompt injection”</td>
<td>“We need to make sure users can’t trick the AI into ignoring our rules”</td>
</tr>
<tr class="odd">
<td>“Our model suffers from hallucination issues”</td>
<td>“Sometimes the AI makes things up, so we need to check its answers”</td>
</tr>
</tbody>
</table>
<p>This doesn’t mean dumbing things down – it means being precise about what you’re actually doing. When you say “we’re building an agent,” what specific capability are you adding? Is it function calling? Tool use? Or just a better prompt? Being specific helps everyone understand what’s actually happening.</p>
<p>There’s nuance here. Technical terminology exists for a reason – it provides precision when talking with other technical stakeholders. The key is adapting your language to your audience.</p>
<p>The challenge many teams raise at this point is: “This all sounds great, but what if we don’t have any data yet? How can we look at examples or iterate on prompts when we’re just starting out?” That’s what we’ll talk about next.</p>
</section>
</section>
<section id="bootstrapping-your-ai-with-synthetic-data-is-effective-even-with-zero-users" class="level2">
<h2 class="anchored" data-anchor-id="bootstrapping-your-ai-with-synthetic-data-is-effective-even-with-zero-users">5. Bootstrapping Your AI With Synthetic Data Is Effective (Even With Zero Users)</h2>
<p>One of the most common roadblocks I hear from teams is: “We can’t do proper evaluation because we don’t have enough real user data yet.” This creates a chicken-and-egg problem – you need data to improve your AI, but you need a decent AI to get users who generate that data.</p>
<p>Fortunately, there’s a solution that works surprisingly well: synthetic data. LLMs can generate realistic test cases that cover the range of scenarios your AI will encounter.</p>
<p>As I wrote in my <a href="https://hamel.dev/blog/posts/llm-judge/#generating-data">LLM-as-a-Judge blog post</a>, synthetic data can be remarkably effective for evaluation. <a href="https://www.linkedin.com/in/bryan-bischof/">Bryan Bischof</a>, the former Head of AI at Hex, put it perfectly:</p>
<blockquote class="blockquote">
<p>“LLMs are surprisingly good at generating excellent - and diverse - examples of user prompts. This can be relevant for powering application features, and sneakily, for building Evals. If this sounds a bit like the Large Language Snake is eating its tail, I was just as surprised as you! All I can say is: it works, ship it.”</p>
</blockquote>
<section id="a-framework-for-generating-realistic-test-data" class="level3">
<h3 class="anchored" data-anchor-id="a-framework-for-generating-realistic-test-data">A Framework for Generating Realistic Test Data</h3>
<p>The key to effective synthetic data is choosing the right dimensions to test. While these dimensions will vary based on your specific needs, I find it helpful to think about three broad categories:</p>
<ol type="1">
<li><strong>Features</strong>: What capabilities does your AI need to support?</li>
<li><strong>Scenarios</strong>: What situations will it encounter?</li>
<li><strong>User Personas</strong>: Who will be using it and how?</li>
</ol>
<p>These aren’t the only dimensions you might care about – you might also want to test different tones of voice, levels of technical sophistication, or even different locales and languages. The important thing is identifying dimensions that matter for your specific use case.</p>
<p>For a real estate CRM AI assistant I worked on with <a href="https://www.rechat.com/">Rechat</a>, we defined these dimensions like this:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb1-2">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"property search"</span>,      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Finding listings matching criteria</span></span>
<span id="cb1-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"market analysis"</span>,      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Analyzing trends and pricing</span></span>
<span id="cb1-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"scheduling"</span>,          <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Setting up property viewings</span></span>
<span id="cb1-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"follow-up"</span>           <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Post-viewing communication</span></span>
<span id="cb1-6">]</span>
<span id="cb1-7"></span>
<span id="cb1-8">scenarios <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb1-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"exact match"</span>,         <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># One perfect listing match</span></span>
<span id="cb1-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"multiple matches"</span>,    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Need to help user narrow down</span></span>
<span id="cb1-11">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"no matches"</span>,         <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Need to suggest alternatives</span></span>
<span id="cb1-12">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"invalid criteria"</span>     <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Help user correct search terms</span></span>
<span id="cb1-13">]</span>
<span id="cb1-14"></span>
<span id="cb1-15">personas <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb1-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"first_time_buyer"</span>,    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Needs more guidance and explanation</span></span>
<span id="cb1-17">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"investor"</span>,           <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Focused on numbers and ROI</span></span>
<span id="cb1-18">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"luxury_client"</span>,      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Expects white-glove service</span></span>
<span id="cb1-19">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"relocating_family"</span>   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Has specific neighborhood/school needs</span></span>
<span id="cb1-20">]</span></code></pre></div>
<p>But having these dimensions defined is only half the battle. The real challenge is ensuring your synthetic data actually triggers the scenarios you want to test. This requires two things:</p>
<ol type="1">
<li>A test database with enough variety to support your scenarios</li>
<li>A way to verify that generated queries actually trigger intended scenarios</li>
</ol>
<p>For Rechat, we maintained a test database of listings that we knew would trigger different edge cases. Some teams prefer to use an anonymized copy of production data, but either way, you need to ensure your test data has enough variety to exercise the scenarios you care about.</p>
<p>Here’s an example of how we might use these dimensions with real data to generate test cases for the property search feature (this is just pseudo-code, and very illustrative):</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> generate_search_query(scenario, persona, listing_db):</span>
<span id="cb2-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Generate a realistic user query about listings"""</span></span>
<span id="cb2-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pull real listing data to ground the generation</span></span>
<span id="cb2-4">    sample_listings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> listing_db.get_sample_listings(</span>
<span id="cb2-5">        price_range<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>persona.price_range,</span>
<span id="cb2-6">        location<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>persona.preferred_areas</span>
<span id="cb2-7">    )</span>
<span id="cb2-8">    </span>
<span id="cb2-9">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Verify we have listings that will trigger our scenario</span></span>
<span id="cb2-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> scenario <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"multiple_matches"</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(sample_listings) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>:</span>
<span id="cb2-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">ValueError</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Need multiple listings for this scenario"</span>)</span>
<span id="cb2-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> scenario <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"no_matches"</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(sample_listings) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb2-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">ValueError</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Found matches when testing no-match scenario"</span>)</span>
<span id="cb2-14">    </span>
<span id="cb2-15">    prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"""</span></span>
<span id="cb2-16"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    You are an expert real estate agent who is searching for listings. You are given a customer type and a scenario.</span></span>
<span id="cb2-17"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb2-18"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Your job is to generate a natural language query you would use to search these listings.</span></span>
<span id="cb2-19"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb2-20"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Context:</span></span>
<span id="cb2-21"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    - Customer type: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>persona<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>description<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb2-22"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    - Scenario: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>scenario<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb2-23"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb2-24"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Use these actual listings as reference:</span></span>
<span id="cb2-25"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>format_listings(sample_listings)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb2-26"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb2-27"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    The query should reflect the customer type and the scenario.</span></span>
<span id="cb2-28"></span>
<span id="cb2-29"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    Example query: Find homes in the 75019 zip code, 3 bedrooms, 2 bathrooms, price range $750k - $1M for an investor.</span></span>
<span id="cb2-30"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb2-31">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> generate_with_llm(prompt)</span></code></pre></div>
<p>This produced realistic queries like:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 22%">
<col style="width: 20%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Scenario</th>
<th>Persona</th>
<th>Generated Query</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>property search</td>
<td>multiple matches</td>
<td>first_time_buyer</td>
<td>“Looking for 3-bedroom homes under $500k in the Riverside area. Would love something close to parks since we have young kids.”</td>
</tr>
<tr class="even">
<td>market analysis</td>
<td>no matches</td>
<td>investor</td>
<td>“Need comps for 123 Oak St.&nbsp;Specifically interested in rental yield comparison with similar properties in a 2-mile radius.”</td>
</tr>
</tbody>
</table>
<p>The key to useful synthetic data is grounding it in real system constraints. For the real-estate AI assistant, this means:</p>
<ol type="1">
<li>Using real listing IDs and addresses from their database</li>
<li>Incorporating actual agent schedules and availability windows</li>
<li>Respecting business rules like showing restrictions and notice periods</li>
<li>Including market-specific details like HOA requirements or local regulations</li>
</ol>
<p>We then feed these test cases through Lucy and log the interactions. This gives us a rich dataset to analyze, showing exactly how the AI handles different situations with real system constraints. This approach helped us fix issues before they affected real users.</p>
<p>Sometimes you don’t have access to a production database, especially for new products. In these cases, use LLMs to generate both test queries and the underlying test data. For a real estate AI assistant, this might mean creating synthetic property listings with realistic attributes – prices that match market ranges, valid addresses with real street names, and amenities appropriate for each property type. The key is grounding synthetic data in real-world constraints to make it useful for testing. The specifics of generating robust synthetic databases are beyond the scope of this post.</p>
</section>
<section id="guidelines-for-using-synthetic-data" class="level3">
<h3 class="anchored" data-anchor-id="guidelines-for-using-synthetic-data">Guidelines for Using Synthetic Data</h3>
<p>When generating synthetic data, follow these key principles to ensure it’s effective:</p>
<ol type="1">
<li><p><strong>Diversify your dataset</strong>: Create examples that cover a wide range of features, scenarios, and personas. As I wrote in my <a href="https://hamel.dev/blog/posts/llm-judge/">LLM-as-a-Judge post</a>, this diversity helps you identify edge cases and failure modes you might not anticipate otherwise.</p></li>
<li><p><strong>Generate user inputs, not outputs</strong>: Use LLMs to generate realistic user queries or inputs, not the expected AI responses. This prevents your synthetic data from inheriting the biases or limitations of the generating model.</p></li>
<li><p><strong>Incorporate real system constraints</strong>: Ground your synthetic data in actual system limitations and data. For example, when testing a scheduling feature, use real availability windows and booking rules.</p></li>
<li><p><strong>Verify scenario coverage</strong>: Ensure your generated data actually triggers the scenarios you want to test. A query intended to test “no matches found” should actually return zero results when run against your system.</p></li>
<li><p><strong>Start simple, then add complexity</strong>: Begin with straightforward test cases before adding nuance. This helps isolate issues and establish a baseline before tackling edge cases.</p></li>
</ol>
<p>This approach isn’t just theoretical – it’s been proven in production across dozens of companies. What often starts as a stopgap measure becomes a permanent part of the evaluation infrastructure, even after real user data becomes available.</p>
<p>Let’s look at how to maintain trust in your evaluation system as you scale…</p>
</section>
</section>
<section id="maintaining-trust-in-evals-is-critical" class="level2">
<h2 class="anchored" data-anchor-id="maintaining-trust-in-evals-is-critical">6. Maintaining Trust In Evals Is Critical</h2>
<p>This is a pattern I’ve seen repeatedly: teams build evaluation systems, then gradually lose faith in them. Sometimes it’s because the metrics don’t align with what they observe in production. Other times, it’s because the evaluations become too complex to interpret. Either way, the result is the same – the team reverts to making decisions based on gut feeling and anecdotal feedback, undermining the entire purpose of having evaluations.</p>
<p>Maintaining trust in your evaluation system is just as important as building it in the first place. Here’s how the most successful teams approach this challenge:</p>
<section id="understanding-criteria-drift" class="level3">
<h3 class="anchored" data-anchor-id="understanding-criteria-drift">Understanding Criteria Drift</h3>
<p>One of the most insidious problems in AI evaluation is “criteria drift” – a phenomenon where evaluation criteria evolve as you observe more model outputs. In their paper <a href="https://arxiv.org/abs/2404.12272">“Who Validates the Validators?”</a>, Shankar et al.&nbsp;describe this phenomenon:</p>
<blockquote class="blockquote">
<p>“To grade outputs, people need to externalize and define their evaluation criteria; however, the process of grading outputs helps them to define that very criteria.”</p>
</blockquote>
<p>This creates a paradox: you can’t fully define your evaluation criteria until you’ve seen a wide range of outputs, but you need criteria to evaluate those outputs in the first place. In other words, <strong>it is impossible to completely determine evaluation criteria prior to human judging of LLM outputs</strong>.</p>
<p>I’ve observed this firsthand when working with Phillip Carter at Honeycomb on their <a href="https://www.honeycomb.io/blog/introducing-query-assistant">Query Assistant</a> feature. As we evaluated the AI’s ability to generate database queries, Phillip noticed something interesting:</p>
<blockquote class="blockquote">
<p>“Seeing how the LLM breaks down its reasoning made me realize I wasn’t being consistent about how I judged certain edge cases.”</p>
</blockquote>
<p>The process of reviewing AI outputs helped him articulate his own evaluation standards more clearly. This isn’t a sign of poor planning – it’s an inherent characteristic of working with AI systems that produce diverse and sometimes unexpected outputs.</p>
<p>The teams that maintain trust in their evaluation systems embrace this reality rather than fighting it. They treat evaluation criteria as living documents that evolve alongside their understanding of the problem space. They also recognize that different stakeholders might have different (sometimes contradictory) criteria, and they work to reconcile these perspectives rather than imposing a single standard.</p>
</section>
<section id="creating-trustworthy-evaluation-systems" class="level3">
<h3 class="anchored" data-anchor-id="creating-trustworthy-evaluation-systems">Creating Trustworthy Evaluation Systems</h3>
<p>So how do you build evaluation systems that remain trustworthy despite criteria drift? Here are the approaches I’ve found most effective:</p>
<section id="favor-binary-decisions-over-arbitrary-scales" class="level4">
<h4 class="anchored" data-anchor-id="favor-binary-decisions-over-arbitrary-scales">1. Favor Binary Decisions Over Arbitrary Scales</h4>
<p>As I wrote in my <a href="https://hamel.dev/blog/posts/llm-judge/#why-are-simple-passfail-metrics-important">LLM-as-a-Judge post</a>, binary decisions provide clarity that more complex scales often obscure. When faced with a 1-5 scale, evaluators frequently struggle with the difference between a 3 and a 4, introducing inconsistency and subjectivity. What exactly distinguishes “somewhat helpful” from “helpful”? These boundary cases consume disproportionate mental energy and create noise in your evaluation data. And even when businesses use a 1-5 scale, they inevitably ask where to draw the line for “good enough” or to trigger intervention, forcing a binary decision anyway.</p>
<p>In contrast, a binary pass/fail forces evaluators to make a clear judgment: did this output achieve its purpose or not? This clarity extends to measuring progress – a 10% increase in passing outputs is immediately meaningful, while a 0.5-point improvement on a 5-point scale requires interpretation.</p>
<p>I’ve found that teams who resist binary evaluation often do so because they want to capture nuance. But nuance isn’t lost – it’s just moved to the qualitative critique that accompanies the judgment. The critique provides rich context about why something passed or failed, and what specific aspects could be improved, while the binary decision creates actionable clarity about whether improvement is needed at all.</p>
</section>
<section id="enhance-binary-judgments-with-detailed-critiques" class="level4">
<h4 class="anchored" data-anchor-id="enhance-binary-judgments-with-detailed-critiques">2. Enhance Binary Judgments With Detailed Critiques</h4>
<p>While binary decisions provide clarity, they work best when paired with detailed critiques that capture the nuance of why something passed or failed. This combination gives you the best of both worlds: clear, actionable metrics and rich contextual understanding.</p>
<p>For example, when evaluating a response that correctly answers a user’s question but contains unnecessary information, a good critique might read:</p>
<blockquote class="blockquote">
<p>“The AI successfully provided the market analysis requested (PASS), but included excessive detail about neighborhood demographics that wasn’t relevant to the investment question. This makes the response longer than necessary and potentially distracting.”</p>
</blockquote>
<p>These critiques serve multiple functions beyond just explanation. They force domain experts to externalize implicit knowledge – I’ve seen legal experts move from vague feelings that something “doesn’t sound right” to articulating specific issues with citation formats or reasoning patterns that can be systematically addressed.</p>
<p>When included as few-shot examples in judge prompts, these critiques improve the LLM’s ability to reason about complex edge cases. I’ve found this approach often yields 15-20% higher agreement rates between human and LLM evaluations compared to prompts without example critiques. The critiques also provide excellent raw material for generating high-quality synthetic data, creating a flywheel for improvement.</p>
</section>
<section id="measure-alignment-between-automated-evals-and-human-judgment" class="level4">
<h4 class="anchored" data-anchor-id="measure-alignment-between-automated-evals-and-human-judgment">3. Measure Alignment Between Automated Evals and Human Judgment</h4>
<p>If you’re using LLMs to evaluate outputs (which is often necessary at scale), it’s crucial to regularly check how well these automated evaluations align with human judgment.</p>
<p>This is particularly important given our natural tendency to over-trust AI systems. As Shankar et al.&nbsp;note in <a href="https://arxiv.org/abs/2404.12272">“Who Validates the Validators?”</a>, the lack of tools to validate evaluator quality is concerning</p>
<blockquote class="blockquote">
<p>Research shows people tend to over-rely and over-trust AI systems. For instance, in one high profile incident, researchers from MIT posted a pre-print on arXiv claiming that GPT-4 could ace the MIT EECS exam. Within hours, [the] work [was] debunked … citing problems arising from over-reliance on GPT-4 to grade itself.”</p>
</blockquote>
<p>This over-trust problem extends beyond self-evaluation. Research has shown that LLMs can be biased by simple factors like the ordering of options in a set, or even seemingly innocuous formatting changes in prompts. Without rigorous human validation, these biases can silently undermine your evaluation system.</p>
<p>When working with Honeycomb, we tracked agreement rates between our LLM-as-a-judge and Phillip’s evaluations:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/field-guide/images/score.png" class="img-fluid figure-img"></p>
<figcaption>Agreement rates between LLM evaluator and human expert. More details <a href="https://hamel.dev/blog/posts/evals/#automated-evaluation-w-llms">here</a>.</figcaption>
</figure>
</div>
<p>It took three iterations to achieve &gt;90% agreement, but this investment paid off in a system the team could trust. Without this validation step, automated evaluations often drift from human expectations over time, especially as the distribution of inputs changes. You can <a href="https://hamel.dev/blog/posts/evals/#automated-evaluation-w-llms">read more about this here</a>.</p>
<p>Tools like <a href="https://eugeneyan.com/writing/aligneval/">Eugene Yan’s AlignEval</a> demonstrate this alignment process beautifully. It provides a simple interface where you upload data, label examples with a binary “good” or “bad,” and then evaluate LLM-based judges against those human judgments. What makes it effective is how it streamlines the workflow – you can quickly see where automated evaluations diverge from your preferences, refine your criteria based on these insights, and measure improvement over time. This approach reinforces that alignment isn’t a one-time setup but an ongoing conversation between human judgment and automated evaluation.</p>
</section>
</section>
<section id="scaling-without-losing-trust" class="level3">
<h3 class="anchored" data-anchor-id="scaling-without-losing-trust">Scaling Without Losing Trust</h3>
<p>As your AI system grows, you’ll inevitably face pressure to reduce the human effort involved in evaluation. This is where many teams go wrong – they automate too much, too quickly, and lose the human connection that keeps their evaluations grounded.</p>
<p>The most successful teams take a more measured approach:</p>
<ol type="1">
<li><p><strong>Start with high human involvement</strong>: In the early stages, have domain experts evaluate a significant percentage of outputs.</p></li>
<li><p><strong>Study alignment patterns</strong>: Rather than automating evaluation, focus on understanding where automated evaluations align with human judgment and where they diverge. This helps you identify which types of cases need more careful human attention.</p></li>
<li><p><strong>Use strategic sampling</strong>: Rather than evaluating every output, use statistical techniques to sample outputs that provide the most information, particularly focusing on areas where alignment is weakest.</p></li>
<li><p><strong>Maintain regular calibration</strong>: Even as you scale, continue to compare automated evaluations against human judgment regularly, using these comparisons to refine your understanding of when to trust automated evaluations.</p></li>
</ol>
<p>Scaling evaluation isn’t just about reducing human effort – it’s about directing that effort where it adds the most value. By focusing human attention on the most challenging or informative cases, you can maintain quality even as your system grows.</p>
<p>Now that we’ve covered how to maintain trust in your evaluations, let’s talk about a fundamental shift in how you should approach AI development roadmaps…</p>
</section>
</section>
<section id="your-ai-roadmap-should-count-experiments-not-features" class="level2">
<h2 class="anchored" data-anchor-id="your-ai-roadmap-should-count-experiments-not-features">7. Your AI Roadmap Should Count Experiments, Not Features</h2>
<p>If you’ve worked in software development, you’re familiar with traditional roadmaps: a list of features with target delivery dates. Teams commit to shipping specific functionality by specific deadlines, and success is measured by how closely they hit those targets.</p>
<p>This approach fails spectacularly with AI.</p>
<p>I’ve watched teams commit to roadmaps like “Launch sentiment analysis by Q2” or “Deploy agent-based customer support by end of year,” only to discover that the technology simply isn’t ready to meet their quality bar. They either ship something subpar to hit the deadline or miss the deadline entirely. Either way, trust erodes.</p>
<p>The fundamental problem is that traditional roadmaps assume we know what’s possible. With conventional software, that’s often true – given enough time and resources, you can build most features reliably. With AI, especially at the cutting edge, you’re constantly testing the boundaries of what’s feasible.</p>
<section id="experiments-vs.-features" class="level3">
<h3 class="anchored" data-anchor-id="experiments-vs.-features">Experiments vs.&nbsp;Features</h3>
<p><a href="https://www.linkedin.com/in/bryan-bischof/">Bryan Bischof</a>, Former Head of AI at Hex, introduced me to what he calls a “capability funnel” approach to AI roadmaps. This strategy reframes how we think about AI development progress.</p>
<p>Instead of defining success as shipping a feature, the capability funnel breaks down AI performance into progressive levels of utility. At the top of the funnel is the most basic functionality – can the system respond at all? At the bottom is fully solving the user’s job to be done. Between these points are various stages of increasing usefulness.</p>
<p>For example, in a query assistant, the capability funnel might look like: 1. Can generate syntactically valid queries (basic functionality) 2. Can generate queries that execute without errors 3. Can generate queries that return relevant results 4. Can generate queries that match user intent 5. Can generate optimal queries that solve the user’s problem (complete solution)</p>
<p>This approach acknowledges that AI progress isn’t binary – it’s about gradually improving capabilities across multiple dimensions. It also provides a framework for measuring progress even when you haven’t reached the final goal.</p>
<p>The most successful teams I’ve worked with structure their roadmaps around experiments rather than features. Instead of committing to specific outcomes, they commit to a cadence of experimentation, learning, and iteration.</p>
<p><a href="https://eugeneyan.com/">Eugene Yan</a>, an applied scientist at Amazon, shared how he approaches ML project planning with leadership - a process that, while originally developed for traditional machine learning, applies equally well to modern LLM development:</p>
<blockquote class="blockquote">
<p>“Here’s a common timeline. First, I take two weeks to do a data feasibility analysis, i.e”do I have the right data?” […] Then I take an additional month to do a technical feasibility analysis, i.e “can AI solve this?” After that, if it still works I’ll spend six weeks building a prototype we can A/B test.”</p>
</blockquote>
<p>While LLMs might not require the same kind of feature engineering or model training as traditional ML, the underlying principle remains the same: time-box your exploration, establish clear decision points, and focus on proving feasibility before committing to full implementation. This approach gives leadership confidence that resources won’t be wasted on open-ended exploration, while giving the team the freedom to learn and adapt as they go.</p>
</section>
<section id="the-foundation-evaluation-infrastructure" class="level3">
<h3 class="anchored" data-anchor-id="the-foundation-evaluation-infrastructure">The Foundation: Evaluation Infrastructure</h3>
<p>The key to making an experiment-based roadmap work is having robust evaluation infrastructure. Without it, you’re just guessing whether your experiments are working. With it, you can rapidly iterate, test hypotheses, and build on successes.</p>
<p>I saw this firsthand during the early development of GitHub Copilot. What most people don’t realize is that the team invested heavily in building sophisticated offline evaluation infrastructure. They created systems that could test code completions against a very large corpus of repositories on GitHub, leveraging unit tests that already existed in high-quality codebases as an automated way to verify completion correctness. This was a massive engineering undertaking – they had to build systems that could clone repositories at scale, set up their environments, run their test suites, and analyze the results, all while handling the incredible diversity of programming languages, frameworks, and testing approaches.</p>
<p>This wasn’t wasted time—it was the foundation that accelerated everything. With solid evaluation in place, the team ran thousands of experiments, quickly identified what worked, and could say with confidence “this change improved quality by X%” instead of relying on gut feelings. While the upfront investment in evaluation feels slow, it prevents endless debates about whether changes help or hurt, and dramatically speeds up innovation later.</p>
</section>
<section id="communicating-this-to-stakeholders" class="level3">
<h3 class="anchored" data-anchor-id="communicating-this-to-stakeholders">Communicating This to Stakeholders</h3>
<p>The challenge, of course, is that executives often want certainty. They want to know when features will ship and what they’ll do. How do you bridge this gap?</p>
<p>The key is to shift the conversation from outputs to outcomes. Instead of promising specific features by specific dates, commit to a process that will maximize the chances of achieving the desired business outcomes.</p>
<p>Eugene shared how he handles these conversations:</p>
<blockquote class="blockquote">
<p>“I try to reassure leadership with timeboxes. At the end of three months, if it works out, then we move it to production. At any step of the way, if it doesn’t work out, we pivot.”</p>
</blockquote>
<p>This approach gives stakeholders clear decision points while acknowledging the inherent uncertainty in AI development. It also helps manage expectations about timelines – instead of promising a feature in six months, you’re promising a clear understanding of whether that feature is feasible in three months.</p>
<p>Bryan’s capability funnel approach provides another powerful communication tool. It allows teams to show concrete progress through the funnel stages, even when the final solution isn’t ready. It also helps executives understand where problems are occurring and make informed decisions about where to invest resources.</p>
</section>
<section id="build-a-culture-of-experimentation-through-failure-sharing" class="level3">
<h3 class="anchored" data-anchor-id="build-a-culture-of-experimentation-through-failure-sharing">Build a Culture of Experimentation Through Failure Sharing</h3>
<p>Perhaps the most counterintuitive aspect of this approach is the emphasis on learning from failures. In traditional software development, failures are often hidden or downplayed. In AI development, they’re the primary source of learning.</p>
<p>Eugene operationalizes this at his organization through what he calls a “fifteen-five” – a weekly update that takes fifteen minutes to write and five minutes to read:</p>
<blockquote class="blockquote">
<p>“In my fifteen-fives, I document my failures and my successes. Within our team, we also have weekly”no-prep sharing sessions” where we discuss what we’ve been working on and what we’ve learned. When I do this, I go out of my way to share failures.”</p>
</blockquote>
<p>This practice normalizes failure as part of the learning process. It shows that even experienced practitioners encounter dead ends, and it accelerates team learning by sharing those experiences openly. And by celebrating the process of experimentation rather than just the outcomes, teams create an environment where people feel safe taking risks and learning from failures.</p>
</section>
<section id="a-better-way-forward" class="level3">
<h3 class="anchored" data-anchor-id="a-better-way-forward">A Better Way Forward</h3>
<p>So what does an experiment-based roadmap look like in practice? Here’s a simplified example from a content moderation project Eugene worked on:</p>
<blockquote class="blockquote">
<p>“I was asked to do content moderation. I said, ‘It’s uncertain whether we’ll meet that goal. It’s uncertain even if that goal is feasible with our data, or what machine learning techniques would work. But here’s my experimentation roadmap. Here are the techniques I’m gonna try, and I’m gonna update you at a two-week cadence.’”</p>
</blockquote>
<p>The roadmap didn’t promise specific features or capabilities. Instead, it committed to a systematic exploration of possible approaches, with regular check-ins to assess progress and pivot if necessary.</p>
<p>The results were telling:</p>
<blockquote class="blockquote">
<p>“For the first two to three months, nothing worked. […] And then [a breakthrough] came out. […] Within a month, that problem was solved. So you can see that in the first quarter or even four months, it was going nowhere. […] But then you can also see that all of a sudden, some new technology comes along, some new paradigm, some new reframing comes along that just [solves] 80% of [the problem].”</p>
</blockquote>
<p>This pattern – long periods of apparent failure followed by breakthroughs – is common in AI development. Traditional feature-based roadmaps would have killed the project after months of “failure,” missing the eventual breakthrough.</p>
<p>By focusing on experiments rather than features, teams create space for these breakthroughs to emerge. They also build the infrastructure and processes that make breakthroughs more likely – data pipelines, evaluation frameworks, and rapid iteration cycles.</p>
<p>The most successful teams I’ve worked with start by building evaluation infrastructure before committing to specific features. They create tools that make iteration faster and focus on processes that support rapid experimentation. This approach might seem slower at first, but it dramatically accelerates development in the long run by enabling teams to learn and adapt quickly.</p>
<p>The key metric for AI roadmaps isn’t features shipped – it’s experiments run. The teams that win are those that can run more experiments, learn faster, and iterate more quickly than their competitors. And the foundation for this rapid experimentation is always the same: robust, trusted evaluation infrastructure that gives everyone confidence in the results.</p>
<p>By reframing your roadmap around experiments rather than features, you create the conditions for similar breakthroughs in your own organization.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Throughout this post, I’ve shared patterns I’ve observed across dozens of AI implementations. The most successful teams aren’t the ones with the most sophisticated tools or the most advanced models – they’re the ones that master the fundamentals of measurement, iteration, and learning.</p>
<p>The core principles are surprisingly simple:</p>
<ol type="1">
<li><p><strong>Look at your data.</strong> Nothing replaces the insight gained from examining real examples. Error analysis consistently reveals the highest-ROI improvements.</p></li>
<li><p><strong>Build simple tools that remove friction.</strong> Custom data viewers that make it easy to examine AI outputs yield more insights than complex dashboards with generic metrics.</p></li>
<li><p><strong>Empower domain experts.</strong> The people who understand your domain best are often the ones who can most effectively improve your AI, regardless of their technical background.</p></li>
<li><p><strong>Use synthetic data strategically.</strong> You don’t need real users to start testing and improving your AI. Thoughtfully generated synthetic data can bootstrap your evaluation process.</p></li>
<li><p><strong>Maintain trust in your evaluations.</strong> Binary judgments with detailed critiques create clarity while preserving nuance. Regular alignment checks ensure automated evaluations remain trustworthy.</p></li>
<li><p><strong>Structure roadmaps around experiments, not features.</strong> Commit to a cadence of experimentation and learning rather than specific outcomes by specific dates.</p></li>
</ol>
<p>These principles apply regardless of your domain, team size, or technical stack. They’ve worked for companies ranging from early-stage startups to tech giants, across use cases from customer support to code generation.</p>
<section id="resources-for-going-deeper" class="level3">
<h3 class="anchored" data-anchor-id="resources-for-going-deeper">Resources for Going Deeper</h3>
<p>If you’d like to explore these topics further, here are some resources that might help:</p>
<ul>
<li><p><a href="https://ai.hamel.dev/">My blog</a> for more content on AI evaluation and improvement. My other posts dive into more technical detail on topics such as constructing effective LLM judges, implementing evaluation systems, and other aspects of AI development<sup>1</sup>. Also check out the blogs of <a href="https://www.sh-reya.com/">Shreya Shankar</a> and <a href="https://eugeneyan.com/">Eugene Yan</a> who are also great sources of information on these topics.</p></li>
<li><p>A course I’m teaching: <strong><a href="https://bit.ly/evals-ai">Rapidly Improve AI Products With Evals</a></strong>, with Shreya Shankar. The course provides hands-on experience with techniques such as error analysis, synthetic data generation, and building trustworthy evaluation systems. It includes practical exercises and personalized instruction through office hours.</p></li>
<li><p>If you’re looking for hands-on guidance specific to your organization’s needs, you can learn more about working with me at <a href="https://parlance-labs.com/">Parlance Labs</a>.</p></li>
</ul>


</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>I write more broadly about machine learning, AI, and software development. Some posts that expand on these topics include <a href="https://hamel.dev/blog/posts/evals/">Your AI Product Needs Evals</a>, <a href="https://hamel.dev/blog/posts/llm-judge/">Creating a LLM-as-a-Judge That Drives Business Results</a>, and <a href="https://applied-llms.org/">What We’ve Learned From A Year of Building with LLMs</a>. You can see all my posts at <a href="https://hamel.dev/">hamel.dev</a>.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>LLMs</category>
  <category>AI</category>
  <guid>https://hamel.dev/blog/posts/field-guide/</guid>
  <pubDate>Mon, 24 Mar 2025 07:00:00 GMT</pubDate>
  <media:content url="https://hamel.dev/blog/posts/field-guide/images/field_guide_2.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Thoughts On A Month With Devin</title>
  <link>https://hamel.dev/</link>
  <description>Our impressions of Devin after giving it 20+ tasks.
</description>
  <category>LLMs</category>
  <guid>https://hamel.dev/</guid>
  <pubDate>Sun, 19 Jan 2025 08:00:00 GMT</pubDate>
</item>
<item>
  <title>nbsanity - Share Notebooks as Polished Web Pages in Seconds</title>
  <link>https://hamel.dev/</link>
  <description>Transform your GitHub Jupyter notebooks into beautiful, readable web pages with a single URL change. No setup required.
</description>
  <category>Jupyter</category>
  <guid>https://hamel.dev/</guid>
  <pubDate>Fri, 13 Dec 2024 08:00:00 GMT</pubDate>
</item>
<item>
  <title>Building an Audience Through Technical Writing: Strategies and Mistakes</title>
  <dc:creator>Hamel Husain</dc:creator>
  <link>https://hamel.dev/blog/posts/audience/</link>
  <description><![CDATA[ 




<p>People often find me through my writing on AI and tech. This creates an interesting pattern. Nearly every week, vendors reach out asking me to write about their products. While I appreciate their interest and love learning about new tools, I reserve my writing for topics that I have personal experience with.</p>
<p>One conversation last week really stuck with me. A founder confided, “We can write the best content in the world, but we don’t have any distribution.” This hit home because I used to think the same way.</p>
<p>Let me share what works for reaching developers. Companies and individuals alike often skip the basics when trying to grow their audience. These are proven approaches I’ve seen succeed, both in my work and in others’ efforts to grow their audience in the AI space.</p>
<section id="build-on-great-work" class="level2">
<h2 class="anchored" data-anchor-id="build-on-great-work">1. Build on Great Work</h2>
<p>Here’s something surprising: few people take the time to thoughtfully engage with others’ work in our field. But when you do, amazing things happen naturally.</p>
<p>For example, here are some recent posts I’ve enjoyed that present opportunities to engage with others:</p>
<ul>
<li>Shreya Shankar’s <a href="https://data-people-group.github.io/blogs/2024/09/24/docetl/">DocETL</a></li>
<li>Eugene Yan’s work on <a href="https://eugeneyan.com/writing/aligneval/">AlignEval</a></li>
<li>Ben Claive’s work on <a href="https://www.answer.ai/posts/2024-09-16-rerankers.html">rerankers</a></li>
<li>Jeremy Howard’s work on <a href="https://www.answer.ai/posts/2024-09-03-llmstxt.html">llms.txt</a></li>
</ul>
<p>In the above examples, you could share how their ideas connect with what you’ve built. You could add additional case studies and real-world insights. If you deeply engage with someone’s work and add your insights, they often share your content with their audience. Not because you asked, but because you’ve added something meaningful to their work. Swyx has written a <a href="https://www.swyx.io/puwtpd">great post</a> on how to do this effectively.</p>
<p>The key is authenticity. Don’t do this just for marketing—do it because you’re genuinely interested in learning from others and building on their ideas. It’s not hard to find things to be excited about. I’m amazed by how few people take this approach. It’s both effective and fun.</p>
</section>
<section id="show-up-consistently" class="level2">
<h2 class="anchored" data-anchor-id="show-up-consistently">2. Show Up Consistently</h2>
<p>I see too many folks blogging or posting once every few months and wondering why they’re not getting traction. Want to know what actually works? Look at <a href="https://x.com/jxnlco">Jason Liu</a>. He grew his following from 500 to 30,000 followers by posting ~ 30 times every day for a year.</p>
<p>You don’t have to post that often (I certainly don’t!), but consistency matters more than perfection. Finally, don’t just post into the void. Engage with others. When someone comments on your post, reply thoughtfully. When you see conversations where you can add value, provide helpful information.</p>
<p>Finally, don’t be discouraged if you don’t see results immediately. Here’s some advice from my friend (and prolific writer), <a href="https://eugeneyan.com/">Eugene Yan</a>:</p>
<blockquote class="blockquote">
<p>In the beginning, when most people start writing, the output’s gonna suck. Harsh, but true—my first 100 posts or so were crap. But with practice, people can get better. But they have to be deliberate in wanting to practice and get better with each piece, and not just write for the sake of publishing something and tweeting about it. The Sam Parr course (see below) is a great example of deliberate practice on copywriting.</p>
</blockquote>
</section>
<section id="get-better-at-copywriting" class="level2">
<h2 class="anchored" data-anchor-id="get-better-at-copywriting">3. Get Better at Copywriting</h2>
<p>This changed everything for me. I took <a href="https://copythat.com/">Sam Parr’s copywriting course</a> just 30 minutes a day for a week. Now I keep my favorite writing samples in a Claude project and reference them when I’m writing something important. Small improvements in how you communicate can make a huge difference in how your content lands.</p>
<p>One thing Sam teaches is that big words don’t make you sound smart. Clear writing that avoids jargon is more effective. That’s why Sam teaches aiming for a 6th-grade reading level. This matters even more with AI, as AI loves to generate flowery language and long sentences. The <a href="https://hemingwayapp.com/">Hemingway App</a> can be helpful in helping you simplify your writing.<sup>1</sup></p>
</section>
<section id="build-a-voice-to-content-pipeline" class="level2">
<h2 class="anchored" data-anchor-id="build-a-voice-to-content-pipeline">4. Build a Voice-to-Content Pipeline</h2>
<p>The struggle most people have with creating content is that it takes too much time. But it doesn’t have to if you build the right systems, especially with AI.</p>
<p>Getting this system right takes some upfront work, but the payoff is enormous. Start by installing a good voice-to-text app on your phone. I use either <a href="https://superwhisper.com/">Superwhisper</a> or <a href="https://voicepal.me/">VoicePal</a>. VoicePal is great for prompting you to elaborate with follow-up questions. These tools let me capture ideas at their best. That’s usually when I’m walking outside or away from my computer. At my computer, I use <a href="https://www.flowvoice.ai/">Flow</a>.</p>
<p>The key is to carefully craft your first few pieces of content. These become examples for your prompts that teach AI your style and tone. Once you have high-quality examples, you can organize these (transcript, content) pairs and feed them to language models. The in-context learning creates remarkably aligned output that matches your writing style while maintaining the authenticity of your original thoughts.</p>
<p>For example, I use this pipeline at Answer AI. We have started interviewing each other and using the recordings as grounding for blog posts. Our recent <a href="https://www.answer.ai/posts/2024-11-07-solveit.html">post about SolveIt</a> shows this in action. The raw conversation is the foundation. Our workflow turns it into polished content.</p>
<p>I’ve also integrated this workflow into my meetings. Using <a href="https://circleback.ai/?via=hamel">CircleBack</a>, my favorite AI note-taking app, I can automatically capture and process meeting discussions. You can set up workflows to send your meeting notes and transcripts to AI for processing. This turns conversations into content opportunities.</p>
<p>The real power comes from having all these pieces working together. Voice capture, AI, and automation makes content creation fun and manageable.</p>
</section>
<section id="leverage-your-unique-perspective" class="level2">
<h2 class="anchored" data-anchor-id="leverage-your-unique-perspective">5. Leverage Your Unique Perspective</h2>
<p>Through my consulting work, I notice patterns that others miss. My most popular posts address common problems my clients had. When everyone’s confused about a topic, especially in AI where there’s lots of hype, clear explanations are gold. This is the motivation for some of my blog posts like:</p>
<ul>
<li><a href="https://hamel.dev/blog/posts/prompt/">Fuck You, Show Me The Prompt</a></li>
<li><a href="https://hamel.dev/blog/posts/evals/">Your AI Product Needs Evals</a></li>
<li><a href="https://hamel.dev/blog/posts/llm-judge/">Creating a LLM-as-a-Judge That Drives Business Results</a></li>
</ul>
<p>You probably see patterns too. Maybe it’s common questions from customers, or problems you’ve solved repeatedly. Maybe you work with a unique set of technologies or interesting use cases. Share these insights! Your unique perspective is more valuable than you think.</p>
</section>
<section id="use-high-quality-social-cards-threads-and-scheduling" class="level2">
<h2 class="anchored" data-anchor-id="use-high-quality-social-cards-threads-and-scheduling">6. Use High Quality Social Cards, Threads, and Scheduling</h2>
<p>This is probably the least important part of the process, but it’s still important. Thumbnails and social cards are vital for visibility on social media. Here are the tools I use:</p>
<ul>
<li><a href="https://socialsharepreview.com/">socialsharepreview.com</a> to check how your content looks on different platforms. For X, I sometimes use the <a href="https://cards-dev.twitter.com/validator">Twitter Card Validator</a>.</li>
<li><a href="https://chatgpt.com/">chatGPT</a> to create cover images for my posts. Then, paste them into Canva to size and edit them. Some of my friends use <a href="https://ideogram.ai/">ideogram</a>, which generates images with text accurately.</li>
<li><a href="https://www.canva.com/">Canva</a> for the last mile of creating social cards. They have easy-to-use buttons to ensure you get the dimensions right. They also have inpainting, background removal, and more.</li>
<li>If using X, social cards can be a bit fiddly. As of this writing, they do not show your post title, just the image if using the large-image size. To mitigate this,I use Canva to write the post’s title in the image <a href="https://hamel.dev/blog/posts/audience/content_2.png">like this</a>.</li>
<li>Social media can be distracting, so I like to schedule my posts in advance. I use <a href="https://typefully.com/">typefully</a> for this purpose. Some of my friends use <a href="https://hypefury.com/">hypefury</a>.</li>
</ul>
<p>Finally, when posting on X, threads can be a great way to raise the visibility of your content. A simple approach is to take screenshots or copy-paste snippets of your content. Then, walk through them in a thread, as you would want a reader to. Jeremy Howard does a great job at this: <a href="https://x.com/jeremyphoward/status/1818036923304456492">example 1</a>, <a href="https://x.com/jeremyphoward/status/1831089138571133290">example 2</a>.</p>
</section>
<section id="the-content-flywheel-putting-it-all-together" class="level2">
<h2 class="anchored" data-anchor-id="the-content-flywheel-putting-it-all-together">The Content Flywheel: Putting It All Together</h2>
<p>Once you have these systems in place, something magical happens: content creates more content. Your blog posts spawn social media updates. Your conversations turn into newsletters. Your client solutions become case studies. Each piece of work feeds the next, creating a natural flywheel.</p>
<p>Don’t try to sell too hard. Instead, share real insights and helpful information. Focus on adding value and educating your audience. When you do this well, people will want to follow your work.</p>
<p>This journey is different for everyone. These are just the patterns I’ve seen work in my consulting practice and my own growth. Try what feels right. Adjust what doesn’t.</p>
<p>P.S. If you’d like to follow my writing journey, you can <a href="https://ai.hamel.dev/">stay connected here</a>.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li><a href="https://simonwillison.net/tags/writing/">Simon Willison’s Posts on Writing</a></li>
<li><a href="https://eugeneyan.com/tag/writing/">Eugene’s Posts on Writing</a></li>
<li><a href="https://medium.com/@racheltho/why-you-yes-you-should-blog-7d2544ac1045">Why you, (yes, you) should blog</a></li>
</ul>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Don’t abuse these tools or use them blindly. There’s <a href="https://x.com/swyx/status/1863352038597558712">plenty of situations where you should not be writing at a 6th-grade reading level</a>. This includes, humor, poetry, shitposting, and more. Even formal writing shouldn’t adhere strictly to this rule. It’s advice that you should judge on a case-by-case basis. When you simplify your writing - do you like it more?↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Writing</category>
  <guid>https://hamel.dev/blog/posts/audience/</guid>
  <pubDate>Sat, 30 Nov 2024 08:00:00 GMT</pubDate>
  <media:content url="https://hamel.dev/blog/posts/audience/content_2.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Creating a LLM-as-a-Judge That Drives Business Results</title>
  <dc:creator>Hamel Husain</dc:creator>
  <link>https://hamel.dev/blog/posts/llm-judge/</link>
  <description><![CDATA[ 




<p>Earlier this year, I wrote <a href="https://hamel.dev/blog/posts/evals/">Your AI product needs evals</a>. Many of you asked, “How do I get started with LLM-as-a-judge?” This guide shares what I’ve learned after helping over <a href="https://parlance-labs.com/">30 companies</a> set up their evaluation systems.</p>
<section id="the-problem-ai-teams-are-drowning-in-data" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-ai-teams-are-drowning-in-data">The Problem: AI Teams Are Drowning in Data</h2>
<p>Ever spend weeks building an AI system, only to realize you have no idea if it’s actually working? You’re not alone. I’ve noticed teams repeat the same mistakes when using LLMs to evaluate AI outputs:</p>
<ol type="1">
<li><strong>Too Many Metrics</strong>: Creating numerous measurements that become unmanageable.</li>
<li><strong>Arbitrary Scoring Systems</strong>: Using uncalibrated scales (like 1-5) across multiple dimensions, where the difference between scores is unclear and subjective. What makes something a 3 versus a 4? Nobody knows, and different evaluators often interpret these scales differently.</li>
<li><strong>Ignoring Domain Experts</strong>: Not involving the people who understand the subject matter deeply.</li>
<li><strong>Unvalidated Metrics</strong>: Using measurements that don’t truly reflect what matters to the users or the business.</li>
</ol>
<p>The result? Teams end up buried under mountains of metrics or data they don’t trust and can’t use. Progress grinds to a halt. Everyone gets frustrated.</p>
<p>For example, it’s not uncommon for me to see dashboards that look like this:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/llm-judge/blog_header.png" class="img-fluid figure-img"></p>
<figcaption>An illustrative example of a bad eval dashboard</figcaption>
</figure>
</div>
<p>Tracking a bunch of scores on a 1-5 scale is often a sign of a bad eval process (I’ll discuss why later). In this post, I’ll show you how to avoid these pitfalls. The solution is to use a technique that I call <strong>“Critique Shadowing”</strong>. Here’s how to do it, step by step.</p>
</section>
<section id="step-1-find-the-principal-domain-expert" class="level2">
<h2 class="anchored" data-anchor-id="step-1-find-the-principal-domain-expert">Step 1: Find <em>The</em> Principal Domain Expert</h2>
<p>In most organizations there is usually one (maybe two) key individuals whose judgment is crucial for the success of your AI product. These are the people with deep domain expertise or represent your target users. Identifying and involving this <strong>Principal Domain Expert</strong> early in the process is critical.</p>
<p><strong>Why is finding the right domain expert so important?</strong></p>
<ul>
<li><p><strong>They Set the Standard</strong>: This person not only defines what is acceptable technically, but also helps you understand if you’re building something users actually want.</p></li>
<li><p><strong>Capture Unspoken Expectations</strong>: By involving them, you uncover their preferences and expectations, which they might not be able to fully articulate upfront. Through the evaluation process, you help them clarify what a “passable” AI interaction looks like.</p></li>
<li><p><strong>Consistency in Judgment</strong>: People in your organization may have different opinions about the AI’s performance. Focusing on the principal expert ensures that evaluations are consistent and aligned with the most critical standards.</p></li>
<li><p><strong>Sense of Ownership</strong>: Involving the expert gives them a stake in the AI’s development. They feel invested because they’ve had a hand in shaping it. In the end, they are more likely to approve of the AI.</p></li>
</ul>
<p><strong>Examples of Principal Domain Experts:</strong></p>
<ul>
<li>A <strong>psychologist</strong> for a mental health AI assistant.</li>
<li>A <strong>lawyer</strong> for an AI that analyzes legal documents.</li>
<li>A <strong>customer service director</strong> for a support chatbot.</li>
<li>A <strong>lead teacher or curriculum developer</strong> for an educational AI tool.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exceptions
</div>
</div>
<div class="callout-body-container callout-body">
<p>In a smaller company, this might be the CEO or founder. If you are an independent developer, you should be the domain expert (but be honest with yourself about your expertise).</p>
<p>If you must rely on leadership, you should regularly validate their assumptions against real user feedback.</p>
</div>
</div>
<p>Many developers attempt to act as the domain expert themselves, or find a convenient proxy (ex: their superior). This is a recipe for disaster. People will have varying opinions about what is acceptable, and you can’t make everyone happy. What’s important is that your principal domain expert is satisfied.</p>
<p><strong>Remember:</strong> This doesn’t have to take a lot of the domain expert’s time. Later in this post, I’ll discuss how you can make the process efficient. Their involvement is absolutely critical to the AI’s success.</p>
<section id="next-steps" class="level3">
<h3 class="anchored" data-anchor-id="next-steps">Next Steps</h3>
<p>Once you’ve found your expert, we need to give them the right data to review. Let’s talk about how to do that next.</p>
</section>
</section>
<section id="step-2-create-a-dataset" class="level2">
<h2 class="anchored" data-anchor-id="step-2-create-a-dataset">Step 2: Create a Dataset</h2>
<p>With your principal domain expert on board, the next step is to build a dataset that captures problems that your AI will encounter. It’s important that the dataset is diverse and represents the types of interactions that your AI will have in production.</p>
<section id="why-a-diverse-dataset-matters" class="level3">
<h3 class="anchored" data-anchor-id="why-a-diverse-dataset-matters">Why a Diverse Dataset Matters</h3>
<ul>
<li><strong>Comprehensive Testing</strong>: Ensures your AI is evaluated across a wide range of situations.</li>
<li><strong>Realistic Interactions</strong>: Reflects actual user behavior for more relevant evaluations.</li>
<li><strong>Identifies Weaknesses</strong>: Helps uncover areas where the AI may struggle or produce errors.</li>
</ul>
</section>
<section id="dimensions-for-structuring-your-dataset" class="level3">
<h3 class="anchored" data-anchor-id="dimensions-for-structuring-your-dataset">Dimensions for Structuring Your Dataset</h3>
<p>You want to define dimensions that make sense for your use case. For example, here are ones that I often use for B2C applications:</p>
<ol type="1">
<li><strong>Features</strong>: Specific functionalities of your AI product.</li>
<li><strong>Scenarios</strong>: Situations or problems the AI may encounter and needs to handle.</li>
<li><strong>Personas</strong>: Representative user profiles with distinct characteristics and needs.</li>
</ol>
</section>
<section id="examples-of-features-scenarios-and-personas" class="level3">
<h3 class="anchored" data-anchor-id="examples-of-features-scenarios-and-personas">Examples of Features, Scenarios, and Personas</h3>
<section id="features" class="level4">
<h4 class="anchored" data-anchor-id="features">Features</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 30%">
<col style="width: 69%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Feature</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Email Summarization</strong></td>
<td>Condensing lengthy emails into key points.</td>
</tr>
<tr class="even">
<td><strong>Meeting Scheduler</strong></td>
<td>Automating the scheduling of meetings across time zones.</td>
</tr>
<tr class="odd">
<td><strong>Order Tracking</strong></td>
<td>Providing shipment status and delivery updates.</td>
</tr>
<tr class="even">
<td><strong>Contact Search</strong></td>
<td>Finding and retrieving contact information from a database.</td>
</tr>
<tr class="odd">
<td><strong>Language Translation</strong></td>
<td>Translating text between languages.</td>
</tr>
<tr class="even">
<td><strong>Content Recommendation</strong></td>
<td>Suggesting articles or products based on user interests.</td>
</tr>
</tbody>
</table>
</section>
<section id="scenarios" class="level4">
<h4 class="anchored" data-anchor-id="scenarios">Scenarios</h4>
<p>Scenarios are situations the AI needs to handle, (not based on the outcome of the AI’s response).</p>
<table class="caption-top table">
<colgroup>
<col style="width: 31%">
<col style="width: 68%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Scenario</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Multiple Matches Found</strong></td>
<td>User’s request yields multiple results that need narrowing down. For example: User asks “Where’s my order?” but has three active orders (#123, #124, #125). AI must help identify which specific order they’re asking about.</td>
</tr>
<tr class="even">
<td><strong>No Matches Found</strong></td>
<td>User’s request yields no results, requiring alternatives or corrections. For example: User searches for order #ABC-123 which doesn’t exist. AI should explain valid order formats and suggest checking their confirmation email.</td>
</tr>
<tr class="odd">
<td><strong>Ambiguous Request</strong></td>
<td>User input lacks necessary specificity. For example: User says “I need to change my delivery” without specifying which order or what aspect of delivery (date, address, etc.) they want to change.</td>
</tr>
<tr class="even">
<td><strong>Invalid Data Provided</strong></td>
<td>User provides incorrect data type or format. For example: User tries to track a return using a regular order number instead of a return authorization (RMA) number.</td>
</tr>
<tr class="odd">
<td><strong>System Errors</strong></td>
<td>Technical issues prevent normal operation. For example: While looking up an order, the inventory database is temporarily unavailable. AI needs to explain the situation and provide alternatives.</td>
</tr>
<tr class="even">
<td><strong>Incomplete Information</strong></td>
<td>User omits required details. For example: User wants to initiate a return but hasn’t provided the order number or reason. AI needs to collect this information step by step.</td>
</tr>
<tr class="odd">
<td><strong>Unsupported Feature</strong></td>
<td>User requests functionality that doesn’t exist. For example: User asks to change payment method after order has shipped. AI must explain why this isn’t possible and suggest alternatives.</td>
</tr>
</tbody>
</table>
</section>
<section id="personas" class="level4">
<h4 class="anchored" data-anchor-id="personas">Personas</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 27%">
<col style="width: 72%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Persona</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>New User</strong></td>
<td>Unfamiliar with the system; requires guidance.</td>
</tr>
<tr class="even">
<td><strong>Expert User</strong></td>
<td>Experienced; expects efficiency and advanced features.</td>
</tr>
<tr class="odd">
<td><strong>Non-Native Speaker</strong></td>
<td>May have language barriers; uses non-standard expressions.</td>
</tr>
<tr class="even">
<td><strong>Busy Professional</strong></td>
<td>Values quick, concise responses; often multitasking.</td>
</tr>
<tr class="odd">
<td><strong>Technophobe</strong></td>
<td>Uncomfortable with technology; needs simple instructions.</td>
</tr>
<tr class="even">
<td><strong>Elderly User</strong></td>
<td>May not be tech-savvy; requires patience and clear guidance.</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="this-taxonomy-is-not-universal" class="level3">
<h3 class="anchored" data-anchor-id="this-taxonomy-is-not-universal">This taxonomy is not universal</h3>
<p>This taxonomy (features, scenarios, personas) is not universal. For example, it may not make sense to even have personas if users aren’t directly engaging with your AI. The idea is you should outline dimensions that make sense for your use case and generate data that covers them. You’ll likely refine these after the first round of evaluations.</p>
</section>
<section id="generating-data" class="level3">
<h3 class="anchored" data-anchor-id="generating-data">Generating Data</h3>
<p>To build your dataset, you can:</p>
<ul>
<li><strong>Use Existing Data</strong>: Sample real user interactions or behaviors from your AI system.</li>
<li><strong>Generate Synthetic Data</strong>: Use LLMs to create realistic user inputs covering various features, scenarios, and personas.</li>
</ul>
<p>Often, you’ll do a combination of both to ensure comprehensive coverage. Synthetic data is not as good as real data, but it’s a good starting point. Also, we are only using LLMs to generate the user inputs, not the LLM responses or internal system behavior.</p>
<p>Regardless of whether you use existing data or synthetic data, you want good coverage across the dimensions you’ve defined.</p>
<p><strong>Incorporating System Information</strong></p>
<p>When making test data, use your APIs and databases where appropriate. This will create realistic data and trigger the right scenarios. Sometimes you’ll need to write simple programs to get this information. That’s what the “Assumptions” column is referring to in the examples below.</p>
</section>
<section id="example-llm-prompts-for-generating-user-inputs" class="level3">
<h3 class="anchored" data-anchor-id="example-llm-prompts-for-generating-user-inputs">Example LLM Prompts for Generating User Inputs</h3>
<p>Here are some example prompts that illustrate how to use an LLM to generate synthetic <strong>user inputs</strong> for different combinations of features, scenarios, and personas:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 3%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 10%">
<col style="width: 35%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th><strong>ID</strong></th>
<th><strong>Feature</strong></th>
<th><strong>Scenario</strong></th>
<th><strong>Persona</strong></th>
<th><strong>LLM Prompt to Generate User Input</strong></th>
<th>Assumptions (not directly in the prompt)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><strong>Order Tracking</strong></td>
<td>Invalid Data Provided</td>
<td>Frustrated Customer</td>
<td>“Generate a user input from someone who is clearly irritated and impatient, using short, terse language to demand information about their order status for order number <strong>#1234567890</strong>. Include hints of previous negative experiences.”</td>
<td>Order number <strong>#1234567890</strong> does <strong>not</strong> exist in the system.</td>
</tr>
<tr class="even">
<td>2</td>
<td><strong>Contact Search</strong></td>
<td>Multiple Matches Found</td>
<td>New User</td>
<td>“Create a user input from someone who seems unfamiliar with the system, using hesitant language and asking for help to find contact information for a person named ‘Alex’. The user should appear unsure about what information is needed.”</td>
<td>Multiple contacts named ‘Alex’ exist in the system.</td>
</tr>
<tr class="odd">
<td>3</td>
<td><strong>Meeting Scheduler</strong></td>
<td>Ambiguous Request</td>
<td>Busy Professional</td>
<td>“Simulate a user input from someone who is clearly in a hurry, using abbreviated language and minimal details to request scheduling a meeting. The message should feel rushed and lack specific information.”</td>
<td>N/A</td>
</tr>
<tr class="even">
<td>4</td>
<td><strong>Content Recommendation</strong></td>
<td>No Matches Found</td>
<td>Expert User</td>
<td>“Produce a user input from someone who demonstrates in-depth knowledge of their industry, using specific terminology to request articles on sustainable supply chain management. Use the information in this article involving sustainable supply chain management to formulate a plausible query: {{article}}”</td>
<td>No articles on ‘Emerging trends in sustainable supply chain management’ exist in the system.</td>
</tr>
</tbody>
</table>
</section>
<section id="generating-synthetic-data" class="level3">
<h3 class="anchored" data-anchor-id="generating-synthetic-data">Generating Synthetic Data</h3>
<p>When generating synthetic data, you only need to create the user inputs. You then feed these inputs into your AI system to generate the AI’s responses. It’s important that you log everything so you can evaluate your AI. To recap, here’s the process:</p>
<ol type="1">
<li><strong>Generate User Inputs</strong>: Use the LLM prompts to create realistic user inputs.</li>
<li><strong>Feed Inputs into Your AI System</strong>: Input the user interactions into your AI as it currently exists.</li>
<li><strong>Capture AI Responses</strong>: Record the AI’s responses to form complete interactions.</li>
<li><strong>Organize the Interactions</strong>: Create a table to store the user inputs, AI responses, and relevant metadata.</li>
</ol>
<section id="how-much-data-should-you-generate" class="level4">
<h4 class="anchored" data-anchor-id="how-much-data-should-you-generate">How much data should you generate?</h4>
<p>There is no right answer here. At a minimum, you want to generate enough data so that you have examples for each combination of dimensions (in this toy example: features, scenarios, and personas). However, you also want to keep generating more data until you feel like you have stopped seeing new failure modes. The amount of data I generate varies significantly depending on the use case.</p>
</section>
<section id="does-synthetic-data-actually-work" class="level4">
<h4 class="anchored" data-anchor-id="does-synthetic-data-actually-work">Does synthetic data actually work?</h4>
<p>You might be skeptical of using synthetic data. After all, it’s not real data, so how can it be a good proxy? In my experience, it works surprisingly well. Some of my favorite AI products, like <a href="https://hex.tech/">Hex</a> use synthetic data to power their evals:</p>
<blockquote class="blockquote">
<p>“LLMs are surprisingly good at generating excellent - and diverse - examples of user prompts. This can be relevant for powering application features, and sneakily, for building Evals. If this sounds a bit like the Large Language Snake is eating its tail, I was just as surprised as you! All I can say is: it works, ship it.” <em><a href="https://www.linkedin.com/in/bryan-bischof/">Bryan Bischof</a>, Head of AI Engineering at Hex</em></p>
</blockquote>
</section>
</section>
<section id="next-steps-1" class="level3">
<h3 class="anchored" data-anchor-id="next-steps-1">Next Steps</h3>
<p>With your dataset ready, now comes the most important part: getting your principal domain expert to evaluate the interactions.</p>
</section>
</section>
<section id="step-3-direct-the-domain-expert-to-make-passfail-judgments-with-critiques" class="level2">
<h2 class="anchored" data-anchor-id="step-3-direct-the-domain-expert-to-make-passfail-judgments-with-critiques">Step 3: Direct The Domain Expert to Make Pass/Fail Judgments with Critiques</h2>
<p>The domain expert’s job is to focus on one thing: <strong>“Did the AI achieve the desired outcome?”</strong> No complex scoring scales or multiple metrics. Just a clear <strong>pass or fail</strong> decision. In addition to the pass/fail decision, the domain expert should write a critique that explains their reasoning.</p>
<section id="why-are-simple-passfail-metrics-important" class="level3">
<h3 class="anchored" data-anchor-id="why-are-simple-passfail-metrics-important">Why are simple pass/fail metrics important?</h3>
<ul>
<li><p><strong>Clarity and Focus</strong>: A binary decision forces everyone to consider what truly matters. It simplifies the evaluation to a single, crucial question.</p></li>
<li><p><strong>Actionable Insights</strong>: Pass/fail judgments are easy to interpret and act upon. They help you quickly identify whether the AI meets the user’s needs.</p></li>
<li><p><strong>Forces Articulation of Expectations</strong>: When domain experts must decide if an interaction passes or fails, they are compelled to articulate their expectations clearly. This process uncovers nuances and unspoken assumptions about how the AI should behave.</p></li>
<li><p><strong>Efficient Use of Resources</strong>: Keeps the evaluation process manageable, especially when starting out. You avoid getting bogged down in detailed metrics that might not be meaningful yet.</p></li>
</ul>
</section>
<section id="the-role-of-critiques" class="level3">
<h3 class="anchored" data-anchor-id="the-role-of-critiques">The Role of Critiques</h3>
<p>Alongside a binary pass/fail judgment, it’s important to write a detailed critique of the LLM-generated output. These critiques:</p>
<ul>
<li><p><strong>Captures Nuances</strong>: The critique allows you to note if something was mostly correct but had areas for improvement.</p></li>
<li><p><strong>Guide Improvement</strong>: Detailed feedback provides specific insights into how the AI can be enhanced.</p></li>
<li><p><strong>Balance Simplicity with Depth</strong>: While the pass/fail offers a clear verdict, the critique offers the depth needed to understand the reasoning behind the judgment.</p></li>
</ul>
<p><strong>Why Write Critiques?:</strong></p>
<p>In practice, domain experts may not have fully internalized all the judgment criteria. By forcing them to make a pass/fail decision and explain their reasoning, they clarify their expectations and provide valuable guidance for refining the AI.</p>
<p><em>“But my problem is complex!”</em> Trust me—starting simple forces you to focus on what truly matters. You can introduce more complexity later if needed.</p>
</section>
<section id="examples-of-good-critiques" class="level3">
<h3 class="anchored" data-anchor-id="examples-of-good-critiques">Examples of Good Critiques</h3>
<p>To illustrate how simple pass/fail judgments combined with detailed critiques work in practice, here’s a table showcasing examples of user interactions with an AI assistant. The table includes both <strong>passes</strong> and <strong>fails</strong>, with critiques explaining why the AI received that judgment. In cases where the AI passed despite critical issues, the critique highlights these aspects and justifies why it still passed overall. For failed interactions, the critique explains the critical elements that led to the failure.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 51%">
<col style="width: 24%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="header">
<th><strong>User Interaction with AI</strong></th>
<th><strong>Judgment</strong></th>
<th><strong>Critique</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>User:</strong> “I need to cancel my flight booking for next week.”<br><strong>AI:</strong> “Your flight booking for next week has been canceled. A confirmation email has been sent to you.”</td>
<td><strong>Pass</strong></td>
<td>The AI successfully executed the user’s request by canceling the flight and sending a confirmation, achieving the primary goal. <strong>However</strong>, it should have asked for confirmation before proceeding to prevent accidental cancellations. Despite this critical oversight, the AI fulfilled the user’s request, so it <strong>passes</strong>, but adding a confirmation step would improve user safety.</td>
</tr>
<tr class="even">
<td><strong>User:</strong> “What’s the capital of France?”<br><strong>AI:</strong> “The capital of France is Paris.”</td>
<td><strong>Pass</strong></td>
<td>The AI correctly answered the user’s question, providing accurate information promptly. <strong>Although</strong> the response is sufficient, the AI could enhance the interaction by offering additional interesting facts or asking if the user has more questions. Despite this opportunity for added engagement, the AI met the user’s primary need, so it <strong>passes</strong>.</td>
</tr>
<tr class="odd">
<td><strong>User:</strong> “I can’t log into my account; it says my password is incorrect.”<br><strong>AI:</strong> “Please reset your password by clicking ‘Forgot Password’.”</td>
<td><strong>Fail</strong></td>
<td>The AI provided a generic solution without acknowledging the user’s frustration or checking for other issues like account lockout. It failed to offer empathetic support or additional assistance. Due to the lack of personalized help and poor user experience, it <strong>fails</strong>.</td>
</tr>
<tr class="even">
<td><strong>User:</strong> “Book a table for two at an Italian restaurant tonight at 7 PM.”<br><strong>AI:</strong> “Table for two at Luigi’s Italian Restaurant booked for tonight at 7 PM. Confirmation number is 12345.”</td>
<td><strong>Pass</strong></td>
<td>The AI efficiently completed the booking as requested, providing all necessary details and a confirmation number. <strong>However</strong>, it could have asked if the user had seating preferences or dietary restrictions. The AI accomplished the primary task successfully, so it <strong>passes</strong>, with minor opportunities for enhanced service.</td>
</tr>
<tr class="odd">
<td><strong>User:</strong> “I need help with my billing statement.”<br><strong>AI:</strong> “Please provide your account number and full name.”</td>
<td><strong>Fail</strong></td>
<td>The AI requested sensitive information without verifying the user’s identity through secure means, potentially compromising security. It should guide the user through a secure authentication process first. Due to this critical oversight in user data protection, it <strong>fails</strong>.</td>
</tr>
</tbody>
</table>
<p>These examples demonstrate how the AI can receive both <strong>“Pass”</strong> and <strong>“Fail”</strong> judgments. In the critiques:</p>
<ul>
<li><p>For <strong>passes</strong>, we explain why the AI succeeded in meeting the user’s primary need, even if there were critical aspects that could be improved. We highlight these areas for enhancement while justifying the overall passing judgment.</p></li>
<li><p>For <strong>fails</strong>, we identify the critical elements that led to the failure, explaining why the AI did not meet the user’s main objective or compromised important factors like user experience or security.</p></li>
</ul>
<p>Most importantly, <strong>the critique should be detailed enough so that you can use it in a few-shot prompt for a LLM judge</strong>. In other words, it should be detailed enough that a new employee could understand it. Being too terse is a common mistake.</p>
<p>Note that the example user interactions with the AI are simplified for brevity - but you might need to give the domain expert more context to make a judgement. More on that later.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>At this point, you don’t need to perform a root cause analysis into the technical reasons behind why the AI failed. Many times, it’s useful to get a sense of overall behavior before diving into the weeds.</p>
</div>
</div>
</section>
<section id="dont-stray-from-binary-passfail-judgments-when-starting-out" class="level3">
<h3 class="anchored" data-anchor-id="dont-stray-from-binary-passfail-judgments-when-starting-out">Don’t stray from binary pass/fail judgments when starting out</h3>
<p>A common mistake is straying from binary pass/fail judgments. Let’s revisit the dashboard from earlier:</p>
<p><img src="https://hamel.dev/blog/posts/llm-judge/dashboard.png" class="img-fluid"></p>
<p>If your evaluations consist of a bunch of metrics that LLMs score on a 1-5 scale (or any other scale), you’re doing it wrong. Let’s unpack why.</p>
<ol type="1">
<li><strong>It’s not actionable</strong>: People don’t know what to do with a 3 or 4. It’s not immediately obvious how this number is better than a 2. You need to be able to say “this interaction passed because…” and “this interaction failed because…”.</li>
<li>More often than not, <strong>these metrics do not matter</strong>. Every time I’ve analyzed data on domain expert judgments, they tend not to correlate with these kind of metrics. By having a domain expert make a binary judgment, you can figure out what truly matters.</li>
</ol>
<p>This is why I hate off the shelf metrics that come with many evaluation frameworks. They tend to lead people astray.</p>
<p><strong>Common Objections to Pass/Fail Judgments:</strong></p>
<ul>
<li>“The business said that these 8 dimensions are important, so we need to evaluate all of them.”</li>
<li>“We need to be able to say why an interaction passed or failed.”</li>
</ul>
<p>I can guarantee you that if someone says you need to measure 8 things on a 1-5 scale, they don’t know what they are looking for. They are just guessing. You have to let the domain expert drive and make a pass/fail judgment with critiques so you can figure out what truly matters. Stand your ground here.</p>
</section>
<section id="make-it-easy-for-the-domain-expert-to-review-data" class="level3">
<h3 class="anchored" data-anchor-id="make-it-easy-for-the-domain-expert-to-review-data">Make it easy for the domain expert to review data</h3>
<p>Finally, you need to remove all friction from reviewing data. I’ve written about this <a href="../../../notes/llm/finetuning/data_cleaning.html">here</a>. Sometimes, you can just use a spreadsheet. It’s a judgement call in terms of what is easiest for the domain expert. I found that I often have to provide additional context to help the domain expert understand the user interaction, such as:</p>
<ul>
<li>Metadata about the user, such as their location, subscription tier, etc.</li>
<li>Additional context about the system, such as the current time, inventory levels, etc.</li>
<li>Resources so you can check if the AI’s response is correct (ex: ability to search a database, etc.)</li>
</ul>
<p>All of this data needs to be presented on a single screen so the domain expert can review it without jumping through hoops. That’s why I recommend building <a href="../../../notes/llm/finetuning/data_cleaning.html">a simple web app</a> to review data.</p>
</section>
<section id="how-many-examples-do-you-need" class="level3">
<h3 class="anchored" data-anchor-id="how-many-examples-do-you-need">How many examples do you need?</h3>
<p>The number of examples you need depends on the complexity of the task. My heuristic is that I start with around 30 examples and keep going until I do not see any new failure modes. From there, I keep going until I’m not learning anything new.</p>
<p>Next, we’ll look at how to use this data to build an LLM judge.</p>
</section>
</section>
<section id="step-4-fix-errors" class="level2">
<h2 class="anchored" data-anchor-id="step-4-fix-errors">Step 4: Fix Errors</h2>
<p>After looking at the data, it’s likely you will find errors in your AI system. Instead of plowing ahead and building an LLM judge, you want to fix any obvious errors. Remember, the whole point of the LLM as a judge is to help you find these errors, so it’s totally fine if you find them earlier!</p>
<p>If you have already developed <a href="https://hamel.dev/blog/posts/evals">Level 1 evals as outlined in my previous post</a>, you should not have any pervasive errors. However, these errors can sometimes slip through the cracks. If you find pervasive errors, fix them and go back to step 3. Keep iterating until you feel like you have stabilized your system.</p>
</section>
<section id="step-5-build-your-llm-as-a-judge-iteratively" class="level2">
<h2 class="anchored" data-anchor-id="step-5-build-your-llm-as-a-judge-iteratively">Step 5: Build Your LLM as A Judge, Iteratively</h2>
<section id="the-hidden-power-of-critiques" class="level3">
<h3 class="anchored" data-anchor-id="the-hidden-power-of-critiques">The Hidden Power of Critiques</h3>
<p>You cannot write a good judge prompt until you’ve seen the data. <a href="https://arxiv.org/abs/2404.12272">The paper from Shankar et al.,</a> “Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences” summarizes this well:</p>
<blockquote class="blockquote">
<p>to grade outputs,people need to externalize and define their evaluation criteria; however, the process of grading outputs helps them to define that very criteria. We dub this phenomenon criteria drift, and it implies thatit is impossible to completely determine evaluation criteria prior to human judging of LLM outputs.</p>
</blockquote>
</section>
<section id="start-with-expert-examples" class="level3">
<h3 class="anchored" data-anchor-id="start-with-expert-examples">Start with Expert Examples</h3>
<p>Let me share a real-world example of building an LLM judge you can apply to your own use case. When I was helping Honeycomb build their <a href="https://www.honeycomb.io/blog/introducing-query-assistant">Query Assistant feature</a>, we needed a way to evaluate if the AI was generating good queries. Here’s what our LLM judge prompt looked like, including few-shot examples of critiques from our domain expert, <a href="https://x.com/_cartermp">Phillip</a>:</p>
<pre class="text"><code>You are a Honeycomb query evaluator with advanced capabilities to judge if a query is good or not.
You understand the nuances of the Honeycomb query language, including what is likely to be
most useful from an analytics perspective. 

Here is information about the Honeycomb query language:
{{query_language_info}}

Here are some guidelines for evaluating queries:
{{guidelines}}

Example evaluations:

&lt;examples&gt;

&lt;example-1&gt;
&lt;nlq&gt;show me traces where ip is 10.0.2.90&lt;/nlq&gt;
&lt;query&gt;
{
  "breakdowns": ["trace.trace_id"],
  "calculations": [{"op": "COUNT"}],
  "filters": [{"column": "net.host.ip", "op": "=", "value": "10.0.2.90"}]
}
&lt;/query&gt;
&lt;critique&gt;
{
  "critique": "The query correctly filters for traces with an IP address of 10.0.2.90 
   and counts the occurrences of those traces, grouped by trace.trace_id. The response 
   is good as it meets the requirement of showing traces from a specific IP address 
   without additional complexities.",
  "outcome": "good"
}
&lt;/critique&gt;
&lt;/example-1&gt;

&lt;example-2&gt;
&lt;nlq&gt;show me slowest trace&lt;/nlq&gt;
&lt;query&gt;
{
  "calculations": [{"column": "duration_ms", "op": "MAX"}],
  "orders": [{"column": "duration_ms", "op": "MAX", "order": "descending"}],
  "limit": 1
}
&lt;/query&gt;
&lt;critique&gt;
{
  "critique": "While the query attempts to find the slowest trace using MAX(duration_ms) 
   and ordering correctly, it fails to group by trace.trace_id. Without this grouping, 
   the query only shows the MAX(duration_ms) measurement over time, not the actual 
   slowest trace.",
  "outcome": "bad"
}
&lt;/critique&gt;
&lt;/example-2&gt;

&lt;example-3&gt;
&lt;nlq&gt;count window-hash where window-hash exists per hour&lt;/nlq&gt;
&lt;query&gt;
{
  "breakdowns": ["window-hash"],
  "calculations": [{"op": "COUNT"}],
  "filters": [{"column": "window-hash", "op": "exists"}],
  "time_range": 3600
}
&lt;/query&gt;
&lt;critique&gt;
{
  "critique": "While the query correctly counts window-hash occurrences, the time_range 
   of 3600 seconds (1 hour) is insufficient for per-hour analysis. When we say 'per hour', 
   we need a time_range of at least 36000 seconds to show meaningful hourly patterns.",
  "outcome": "bad"
}
&lt;/critique&gt;
&lt;/example-3&gt;

&lt;/examples&gt;

For the following query, first write a detailed critique explaining your reasoning,
then provide a pass/fail judgment in the same format as above.

&lt;nlq&gt;{{user_input}}&lt;/nlq&gt;
&lt;query&gt;
{{generated_query}}
&lt;/query&gt;
&lt;critique&gt;</code></pre>
<p>Notice how each example includes:</p>
<ol type="1">
<li>The natural language query (NLQ) in <code>&lt;nlq&gt;</code> tags</li>
<li>The generated query in <code>&lt;query&gt;</code> tags</li>
<li>The critique and outcome in <code>&lt;critique&gt;</code> tags</li>
</ol>
<p>In the prompt above, the example critiques are fixed. An advanced approach is to include examples dynamically based upon the item you are judging. You can learn more in <a href="https://blog.langchain.dev/dosu-langsmith-no-prompt-eng/">this post about Continual In-Context Learning</a>.</p>
</section>
<section id="keep-iterating-on-the-prompt-until-convergence-with-domain-expert" class="level3">
<h3 class="anchored" data-anchor-id="keep-iterating-on-the-prompt-until-convergence-with-domain-expert">Keep Iterating on the Prompt Until Convergence With Domain Expert</h3>
<p>In this case, I used a low-tech approach to iterate on the prompt. I sent Phillip a spreadsheet with the following information:</p>
<ol type="1">
<li>The NLQ</li>
<li>The generated query</li>
<li>The critique</li>
<li>The outcome (pass or fail)</li>
</ol>
<p>Phillip would then fill out his own version of the spreadsheet with his critiques. I used this to iteratively improve the prompt. The spreadsheet looked like this:</p>
<p><img src="https://hamel.dev/blog/posts/llm-judge/spreadsheet.png" class="img-fluid"></p>
<p>I also tracked agreement rates over time to ensure we were converging on a good prompt.</p>
<p><img src="https://hamel.dev/blog/posts/llm-judge/score.png" class="img-fluid"></p>
<p>It took us only three iterations to achieve &gt; 90% agreement between the LLM and Phillip. Your mileage may vary depending on the complexity of the task. For example, <a href="https://humanloop.com/blog/why-your-product-needs-evals">Swyx has conducted a similar process hundreds of times</a> for <a href="https://www.latent.space/">AI News</a>, an <a href="https://x.com/swyx/status/1672306744884887553">extremely popular</a> news aggregator with high quality recommendations. The quality of the AI owing to this process is why this product has received <a href="https://buttondown.com/ainews">critical acclaim</a>.</p>
</section>
<section id="how-to-optimize-the-llm-judge-prompt" class="level3">
<h3 class="anchored" data-anchor-id="how-to-optimize-the-llm-judge-prompt">How to Optimize the LLM Judge Prompt?</h3>
<p>I usually adjust the prompts by hand. I haven’t had much luck with prompt optimizers like DSPy. However, my friend <a href="https://eugeneyan.com/">Eugene Yan</a> has just released a promising tool named <a href="https://eugeneyan.com/writing/aligneval/">ALIGN Eval</a>. I like it because it’s simple and effective. Also, don’t forget the approach of <a href="https://blog.langchain.dev/dosu-langsmith-no-prompt-eng/">continual in-context learning</a> mentioned earlier - it can be effective when implemented correctly.</p>
<p>In rare cases, I might fine-tune a judge, but I prefer not to. I talk about this more in the FAQ section.</p>
</section>
<section id="the-human-side-of-the-process" class="level3">
<h3 class="anchored" data-anchor-id="the-human-side-of-the-process">The Human Side of the Process</h3>
<p>Something unexpected happened during this process. <a href="https://www.linkedin.com/in/phillip-carter-4714a135/">Phillip Carter</a>, our domain expert at Honeycomb, found that reviewing the LLM’s critiques helped him articulate his own evaluation criteria more clearly. He said,</p>
<blockquote class="blockquote">
<p>“Seeing how the LLM breaks down its reasoning made me realize I wasn’t being consistent about how I judged certain edge cases.”</p>
</blockquote>
<p>This is a pattern I’ve seen repeatedly—the process of building an LLM judge often helps standardize evaluation criteria.</p>
<p>Furthermore, because this process forces the domain expert to look at data carefully, I always uncover new insights about the product, AI capabilities, and user needs. The resulting benefits are often <em>more valuable</em> than creating a LLM judge!</p>
</section>
<section id="how-often-should-you-evaluate" class="level3">
<h3 class="anchored" data-anchor-id="how-often-should-you-evaluate">How Often Should You Evaluate?</h3>
<p>I conduct this human review at regular intervals and whenever something material changes. For example, if I update a model, I’ll run the process again. I don’t get too scientific here; instead, I rely on my best judgment. Also note that after the first two iterations, I tend to focus more on errors rather than sampling randomly. For example, if I find an error, I’ll search for more examples that I think might trigger the same error. However, I always do a bit of random sampling as well.</p>
</section>
<section id="what-if-this-doesnt-work" class="level3">
<h3 class="anchored" data-anchor-id="what-if-this-doesnt-work">What if this doesn’t work?</h3>
<p>I’ve seen this process fail when:</p>
<ul>
<li>The AI is overscoped: Example - a chatbot in a SaaS product that promises to do anything you want.</li>
<li>The process is not followed correctly: Not using the principal domain expert, not writing proper critiques, etc.</li>
<li>The expectations of alignment are unrealistic or not feasible.</li>
</ul>
<p>In each of these cases, I try to address the root cause instead of trying to force alignment. Sometimes, you may not be able to achieve the alignment you want and may have to lean heavier on human annotations. However, after following the process described here, you will have metrics that help you understand how much you can trust the LLM judge.</p>
</section>
<section id="mistakes-ive-noticed-in-llm-judge-prompts" class="level3">
<h3 class="anchored" data-anchor-id="mistakes-ive-noticed-in-llm-judge-prompts">Mistakes I’ve noticed in LLM judge prompts</h3>
<p>Most of the mistakes I’ve seen in LLM judge prompts have to do with not providing good examples:</p>
<ol type="1">
<li>Not providing any critiques.</li>
<li>Writing extremely terse critiques.</li>
<li>Not providing external context. Your examples should contain the same information you use to evaluate, including external information like user metadata, system information etc.</li>
<li>Not providing diverse examples. You need a wide variety of examples to ensure that your judge works for a wide variety of inputs.</li>
</ol>
<p>Sometimes, you may encounter difficulties with fitting everything you need into the prompt, and may have to get creative about how you structure the examples. However, this is becoming less of an issue thanks to expanding context windows and <a href="https://platform.openai.com/docs/guides/prompt-caching">prompt caching</a>.</p>
</section>
</section>
<section id="step-6-perform-error-analysis" class="level2">
<h2 class="anchored" data-anchor-id="step-6-perform-error-analysis">Step 6: Perform Error Analysis</h2>
<p>After you have created a LLM as a judge, you will have a dataset of user interactions with the AI, and the LLM’s judgments. If your metrics show an acceptable agreement between the domain expert and the LLM judge, you can apply this judge against real or synthetic interactions. After this, you can you calculate error rates for different dimensions of your data. You should calculate the error on unseen data only to make sure your aren’t getting biased results.</p>
<p>For example, if you have segmented your data by persona, scenario, feature, etc, your data analysis may look like this</p>
<p><strong>Error Rates by Key Dimensions</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Feature</th>
<th>Scenario</th>
<th>Persona</th>
<th>Total Examples</th>
<th>Failure Rate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Order Tracking</td>
<td>Multiple Matches</td>
<td>New User</td>
<td>42</td>
<td>24.3%</td>
</tr>
<tr class="even">
<td>Order Tracking</td>
<td>Multiple Matches</td>
<td>Expert User</td>
<td>38</td>
<td>18.4%</td>
</tr>
<tr class="odd">
<td>Order Tracking</td>
<td>No Matches</td>
<td>Expert User</td>
<td>30</td>
<td>23.3%</td>
</tr>
<tr class="even">
<td>Order Tracking</td>
<td>No Matches</td>
<td>New User</td>
<td>20</td>
<td>75.0%</td>
</tr>
<tr class="odd">
<td>Contact Search</td>
<td>Multiple Matches</td>
<td>New User</td>
<td>35</td>
<td>22.9%</td>
</tr>
<tr class="even">
<td>Contact Search</td>
<td>Multiple Matches</td>
<td>Expert User</td>
<td>32</td>
<td>19.7%</td>
</tr>
<tr class="odd">
<td>Contact Search</td>
<td>No Matches</td>
<td>New User</td>
<td>25</td>
<td>68.0%</td>
</tr>
<tr class="even">
<td>Contact Search</td>
<td>No Matches</td>
<td>Expert User</td>
<td>28</td>
<td>21.4%</td>
</tr>
</tbody>
</table>
<section id="classify-traces" class="level3">
<h3 class="anchored" data-anchor-id="classify-traces">Classify Traces</h3>
<p>Once you know where the errors are now you can perform an error analysis to get to the root cause of the errors. My favorite way is to look at examples of each type of error and classify them by hand. I recommend using a spreadsheet for this. For example, a trace for Order tracking where there are no matches for new users might look like this:</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example Trace
</div>
</div>
<div class="callout-body-container callout-body">
<p>In this example trace, the user provides an invalid order number. The AI correctly identifies that the order number is invalid but provides an unhelpful response. If you are not familiar with logging LLM traces, refer to my <a href="https://hamel.dev/blog/posts/evals/">previous post on evals</a>.</p>
<p>Note that this trace is formatted for readability.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb2-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb2-2"> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"user_input"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Where's my order #ABC123?"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb2-3"> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"function_calls"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb2-4">   <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb2-5">     <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"search_order_database"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb2-6">     <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"args"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"order_id"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ABC123"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb2-7">     <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"result"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb2-8">       <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"status"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"not_found"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb2-9">       <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"valid_patterns"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"XXX-XXX-XXX"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb2-10">     <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb2-11">   <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb2-12">   <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb2-13">     <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"retrieve_context"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb2-14">     <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"result"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb2-15">       <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"relevant_docs"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb2-16">         <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Order numbers follow format XXX-XXX-XXX"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb2-17">         <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"New users should check confirmation email"</span></span>
<span id="cb2-18">       <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb2-19">     <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb2-20">   <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb2-21"> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb2-22"> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"llm_intermediate_steps"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb2-23">   <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb2-24">     <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"thought"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"User is new and order format is invalid"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb2-25">     <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"action"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Generate help message with format info"</span></span>
<span id="cb2-26">   <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb2-27"> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb2-28"> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"final_response"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"I cannot find that order #. Please check the number and try again."</span></span>
<span id="cb2-29"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
</div>
</div>
<p>In this case, you might classify the error as: <code>Missing User Education</code>. The system retrieved new user context and format information but failed to include it in the response, which suggests we could improve our prompt. After you have classified a number of errors, you can calculate the distribution of errors by root cause. That might look like this:</p>
<p><strong>Root Cause Distribution (20 Failed Interactions)</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Root Cause</th>
<th>Count</th>
<th>Percentage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Missing User Education</td>
<td>8</td>
<td>40%</td>
</tr>
<tr class="even">
<td>Authentication/Access Issues</td>
<td>6</td>
<td>30%</td>
</tr>
<tr class="odd">
<td>Poor Context Handling</td>
<td>4</td>
<td>20%</td>
</tr>
<tr class="even">
<td>Inadequate Error Messages</td>
<td>2</td>
<td>10%</td>
</tr>
</tbody>
</table>
<p>Now you know where to focus your efforts. This doesn’t have to take an extraordinary amount of time. You can get quite far in just 15 minutes. Also, you can use a LLM to help you with this classification, but that is beyond the scope of this post (you can use a LLM to help you do anything in this post, as long as you have a process to verify the results).</p>
</section>
<section id="an-interactive-walkthrough-of-error-analysis" class="level3">
<h3 class="anchored" data-anchor-id="an-interactive-walkthrough-of-error-analysis">An Interactive Walkthrough of Error Analysis</h3>
<p>Error analysis has been around in Machine Learning for quite some time. This video by Andrew Ng does a great job of walking through the process interactively:</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/JoAxZsdw_3w?si=R4P1awrDBIYDhJS9" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
<section id="fix-your-errors-again" class="level3">
<h3 class="anchored" data-anchor-id="fix-your-errors-again">Fix Your Errors, Again</h3>
<p>Now that you have a sense of the errors, you can go back and fix them again. Go back to step 3 and iterate until you are satisfied. Note that every time you fix an error, you should try to write a test case for it. Sometimes, this can be an assertion in your test suite, but other times you may need to create a more “specialized” LLM judge for these failures. We’ll talk about this next.</p>
</section>
<section id="doing-this-well-requires-data-literacy" class="level3">
<h3 class="anchored" data-anchor-id="doing-this-well-requires-data-literacy">Doing this well requires data literacy</h3>
<p>Investigating your data is much harder in practice than I made it look in this post. It requires a nose for data that only comes from practice. It also helps to have some basic familiarity with statistics and data analysis tools. My favorite post on data literacy is <a href="https://jxnl.co/writing/2024/06/02/10-ways-to-be-data-illiterate-and-how-to-avoid-them/">this one</a> by Jason Liu and Eugene Yan.</p>
</section>
</section>
<section id="step-7-create-more-specialized-llm-judges-if-needed" class="level2">
<h2 class="anchored" data-anchor-id="step-7-create-more-specialized-llm-judges-if-needed">Step 7: Create More Specialized LLM Judges (if needed)</h2>
<p>Now that you have a sense for where the problems in your AI are, you can decide where and if to invest in more targeted LLM judges. For example, if you find that the AI has trouble with citing sources correctly, you can created a targeted eval for that. You might not even need a LLM judge for some errors (and use a code-based assertion instead).</p>
<p>The key takeaway is don’t jump directly to using specialized LLM judges until you have gone through this critique shadowing process. This will help you rationalize where to invest your time.</p>
</section>
<section id="recap-of-critique-shadowing" class="level2">
<h2 class="anchored" data-anchor-id="recap-of-critique-shadowing">Recap of Critique Shadowing</h2>
<p>Using an LLM as a judge can streamline your AI evaluation process if approached correctly. Here’s a visual illustration of the process (there is a description of the process below the diagram as well):</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph TB
    A[Start] --&gt; B[1 Find Principal Domain Expert]
    B --&gt; C[2 Create Dataset]
    C --&gt; D[3 Domain Expert Reviews Data]
    D --&gt; E{Found Errors?}
    E --&gt;|Yes| F[4 Fix Errors]
    F --&gt; D
    E --&gt;|No| G[5 Build LLM Judge]
    G --&gt; H[Test Against Domain Expert]
    H --&gt; I{Acceptable Agreement?}
    I --&gt;|No| J[Refine Prompt]
    J --&gt; H
    I --&gt;|Yes| K[6 Perform Error Analysis]
    K --&gt; L{Critical Issues Found?}
    L --&gt;|Yes| M[7 Fix Issues &amp; Create Specialized Judges]
    M --&gt; D
    L --&gt;|No| N[Material Changes or Periodic Review?]
    N --&gt;|Yes| C
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>The Critique Shadowing process is iterative, with feedback loops. Let’s list out the steps:</p>
<ol type="1">
<li>Find Principal Domain Expert</li>
<li>Create A Dataset
<ul>
<li>Generate diverse examples covering your use cases</li>
<li>Include real or synthetic user interactions</li>
</ul></li>
<li>Domain Expert Reviews Data
<ul>
<li>Expert makes pass/fail judgments</li>
<li>Expert writes detailed critiques explaining their reasoning</li>
</ul></li>
<li>Fix Errors (if found)
<ul>
<li>Address any issues discovered during review</li>
<li>Return to expert review to verify fixes</li>
<li>Go back to step 3 if errors are found</li>
</ul></li>
<li>Build LLM Judge
<ul>
<li>Create prompt using expert examples</li>
<li>Test against expert judgments</li>
<li>Refine prompt until agreement is satisfactory</li>
</ul></li>
<li>Perform Error Analysis
<ul>
<li>Calculate error rates across different dimensions</li>
<li>Identify patterns and root causes</li>
<li>Fix errors and go back to step 3 if needed</li>
<li>Create specialized judges as needed</li>
</ul></li>
</ol>
<p>This process never truly ends. It repeats periodically or when material changes occur.</p>
<section id="its-not-the-judge-that-created-value-afterall" class="level3">
<h3 class="anchored" data-anchor-id="its-not-the-judge-that-created-value-afterall">It’s Not The Judge That Created Value, Afterall</h3>
<p>The real value of this process is looking at your data and doing careful analysis. Even though an AI judge can be a helpful tool, going through this process is what drives results. I would go as far as saying that creating a LLM judge is a nice “hack” I use to trick people into carefully looking at their data!</p>
<p>That’s right. The real business value comes from looking at your data. But hey, potato, potahto.</p>
</section>
<section id="do-you-really-need-this" class="level3">
<h3 class="anchored" data-anchor-id="do-you-really-need-this">Do You Really Need This?</h3>
<p>Phew, this seems like a lot of work! Do you really need this? Well, it depends. There are cases where you can take a shortcut through this process. For example, let’s say:</p>
<ol type="1">
<li>You are an independent developer who is also a domain expert.</li>
<li>You are working with test data that already available. (Tweets, etc.)</li>
<li>Looking at data is not costly (etc. you can manually look at enough data in a few hours)</li>
</ol>
<p>In this scenario, you can jump directly to something that looks like step 3 and start looking at data right away. Also, since it’s not that costly to look at data, it’s probably fine to just do error analysis without a judge (at least initially). You can incorporate what you learn directly back into your primary model right away. This example is not exhaustive, but gives you an idea of how you can adapt this process to your needs.</p>
<p>However, you can never completely eliminate looking at your data! This is precisely the step that most people skip. Don’t be that person.</p>
</section>
</section>
<section id="faq" class="level2">
<h2 class="anchored" data-anchor-id="faq">FAQ</h2>
<p>I received <a href="https://x.com/HamelHusain/status/1850256204553244713">a lot of questions</a> about this topic. Here are answers to the most common ones:</p>
<section id="if-i-have-a-good-judge-llm-isnt-that-also-the-llm-id-also-want-to-use" class="level3">
<h3 class="anchored" data-anchor-id="if-i-have-a-good-judge-llm-isnt-that-also-the-llm-id-also-want-to-use">If I have a good judge LLM, isn’t that also the LLM I’d also want to use?</h3>
<p>Effective judges often use larger models or more compute (via longer prompts, chain-of-thought, etc.) than the systems they evaluate.</p>
<p>However, If the cost of the most powerful LLM is not prohibitive, and latency is not an issue, then you might want to consider where you invest your efforts differently. In this case, it might make sense to put more effort towards specialist LLM judges, <a href="https://hamel.dev/blog/posts/evals/#the-types-of-evaluation">code-based assertions, and A/B testing</a>. However, you should still go through the process of looking at data and critiquing the LLM’s output before you adopt specialized judges.</p>
</section>
<section id="do-you-recommend-fine-tuning-judges" class="level3">
<h3 class="anchored" data-anchor-id="do-you-recommend-fine-tuning-judges">Do you recommend fine-tuning judges?</h3>
<p>I prefer not to fine-tune LLM judges. I’d rather spend the effort fine-tuning the actual LLM instead. However, fine-tuning guardrails or other specialized judges can be useful (especially if they are small classifiers).</p>
<p>As a related note, you can leverage a LLM judge to curate and transform data for fine-tuning your primary model. For example, you can use the judge to:</p>
<ul>
<li>Eliminate bad examples for fine-tuning.</li>
<li>Generate higher quality outputs (by referencing the critique).</li>
<li>Simulate high quality chain-of-thought with critiques.</li>
</ul>
<p>Using a LLM judge for enhancing fine-tuning data is even more compelling when you are trying to <a href="https://openai.com/index/api-model-distillation/">distill a large LLM into a smaller one</a>. The details of fine-tuning are beyond the scope of this post. If you are interested in learning more, see <a href="https://parlance-labs.com/education/#fine-tuning">these resources</a>.</p>
</section>
<section id="whats-wrong-with-off-the-shelf-llm-judges" class="level3">
<h3 class="anchored" data-anchor-id="whats-wrong-with-off-the-shelf-llm-judges">What’s wrong with off-the-shelf LLM judges?</h3>
<p>Nothing is strictly wrong with them. It’s just that many people are led astray by them. If you are disciplined you can apply them to your data and see if they are telling you something valuable. However, I’ve found that these tend to cause more confusion than value.</p>
</section>
<section id="how-do-you-evaluate-the-llm-judge" class="level3">
<h3 class="anchored" data-anchor-id="how-do-you-evaluate-the-llm-judge">How Do you evaluate the LLM judge?</h3>
<p>You will collect metrics on the agreement between the domain expert and the LLM judge. This tells you how much you can trust the judge and in what scenarios. Your domain expert doesn’t have to inspect every single example, you just need a representative sample so you can have reliable statistics.</p>
</section>
<section id="what-model-do-you-use-for-the-llm-judge" class="level3">
<h3 class="anchored" data-anchor-id="what-model-do-you-use-for-the-llm-judge">What model do you use for the LLM judge?</h3>
<p>For the kind of judge articulated in this blog post, I like to use the most powerful model I can afford in my cost/latency budget. This budget might be different than my primary model, depending on the number of examples I need to score. This can vary significantly according to the use case.</p>
</section>
<section id="what-about-guardrails" class="level3">
<h3 class="anchored" data-anchor-id="what-about-guardrails">What about guardrails?</h3>
<p>Guardrails are a separate but related topic. They are a way to prevent the LLM from saying/doing something harmful or inappropriate. This blog post focuses on helping you create a judge that’s aligned with business goals, especially when starting out.</p>
</section>
<section id="im-using-llm-as-a-judge-and-getting-tremendous-value-but-i-didnt-follow-this-approach." class="level3">
<h3 class="anchored" data-anchor-id="im-using-llm-as-a-judge-and-getting-tremendous-value-but-i-didnt-follow-this-approach.">I’m using LLM as a judge, and getting tremendous value but I didn’t follow this approach.</h3>
<p>I believe you. This blog post is not the only way to use a LLM as a judge. In fact, I’ve seen people use a LLM as a judge in all sorts of creative ways, which include ranking, classification, model selection and so-on. I’m focused on an approach that works well when you are getting started, and avoids the pitfalls of confusing metric sprawl. However, the general process of looking at the data is still central no matter what kind of judge you are building.</p>
</section>
<section id="how-do-you-choose-between-traditional-ml-techniques-llm-as-a-judge-and-human-annotations" class="level3">
<h3 class="anchored" data-anchor-id="how-do-you-choose-between-traditional-ml-techniques-llm-as-a-judge-and-human-annotations">How do you choose between traditional ML techniques, LLM-as-a-judge and human annotations?</h3>
<p>The answer to this (and many other questions) is: do the simplest thing that works. And simple doesn’t always mean traditional ML techniques. Depending on your situation, it might be easier to use a LLM API as a classifier than to train a model and deploy it.</p>
</section>
<section id="can-you-make-judges-from-small-models" class="level3">
<h3 class="anchored" data-anchor-id="can-you-make-judges-from-small-models">Can you make judges from small models?</h3>
<p>Yes, potentially. I’ve only used the larger models for judges. You have to base the answer to this question on the data (i.e.&nbsp;the agreement with the domain expert).</p>
</section>
<section id="how-do-you-ensure-consistency-when-updating-your-llm-model" class="level3">
<h3 class="anchored" data-anchor-id="how-do-you-ensure-consistency-when-updating-your-llm-model">How do you ensure consistency when updating your LLM model?</h3>
<p>You have to go through the process again and measure the results.</p>
</section>
<section id="how-do-you-phase-out-human-in-the-loop-to-scale-this" class="level3">
<h3 class="anchored" data-anchor-id="how-do-you-phase-out-human-in-the-loop-to-scale-this">How do you phase out human in the loop to scale this?</h3>
<p>You don’t need a domain expert to grade every single example. You just need a representative sample. I don’t think you can eliminate humans completely, because the LLM still needs to be aligned to something, and that something is usually a human. As your evaluation system gets better, it naturally reduces the amount of human effort required.</p>
</section>
</section>
<section id="resources" class="level2">
<h2 class="anchored" data-anchor-id="resources">Resources</h2>
<p>These are some of the resources I recommend to learn more on this topic:</p>
<ul>
<li><a href="https://hamel.dev/evals">Your AI Product Needs Evals</a>: This blog post is the predecessor to this one, and provides a high-level overview of evals for LLM based products.</li>
<li><a href="https://arxiv.org/abs/2404.12272">Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences</a>: This paper by Shreya Shankar et al provides a good overview of the challenges of evaluating LLMs, and the importance of following a good process.</li>
<li><a href="https://aligneval.com/">Align Eval</a>: Eugene Yan’s new tool that helps you build LLM judges by following a good process. Also read his accompanying <a href="https://eugeneyan.com/writing/aligneval/">blog post</a>.</li>
<li><a href="https://eugeneyan.com/writing/llm-evaluators/">Evaluating the Effectiveness of LLM-Evaluators (aka LLM-as-Judge)</a>: This is a great survey of different use-cases and approaches for LLM judges, also written by Eugene Yan.</li>
<li><a href="https://www.databricks.com/blog/enhancing-llm-as-a-judge-with-grading-notes">Enhancing LLM-As-A-Judge with Grading Notes</a> by Yi Liu et al.&nbsp;Describes an approach very similar to the one in this blog post, and provides another point of view regarding the utility of writing critiques (they call them grading notes).</li>
<li><a href="https://cookbook.openai.com/examples/custom-llm-as-a-judge">Custom LLM as a Judge to Detect Hallucinations with Braintrust</a> by Ankur Goyal and Shaymal Anadkt provide an end-to-end example of building a LLM judge, and for the use case highlighted, authors found that a classification approach was more reliable than numeric ratings (consistent with this blog post).</li>
<li><a href="https://arize.com/blog/techniques-for-self-improving-llm-evals/">Techniques for Self-Improving LLM Evals</a> by Eric Xiao from Arize shows a nice approach to building LLM Evals with some additional tools that are worth checking out.</li>
<li><a href="https://blog.langchain.dev/dosu-langsmith-no-prompt-eng/">How Dosu Used LangSmith to Achieve a 30% Accuracy Improvement with No Prompt Engineering</a> by Langchain shows a nice approach to building LLM prompts with dynamic examples. The idea is simple, but effective. I’ve been adapting it for my own use cases, including LLM judges. Here is a <a href="https://www.youtube.com/watch?v=tHZtq_pJSGo">video walkthrough</a> of the approach.</li>
<li><a href="https://applied-llms.org/">What We’ve Learned From A Year of Building with LLMs</a>: is a great overview of many practical aspects of building with LLMs, with an emphasis on the importance of evaluation.</li>
</ul>
</section>
<section id="stay-connected" class="level2">
<h2 class="anchored" data-anchor-id="stay-connected">Stay Connected</h2>
<p>I’m continuously learning about LLMs, and enjoy sharing my findings. If you’re interested in this journey, consider subscribing.</p>
<p>What to expect:</p>
<ul>
<li>Occasional emails with my latest insights on LLMs</li>
<li>Early access to new content</li>
<li>No spam, just honest thoughts and discoveries</li>
</ul>
<script async="" data-uid="6379a28bdb" src="https://hamel.ck.page/6379a28bdb/index.js"></script>


</section>

 ]]></description>
  <category>LLMs</category>
  <category>evals</category>
  <guid>https://hamel.dev/blog/posts/llm-judge/</guid>
  <pubDate>Tue, 29 Oct 2024 07:00:00 GMT</pubDate>
  <media:content url="https://hamel.dev/blog/posts/llm-judge/images/cover_img.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Concurrency Foundations For FastHTML</title>
  <link>https://hamel.dev/</link>
  <description>Concurreny fundamentals for FastHTML
</description>
  <category>FastHTML</category>
  <guid>https://hamel.dev/</guid>
  <pubDate>Thu, 10 Oct 2024 07:00:00 GMT</pubDate>
</item>
<item>
  <title>An Open Course on LLMs, Led by Practitioners</title>
  <dc:creator>Hamel Husain</dc:creator>
  <link>https://hamel.dev/blog/posts/course/</link>
  <description><![CDATA[ 




<p>Today, we are releasing <a href="https://parlance-labs.com/education/">Mastering LLMs</a>, a set of workshops and talks from practitioners on topics like evals, retrieval-augmented-generation (RAG), fine-tuning and more. This course is unique because it is:</p>
<ul>
<li>Taught by 25+ industry veterans who are experts in information retrieval, machine learning, recommendation systems, MLOps and data science. We discuss how this prior art can be applied to LLMs to give you a meaningful advantage.</li>
<li>Focused on applied topics that are relevant to people building AI products.</li>
<li><ins>
<strong>Free and open to everyone</strong>
</ins>
.</li>
</ul>
<p>We have organized and annotated the talks from our popular paid course.<sup>1</sup> This is a survey course for technical ICs (including engineers and data scientists) who have some experience with LLMs and need guidance on how to improve AI products.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://parlance-labs.com/education/" target="_blank"><img src="https://hamel.dev/blog/posts/course/course.png" class="img-fluid figure-img" alt="Speakers include Jeremy Howard, Sophia Yang, Simon Willison, JJ Allaire, Wing Lian, Mark Saroufim, Jane Xu, Jason Liu, Emmanuel Ameisen, Hailey Schoelkopf, Johno Whitaker, Zach Mueller, John Berryman, Ben Clavié, Abhishek Thakur, Kyle Corbitt, Ankur Goyal, Freddy Boulton, Jo Bergum, Eugene Yan, Shreya Shankar, Charles Frye, Hamel Husain, Dan Becker and more"></a></p>
<figcaption><em>Speakers include Jeremy Howard, Sophia Yang, Simon Willison, JJ Allaire, Wing Lian, Mark Saroufim, Jane Xu, Jason Liu, Emmanuel Ameisen, Hailey Schoelkopf, Johno Whitaker, Zach Mueller, John Berryman, Ben Clavié, Abhishek Thakur, Kyle Corbitt, Ankur Goyal, Freddy Boulton, Jo Bergum, Eugene Yan, Shreya Shankar, Charles Frye, Hamel Husain, Dan Becker and more</em></figcaption>
</figure>
</div>
<section id="getting-the-most-value-from-the-course" class="level2">
<h2 class="anchored" data-anchor-id="getting-the-most-value-from-the-course">Getting The Most Value From The Course</h2>
<section id="prerequisites" class="level3">
<h3 class="anchored" data-anchor-id="prerequisites">Prerequisites</h3>
<p>The course assumes basic familiarity with LLMs. If you do not have any experience, we recommend watching <a href="https://www.youtube.com/watch?v=jkrNMKz9pWU">A Hacker’s Guide to LLMs</a>. We also recommend the tutorial <a href="https://www.philschmid.de/instruction-tune-llama-2">Instruction Tuning llama2</a> if you are interested in fine-tuning <sup>2</sup>.</p>
</section>
<section id="navigating-the-material" class="level3">
<h3 class="anchored" data-anchor-id="navigating-the-material">Navigating The Material</h3>
<p>The course has over 40 hours of content. To help you navigate this, we provide:</p>
<ul>
<li><strong>Organization by subject area</strong>: evals, RAG, fine-tuning, building applications and prompt engineering.</li>
<li><strong>Chapter summaries:</strong> quickly peruse topics in each talk and skip ahead</li>
<li><strong>Notes, slides, and resources</strong>: these are resources used in the talk, as well as resources to learn more. Many times we have detailed notes as well!</li>
</ul>
<p>To get started, <a href="https://parlance-labs.com/education">navigate to this page</a> and explore topics that interest you. Feel free to skip sections that aren’t relevant to you. We’ve organized the talks within each subject to enhance your learning experience. Be sure to review the chapter summaries, notes, and resources, which are designed to help you focus on the most relevant content and dive deeper when needed. This is a survey course, which means we focus on introducing topics rather than diving deeply into code. To solidify your understanding, we recommend applying what you learn to a personal project.</p>
</section>
<section id="what-students-are-saying" class="level3">
<h3 class="anchored">What Students Are Saying</h3>
<p>Here are some testimonials from students who have taken the course<sup>3</sup>:</p>
<div class="testimonial-section">
<div class="content-block grid gap-4">
<div class="testimonial g-col-12 g-col-md-6">
<p><img src="https://hamel.dev/blog/posts/course/sanyam.jpeg" class="img-fluid"></p>
<section id="sanyam-bhutani-partner-engineer-meta" class="level2">
<h2 class="anchored" data-anchor-id="sanyam-bhutani-partner-engineer-meta"><em>Sanyam Bhutani, Partner Engineer @ Meta</em></h2>
<section id="there-was-a-magical-time-in-2017-when-fastai-changed-the-deep-learning-world.-this-course-does-the-same-by-extending-very-applied-knowledge-to-llms-best-in-class-teachers-teach-you-their-knowledge-with-no-fluff" class="level3">
<h3 class="anchored" data-anchor-id="there-was-a-magical-time-in-2017-when-fastai-changed-the-deep-learning-world.-this-course-does-the-same-by-extending-very-applied-knowledge-to-llms-best-in-class-teachers-teach-you-their-knowledge-with-no-fluff">There was a magical time in 2017 when fastai changed the deep learning world. This course does the same by extending very applied knowledge to LLMs Best in class teachers teach you their knowledge with no fluff</h3>
</section>
</section>
</div>
<div class="testimonial g-col-12 g-col-md-6">
<p><img src="https://hamel.dev/blog/posts/course/laurian.jpeg" class="img-fluid"></p>
<section id="laurian-full-stack-computational-linguist" class="level2">
<h2 class="anchored" data-anchor-id="laurian-full-stack-computational-linguist"><em>Laurian, Full Stack Computational Linguist</em></h2>
<section id="this-course-was-legendary-still-is-and-the-community-on-discord-is-amazing.-ive-been-through-these-lessons-twice-and-i-have-to-do-it-again-as-there-are-so-many-nuances-you-will-get-once-you-actually-have-those-problems-on-your-own-deployment." class="level3">
<h3 class="anchored" data-anchor-id="this-course-was-legendary-still-is-and-the-community-on-discord-is-amazing.-ive-been-through-these-lessons-twice-and-i-have-to-do-it-again-as-there-are-so-many-nuances-you-will-get-once-you-actually-have-those-problems-on-your-own-deployment.">This course was legendary, still is, and the community on Discord is amazing. I’ve been through these lessons twice and I have to do it again as there are so many nuances you will get once you actually have those problems on your own deployment.!</h3>
</section>
</section>
</div>
<div class="testimonial g-col-12 g-col-md-6">
<p><img src="https://hamel.dev/blog/posts/course/andre.png" class="img-fluid"></p>
<section id="andre-cto" class="level2">
<h2 class="anchored" data-anchor-id="andre-cto"><em>Andre, CTO</em></h2>
<section id="amazing-an-opinionated-view-of-llms-from-tools-to-fine-tuning.-excellent-speakers-giving-some-of-the-best-lectures-and-advice-out-there-a-lot-of-real-life-experiences-and-tips-you-cant-find-anywhere-on-the-web-packed-into-this-amazing-courseworkshopconference-thanks-dan-and-hamel-for-making-this-happen" class="level3">
<h3 class="anchored" data-anchor-id="amazing-an-opinionated-view-of-llms-from-tools-to-fine-tuning.-excellent-speakers-giving-some-of-the-best-lectures-and-advice-out-there-a-lot-of-real-life-experiences-and-tips-you-cant-find-anywhere-on-the-web-packed-into-this-amazing-courseworkshopconference-thanks-dan-and-hamel-for-making-this-happen">Amazing! An opinionated view of LLMs, from tools to fine-tuning. Excellent speakers, giving some of the best lectures and advice out there! A lot of real-life experiences and tips you can’t find anywhere on the web packed into this amazing course/workshop/conference! Thanks Dan and Hamel for making this happen!</h3>
</section>
</section>
</div>
<div class="testimonial g-col-12 g-col-md-6">
<p><img src="https://hamel.dev/blog/posts/course/marcus.png" class="img-fluid"></p>
<section id="marcus-software-engineer" class="level2">
<h2 class="anchored" data-anchor-id="marcus-software-engineer"><em>Marcus, Software Engineer</em></h2>
<section id="the-mastering-llms-conference-answered-several-key-questions-i-had-about-when-to-fine-tune-base-models-building-evaluation-suits-and-when-to-use-rag.-the-sessions-provided-a-valuable-overview-of-the-technical-challenges-and-considerations-involved-in-building-and-deploying-custom-llms." class="level3">
<h3 class="anchored" data-anchor-id="the-mastering-llms-conference-answered-several-key-questions-i-had-about-when-to-fine-tune-base-models-building-evaluation-suits-and-when-to-use-rag.-the-sessions-provided-a-valuable-overview-of-the-technical-challenges-and-considerations-involved-in-building-and-deploying-custom-llms.">The Mastering LLMs conference answered several key questions I had about when to fine-tune base models, building evaluation suits and when to use RAG. The sessions provided a valuable overview of the technical challenges and considerations involved in building and deploying custom LLMs.</h3>
</section>
</section>
</div>
<div class="testimonial g-col-12 g-col-md-6">
<p><img src="https://hamel.dev/blog/posts/course/ali.png" class="img-fluid"></p>
<section id="ali-principal-founder-scty" class="level2">
<h2 class="anchored" data-anchor-id="ali-principal-founder-scty"><em>Ali, Principal &amp; Founder, SCTY</em></h2>
<section id="the-course-that-became-a-conference-filled-with-a-lineup-of-renowned-practitioners-whose-expertise-and-contributions-to-the-field-was-only-exceeded-by-their-generosity-of-spirit." class="level3">
<h3 class="anchored" data-anchor-id="the-course-that-became-a-conference-filled-with-a-lineup-of-renowned-practitioners-whose-expertise-and-contributions-to-the-field-was-only-exceeded-by-their-generosity-of-spirit.">The course that became a conference, filled with a lineup of renowned practitioners whose expertise (and contributions to the field) was only exceeded by their generosity of spirit.</h3>
</section>
</section>
</div>
<div class="testimonial g-col-12 g-col-md-6">
<p><img src="https://hamel.dev/blog/posts/course/lukas.png" class="img-fluid"></p>
<section id="lukas-software-engineer" class="level2">
<h2 class="anchored" data-anchor-id="lukas-software-engineer"><em>Lukas, Software Engineer</em></h2>
<section id="the-sheer-amount-of-diverse-speakers-that-cover-the-same-topics-from-different-approaches-both-praising-andor-degrading-certain-workflows-makes-this-extremely-valuable.-especially-when-a-lot-of-information-online-is-produced-by-those-who-are-building-a-commercial-product-behind-naturally-is-biased-towards-a-fine-tune-a-rag-an-open-source-llm-an-open-ai-llm-etc.-it-is-rather-extra-ordinary-to-have-a-variety-of-opinions-packed-like-this.-thank-you" class="level3">
<h3 class="anchored" data-anchor-id="the-sheer-amount-of-diverse-speakers-that-cover-the-same-topics-from-different-approaches-both-praising-andor-degrading-certain-workflows-makes-this-extremely-valuable.-especially-when-a-lot-of-information-online-is-produced-by-those-who-are-building-a-commercial-product-behind-naturally-is-biased-towards-a-fine-tune-a-rag-an-open-source-llm-an-open-ai-llm-etc.-it-is-rather-extra-ordinary-to-have-a-variety-of-opinions-packed-like-this.-thank-you">The sheer amount of diverse speakers that cover the same topics from different approaches, both praising and/or degrading certain workflows makes this extremely valuable. Especially when a lot of information online, is produced by those, who are building a commercial product behind, naturally is biased towards a fine tune, a RAG, an open source LLM, an open ai LLM etc. It is rather extra ordinary to have a variety of opinions packed like this. Thank you!</h3>
</section>
</section>
</div>
</div>
<p><br></p>
<center>
<a href="https://parlance-labs.com/education" target="_blank">Course Website</a>
</center>
</div>
</section>
</section>
<section id="stay-connected" class="level2">
<h2 class="anchored" data-anchor-id="stay-connected">Stay Connected</h2>
<p>I’m continuously learning about LLMs, and enjoy sharing my findings and thoughts. If you’re interested in this journey, consider subscribing.</p>
<p>What to expect:</p>
<ul>
<li>Occasional emails with my latest insights on LLMs</li>
<li>Early access to new content</li>
<li>No spam, just honest thoughts and discoveries</li>
</ul>
<script async="" data-uid="6379a28bdb" src="https://hamel.ck.page/6379a28bdb/index.js"></script>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>https://maven.com/parlance-labs/fine-tuning. We had more than 2,000 students in our first cohort. The students who paid for the original course had early access to the material, office hours, generous compute credits, and a lively Discord community.↩︎</p></li>
<li id="fn2"><p>We find that instruction tuning a model to be a very useful educational experience even if you never intend to fine-tune, because it familiarizes you with topics such as (1) working with open weights models (2) generating synthetic data (3) managing prompts (4) fine-tuning (5) and generating predictions.↩︎</p></li>
<li id="fn3"><p>These testimonials are taken from https://maven.com/parlance-labs/fine-tuning.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>llms</category>
  <category>courses</category>
  <guid>https://hamel.dev/blog/posts/course/</guid>
  <pubDate>Mon, 29 Jul 2024 07:00:00 GMT</pubDate>
  <media:content url="https://hamel.dev/blog/posts/course/course.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>What We’ve Learned From A Year of Building with LLMs</title>
  <link>https://hamel.dev/</link>
  <description>A practical guide to building successful LLM products.
</description>
  <category>LLMs</category>
  <guid>https://hamel.dev/</guid>
  <pubDate>Sat, 01 Jun 2024 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Debugging AI With Adversarial Validation</title>
  <dc:creator>Hamel Husain</dc:creator>
  <link>https://hamel.dev/blog/posts/drift/</link>
  <description><![CDATA[ 




<p>For years, I’ve relied on a straightforward method to identify sudden changes in model inputs or training data, known as “drift.” This method, Adversarial Validation<sup>1</sup>, is both simple and effective. The best part? <strong>It requires no complex tools or infrastructure.</strong></p>
<p>Examples where drift can cause bugs in your AI:</p>
<ol type="1">
<li>Your data for <a href="../../../blog/posts/evals/index.html">evaluations</a> are materially different from the inputs your model receives in production, causing your evaluations to be misleading.</li>
<li>Updates to prompts, functions, RAG, and similar elements aren’t incorporated into your fine-tuning or training data, leading to unexpected model behavior in production.</li>
</ol>
<p>No matter how careful you are, bugs can still slip through the cracks. A a high ROI activity is to routinely audit all your AI/ML projects for drift.</p>
<section id="how-it-works" class="level2">
<h2 class="anchored" data-anchor-id="how-it-works">How It Works</h2>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Uncool Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>This method is so simple that it might seem uncool. You aren’t going to impress any data scientists. Despite this, it’s too valuable to ignore.</p>
</div>
</div>
<p>This slide from <a href="https://www.youtube.com/watch?v=GHk5HMW4XMA">my talk on MLOps tools</a> explains the technique behind Adversarial Validation<sup>2</sup>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/drift/images/drift_tfx.png" class="img-fluid figure-img"></p>
<figcaption>Slide</figcaption>
</figure>
</div>
<p>The process is as follows:</p>
<ol type="1">
<li>Collect two datasets to compare. For example:
<ul>
<li>Training data from two different fine-tuning runs</li>
<li>Training data vs.&nbsp;evaluation data</li>
<li>Training data vs.&nbsp;production data (organized into the same format)</li>
<li>Data from two different time-periods</li>
</ul></li>
<li>Create features from the dataset. A basic example that creates features from <a href="https://platform.openai.com/tokenizer">tokens</a> is illustrated <a href="https://github.com/hamelsmu/ft-drift/blob/main/ft_drift/model.py">here</a>.<sup>3</sup></li>
<li>Give dataset #1 a label of 0 and dataset #2 a label of 1.</li>
<li>Fit a binary classifier (random forest, logistic regression, etc) to discriminate between the two datasets.</li>
<li>If the classifier demonstrates sufficient predictive power (ex: AUC &gt;=0.60), we know there is drift.</li>
<li>If you used an interpretable model (like logistic regression, random forest, etc.), you can inspect feature importance metrics to understand the root cause of the drift. If you use a more complex model (like a neural network), you can use <a href="https://shap.readthedocs.io/en/latest/">SHAP values</a> or other methods to understand what is causing the drift. I recommend starting with a simple interpretable model.</li>
</ol>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>If this process doesn’t detect drift, it doesn’t mean there isn’t drift. It just means that we couldn’t detect it with the model and features we used.</p>
</div>
</div>
</section>
<section id="minimal-example-ft_drift" class="level2">
<h2 class="anchored" data-anchor-id="minimal-example-ft_drift">Minimal Example: <code>ft_drift</code></h2>
<p>I work with lots of folks who are fine-tuning models using the OpenAI API. I’ve created a small CLI tool, <a href="https://github.com/hamelsmu/ft-drift/"><code>ft_drift</code></a>, that detects drift between two <a href="https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset">multi-turn chat formatted</a> jsonl files. Currently, <code>ft_drift</code> only detects drift in prompt templates, schemas and other token-based drift (as opposed to semantic drift). However, this is a good starting point to understand the general concept of adversarial validation. Here is a demo of this tool at work:</p>
<p><img src="https://hamel.dev/blog/posts/drift/images/drift_cli.gif" class="img-fluid"></p>
<p>The demo is from a real-world example where an unintentional change in a prompt template caused unexpected behavior in a model. The demo shows the tool detecting a difference between two datasets, <code>file_a.jsonl</code> and <code>file_b.jsonl</code>. Afterward, a table of important tokens that account for the drift are shown, such as <code>END-UI-FORMAT</code>, <code>UI-FORMAT</code>, etc. We were able to apply the tool and quickly find the root cause of the issue. The modeling code is embarrassingly simple and located at <a href="https://github.com/hamelsmu/ft-drift/blob/main/ft_drift/model.py"><code>ft_drift/model.py</code></a>. The point is you don’t need sophisticated techniques to get started. You can then take this approach further by adding embeddings to your features to also detect semantic drift. Similarly, you could add additional features by hand like the number of conversation turns, length of messages, etc.</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>I first learned of this technique in 2016 from <a href="https://fastml.com/adversarial-validation-part-two/">this blog post</a> by Zygmunt Zając. Throughout the years, I’ve seen this technique used in a variety of contexts, sometimes with different names.↩︎</p></li>
<li id="fn2"><p>This slide uses the word “skew” which is interchangeable with “drift” in this context.↩︎</p></li>
<li id="fn3"><p>For classic ML, if you are already training a model on this data, you likely have a feature engineering pipeline that you can reuse.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>LLMs</category>
  <guid>https://hamel.dev/blog/posts/drift/</guid>
  <pubDate>Fri, 12 Apr 2024 07:00:00 GMT</pubDate>
  <media:content url="https://hamel.dev/blog/posts/drift/images/drift_cover.png" medium="image" type="image/png" height="75" width="144"/>
</item>
<item>
  <title>Your AI Product Needs Evals</title>
  <dc:creator>Hamel Husain</dc:creator>
  <link>https://hamel.dev/blog/posts/evals/</link>
  <description><![CDATA[ 




<section id="motivation" class="level2">
<h2 class="anchored" data-anchor-id="motivation">Motivation</h2>
<p>I started working with language models five years ago when I led the team that created <a href="https://github.com/github/CodeSearchNet">CodeSearchNet</a>, a precursor to GitHub CoPilot. Since then, I’ve seen many successful and unsuccessful approaches to building LLM products. I’ve found that unsuccessful products almost always share a common root cause: <strong>a failure to create robust evaluation systems.</strong></p>
<p>I’m currently an independent consultant who helps companies build domain-specific AI products. I hope companies can save thousands of dollars in consulting fees by reading this post carefully. As much as I love making money, I hate seeing folks make the same mistake repeatedly.</p>
<p>This post outlines my thoughts on building evaluation systems for LLMs-powered AI products.</p>
</section>
<section id="iterating-quickly-success" class="level1">
<h1>Iterating Quickly == Success</h1>
<p>Like software engineering, success with AI hinges on how fast you can iterate. You must have processes and tools for:</p>
<ol type="1">
<li>Evaluating quality (ex: tests).</li>
<li>Debugging issues (ex: logging &amp; inspecting data).</li>
<li>Changing the behavior or the system (prompt eng, fine-tuning, writing code)</li>
</ol>
<p><strong>Many people focus exclusively on #3 above, which prevents them from improving their LLM products beyond a demo.</strong><sup>1</sup> Doing all three activities well creates a virtuous cycle differentiating great from mediocre AI products (see the diagram below for a visualization of this cycle).</p>
<p>If you streamline your evaluation process, all other activities become easy. This is very similar to how tests in software engineering pay massive dividends in the long term despite requiring up-front investment.</p>
<p>To ground this post in a real-world situation, I’ll walk through a case study in which we built a system for rapid improvement. I’ll primarily focus on evaluation as that is the most critical component.</p>
</section>
<section id="case-study-lucy-a-real-estate-ai-assistant" class="level1">
<h1>Case Study: Lucy, A Real Estate AI Assistant</h1>
<p><a href="https://Rechat.com/">Rechat</a> is a SaaS application that allows real estate professionals to perform various tasks, such as managing contracts, searching for listings, building creative assets, managing appointments, and more. The thesis of Rechat is that you can do everything in one place rather than having to context switch between many different tools.</p>
<p><a href="https://Rechat.com/ai/">Rechat’s AI assistant, Lucy</a>, is a canonical AI product: a conversational interface that obviates the need to click, type, and navigate the software. During Lucy’s beginning stages, rapid progress was made with prompt engineering. However, as Lucy’s surface area expanded, the performance of the AI plateaued. Symptoms of this were:</p>
<ol type="1">
<li>Addressing one failure mode led to the emergence of others, resembling a game of whack-a-mole.</li>
<li>There was limited visibility into the AI system’s effectiveness across tasks beyond vibe checks.</li>
<li>Prompts expanded into long and unwieldy forms, attempting to cover numerous edge cases and examples.</li>
</ol>
<section id="problem-how-to-systematically-improve-the-ai" class="level2">
<h2 class="anchored" data-anchor-id="problem-how-to-systematically-improve-the-ai">Problem: How To Systematically Improve The AI?</h2>
<p>To break through this plateau, we created a systematic approach to improving Lucy <strong>centered on evaluation.</strong> Our approach is illustrated by the diagram below.</p>
<p><img src="https://hamel.dev/blog/posts/evals/images/diagram-cover.png" class="img-fluid"></p>
<div class="{callout-note}">
<p>This diagram is a best-faith effort to illustrate my mental model for improving AI systems. In reality, the process is non-linear and can take on many different forms that may or may not look like this diagram.</p>
</div>
<p>I discuss the various components of this system in the context of evaluation below.</p>
</section>
</section>
<section id="the-types-of-evaluation" class="level1">
<h1>The Types Of Evaluation</h1>
<p>Rigorous and systematic evaluation is the most important part of the whole system. That is why “Eval and Curation” is highlighted in yellow at the center of the diagram. You should spend most of your time making your evaluation more robust and streamlined.</p>
<p>There are three levels of evaluation to consider:</p>
<ul>
<li>Level 1: Unit Tests</li>
<li>Level 2: Model &amp; Human Eval (this includes debugging)</li>
<li>Level 3: A/B testing</li>
</ul>
<p>The cost of Level 3 &gt; Level 2 &gt; Level 1. This dictates the cadence and manner you execute them. For example, I often run Level 1 evals on every code change, Level 2 on a set cadence and Level 3 only after significant product changes. It’s also helpful to conquer a good portion of your Level 1 tests before you move into model-based tests, as they require more work and time to execute.</p>
<p>There isn’t a strict formula as to when to introduce each level of testing. You want to balance getting user feedback quickly, managing user perception, and the goals of your AI product. This isn’t too dissimilar from the balancing act you must do for products more generally.</p>
<section id="level-1-unit-tests" class="level2">
<h2 class="anchored" data-anchor-id="level-1-unit-tests">Level 1: Unit Tests</h2>
<p>Unit tests for LLMs are assertions (like you would write in <a href="https://docs.pytest.org/en/8.0.x/">pytest</a>). Unlike typical unit tests, you want to organize these assertions for use in places beyond unit tests, such as data cleaning and automatic retries (using the assertion error to course-correct) during model inference. The important part is that these assertions should run fast and cheaply as you develop your application so that you can run them every time your code changes. If you have trouble thinking of assertions, you should critically examine your traces and failure modes. Also, do not shy away from using an LLM to help you brainstorm assertions!</p>
<section id="step-1-write-scoped-tests" class="level3">
<h3 class="anchored" data-anchor-id="step-1-write-scoped-tests">Step 1: Write Scoped Tests</h3>
<p>The most effective way to think about unit tests is to break down the scope of your LLM into features and scenarios. For example, one feature of Lucy is the ability to find real estate listings, which we can break down into scenarios like so:</p>
<p><strong>Feature: Listing Finder</strong></p>
<p>This feature to be tested is a function call that responds to a user request to find a real estate listing. For example, “Please find listings with more than 3 bedrooms less than $2M in San Jose, CA”</p>
<p>The LLM converts this into a query that gets run against the CRM. The assertion then verifies that the expected number of results is returned. In our test suite, we have three user inputs that trigger each of the scenarios below, which then execute corresponding assertions (this is an oversimplified example for illustrative purposes):</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Scenario</th>
<th>Assertions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Only one listing matches user query</td>
<td>len(listing_array) == 1</td>
</tr>
<tr class="even">
<td>Multiple listings match user query</td>
<td>len(listing_array) &gt; 1</td>
</tr>
<tr class="odd">
<td>No listings match user query</td>
<td>len(listing_array) == 0</td>
</tr>
</tbody>
</table>
<p><br> There are also generic tests that aren’t specific to any one feature. For example, here is the code for one such generic test that ensures the UUID is not mentioned in the output:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode javascript code-with-copy"><code class="sourceCode javascript"><span id="cb1-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> noExposedUUID <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> message <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">=&gt;</span> {</span>
<span id="cb1-2">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Remove all text within double curly braces</span></span>
<span id="cb1-3">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> sanitizedComment <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> message<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">comment</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">replace</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\{\{</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*?\}\}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/g</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>)</span>
<span id="cb1-4"></span>
<span id="cb1-5">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Search for exposed UUIDs</span></span>
<span id="cb1-6">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> regexp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[0-9a-f]{8}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[0-9a-f]{4}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[0-9a-f]{4}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[0-9a-f]{4}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[0-9a-f]{12}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/ig</span></span>
<span id="cb1-7">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> matches <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Array</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">from</span>(sanitizedComment<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matchAll</span>(regexp))</span>
<span id="cb1-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">expect</span>(matches<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">length</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Exposed UUIDs'</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">to</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">equal</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Exposed UUIDs found'</span>)</span>
<span id="cb1-9">}</span></code></pre></div>
<div class="acknowledgments">
<p>CRM results returned to the LLM contain fields that shouldn’t be surfaced to the user; such as the UUID associated with an entry. Our LLM prompt tells the LLM to not include UUIDs. We use a simple regex to assert that the LLM response doesn’t include UUIDs.</p>
</div>
<p><strong>Rechat has hundreds of these unit tests. We continuously update them based on new failures we observe in the data as users challenge the AI or the product evolves.</strong> These unit tests are crucial to getting feedback quickly when iterating on your AI system (prompt engineering, improving RAG, etc.). Many people eventually outgrow their unit tests and move on to other levels of evaluation as their product matures, but it is essential not to skip this step!</p>
</section>
<section id="step-2-create-test-cases" class="level3">
<h3 class="anchored" data-anchor-id="step-2-create-test-cases">Step 2: Create Test Cases</h3>
<p>To test these assertions, you must generate test cases or inputs that will trigger all scenarios you wish to test. I often utilize an LLM to generate these inputs synthetically; for example, here is one such prompt Rechat uses to generate synthetic inputs for a feature that creates and retrieves contacts:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode md code-overflow-wrap code-with-copy"><code class="sourceCode markdown"><span id="cb2-1">Write 50 different instructions that a real estate agent can give to his assistant to create contacts on his CRM. The contact details can include name, phone, email, partner name, birthday, tags, company, address and job.</span>
<span id="cb2-2"></span>
<span id="cb2-3">For each of the instructions, you need to generate a second instruction which can be used to look up the created contact.</span>
<span id="cb2-4"></span>
<span id="cb2-5">. The results should be a JSON code block with only one string as the instruction like the following:</span>
<span id="cb2-6"></span>
<span id="cb2-7"></span>
<span id="cb2-8">[</span>
<span id="cb2-9">  ["Create a contact for John (johndoe@apple.com)", </span>
<span id="cb2-10">  "What's the email address of John Smith?"]</span>
<span id="cb2-11">]</span></code></pre></div>
<p>Using the above prompt, we generate test cases like below:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-overflow-wrap code-with-copy"><code class="sourceCode python"><span id="cb3-1">[ </span>
<span id="cb3-2">    [</span>
<span id="cb3-3">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Create a contact for John Smith (johndoe@apple.com) with phone number 123-456-7890 and address 123 Apple St.'</span>, </span>
<span id="cb3-4">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'What</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\'</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">s the email address of John Smith?'</span></span>
<span id="cb3-5">    ],</span>
<span id="cb3-6">    [</span>
<span id="cb3-7">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Add Emily Johnson with phone 987-654-3210, email emilyj@email.com, and company ABC Inc.'</span>, </span>
<span id="cb3-8">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'What</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\'</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">s the phone number for Emily Johnson?'</span></span>
<span id="cb3-9">    ],</span>
<span id="cb3-10">    [</span>
<span id="cb3-11">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Create a contact for Tom Williams with birthday 10/20/1985, company XYZ Ltd, and job title Manager.'</span>, </span>
<span id="cb3-12">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'What</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\'</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">s Tom Williams</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\'</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> job title?'</span></span>
<span id="cb3-13">    ],</span>
<span id="cb3-14">    [</span>
<span id="cb3-15">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Add a contact for Susan Brown with partner name James Brown, and email susanb@email.com.'</span>, </span>
<span id="cb3-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'What</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\'</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">s the partner name of Susan Brown?'</span></span>
<span id="cb3-17">    ],</span>
<span id="cb3-18">…</span>
<span id="cb3-19">]</span></code></pre></div>
<p>For each of these test cases, we execute the first user input to create the contact. We then execute the second query to fetch that contact. If the CRM doesn’t return exactly 1 result then we know there was a problem either creating or fetching the contact. We can also run generic assertions like the one to verify UUIDs are not in the response. You must constantly update these tests as you observe data through human evaluation and debugging. The key is to make these as challenging as possible while representing users’ interactions with the system.</p>
<p>You don’t need to wait for production data to test your system. You can make educated guesses about how users will use your product and generate synthetic data. You can also let a small set of users use your product and let their usage refine your synthetic data generation strategy. One signal you are writing good tests and assertions is when the model struggles to pass them - these failure modes become problems you can solve with techniques like fine-tuning later on.</p>
<p>On a related note, unlike traditional unit tests, you don’t necessarily need a 100% pass rate. Your pass rate is a product decision, depending on the failures you are willing to tolerate.</p>
</section>
<section id="step-3-run-track-your-tests-regularly" class="level3">
<h3 class="anchored" data-anchor-id="step-3-run-track-your-tests-regularly">Step 3: Run &amp; Track Your Tests Regularly</h3>
<p>There are many ways to orchestrate Level 1 tests. Rechat has been leveraging CI infrastructure (e.g., GitHub Actions, GitLab Pipelines, etc.) to execute these tests. However, the tooling for this part of the workflow is nascent and evolving rapidly.</p>
<p>My advice is to orchestrate tests that involve the least friction in your tech stack. In addition to tracking tests, you need to track the results of your tests over time so you can see if you are making progress. If you use CI, you should collect metrics along with versions of your tests/prompts outside your CI system for easy analysis and tracking.</p>
<p>I recommend starting simple and leveraging your existing analytics system to visualize your test results. For example, Rechat uses Metabase to track their LLM test results over time. Below is a screenshot of a dashboard Rechat built with <a href="https://www.metabase.com/">Metabase</a>:</p>
<p><img src="https://hamel.dev/blog/posts/evals/images/metabase.png" class="img-fluid"></p>
<p>This screenshot shows the prevalence of a particular error (shown in yellow) in Lucy before (left) vs after (right) we addressed it.</p>
</section>
</section>
<section id="level-2-human-model-eval" class="level2">
<h2 class="anchored" data-anchor-id="level-2-human-model-eval">Level 2: Human &amp; Model Eval</h2>
<p>After you have built a solid foundation of Level 1 tests, you can move on to other forms of validation that cannot be tested by assertions alone. A prerequisite to performing human and model-based eval is to log your traces.</p>
<section id="logging-traces" class="level3">
<h3 class="anchored" data-anchor-id="logging-traces">Logging Traces</h3>
<p>A trace is a concept that has been around for a while in software engineering and is a log of a sequence of events such as user sessions or a request flow through a distributed system. In other words, tracing is a logical grouping of logs. In the context of LLMs, traces often refer to conversations you have with a LLM. For example, a user message, followed by an AI response, followed by another user message, would be an example of a trace.</p>
<p>There are a growing number of solutions for logging LLM traces.<sup>2</sup> Rechat uses <a href="https://www.langchain.com/langsmith">LangSmith</a>, which logs traces and allows you to view them in a human-readable way with an interactive playground to iterate on prompts. Sometimes, logging your traces requires you to instrument your code. In this case, Rechat was using <a href="https://www.langchain.com/">LangChain</a> which automatically logs trace events to LangSmith for you. Here is a screenshot of what this looks like:</p>
<p><img src="https://hamel.dev/blog/posts/evals/images/langsmith.png" class="img-fluid"></p>
<p>I like LangSmith - it doesn’t require that you use LangChain and is intuitive and easy to use. Searching, filtering, and reading traces are essential features for whatever solution you pick. I’ve found that some tools do not implement these basic functions correctly!</p>
</section>
<section id="looking-at-your-traces" class="level3">
<h3 class="anchored" data-anchor-id="looking-at-your-traces">Looking At Your Traces</h3>
<p><strong>You must remove all friction from the process of looking at data.</strong> This means rendering your traces in domain-specific ways. I’ve often found that it’s <a href="https://hamel.dev/notes/llm/finetuning/04_data_cleaning.html">better to build my own data viewing &amp; labeling tool</a> so I can gather all the information I need onto one screen. In Lucy’s case, we needed to look at many sources of information (trace log, the CRM, etc) to understand what the AI did. This is precisely the type of friction that needs to be eliminated. In Rechat’s case, this meant adding information like:</p>
<ol type="1">
<li>What tool (feature) &amp; scenario was being evaluated.</li>
<li>Whether the trace resulted from a synthetic input or a real user input.</li>
<li>Filters to navigate between different tools and scenario combinations.</li>
<li>Links to the CRM and trace logging system for the current record.</li>
</ol>
<p>I’ve built different variations of this tool for each problem I’ve worked on. Sometimes, I even need to embed another application to see what the user interaction looks like. Below is a screenshot of the tool we built to evaluate Rechat’s traces:</p>
<p><img src="https://hamel.dev/blog/posts/evals/images/langfree.png" class="img-fluid"></p>
<p>Another design choice specific to Lucy is that we noticed that many failures involved small mistakes in the final output of the LLM (format, content, etc). We decided to make the final output editable by a human so that we could curate &amp; fix data for fine-tuning.</p>
<p>These tools can be built with lightweight front-end frameworks like Gradio, Streamlit, Panel, or Shiny in less than a day. The tool shown above was built with Shiny for Python. Furthermore, there are tools like <a href="https://www.lilacml.com/">Lilac</a> which uses AI to search and filter data semantically, which is incredibly handy for finding a set of similar data points while debugging an issue.</p>
<p>I often start by labeling examples as good or bad. I’ve found that assigning scores or more granular ratings is more onerous to manage than binary ratings. There are advanced techniques you can use to make human evaluation more efficient or accurate (e.g., <a href="https://en.wikipedia.org/wiki/Active_learning_(machine_learning)">active learning</a>, <a href="https://supervisely.com/blog/labeling-consensus/">consensus voting</a>, etc.), but I recommend starting with something simple. Finally, like unit tests, you should organize and analyze your human-eval results to assess if you are progressing over time.</p>
<p>As discussed later, these labeled examples measure the quality of your system, validate automated evaluation, and curate high-quality synthetic data for fine-tuning.</p>
<section id="how-much-data-should-you-look-at" class="level4">
<h4 class="anchored" data-anchor-id="how-much-data-should-you-look-at">How much data should you look at?</h4>
<p>I often get asked how much data to examine. When starting, you should examine as much data as possible. I usually read traces generated from ALL test cases and user-generated traces at a minimum. <strong>You can never stop looking at data—no free lunch exists.</strong> However, you can sample your data more over time, lessening the burden. <sup>3</sup></p>
</section>
</section>
<section id="automated-evaluation-w-llms" class="level3">
<h3 class="anchored" data-anchor-id="automated-evaluation-w-llms">Automated Evaluation w/ LLMs</h3>
<p>Many vendors want to sell you tools that claim to eliminate the need for a human to look at the data. Having humans periodically evaluate at least a sample of traces is a good idea. I often find that “correctness” is somewhat subjective, and you must align the model with a human.</p>
<p>You should track the correlation between model-based and human evaluation to decide how much you can rely on automatic evaluation. Furthermore, by collecting critiques from labelers explaining why they are making a decision, you can iterate on the evaluator model to align it with humans through prompt engineering or fine-tuning. However, I tend to favor prompt engineering for evaluator model alignment.</p>
<p>I love using low-tech solutions like Excel to iterate on aligning model-based eval with humans. For example, I sent my colleague Phillip the following spreadsheet every few days to grade for a different use-case involving a <a href="https://www.honeycomb.io/blog/introducing-query-assistant">natural language query generator</a>. This spreadsheet would contain the following information:</p>
<ol type="1">
<li><strong>model response</strong>: this is the prediction made by the LLM.</li>
<li><strong>model critique</strong>: this is a critique written by a (usually more powerful) LLM about your original LLM’s prediction.</li>
<li><strong>model outcome</strong>: this is a binary label the critique model assigns to the <code>model response</code> as being “good” or “bad.”</li>
</ol>
<p>Phillip then fills out his version of the same information - meaning his critique, outcome, and desired response for 25-50 examples at a time (these are the columns prefixed with “phillip_” below):</p>
<p><img src="https://hamel.dev/blog/posts/evals/images/spreadsheet.png" class="img-fluid"></p>
<p>This information allowed me to iterate on the prompt of the critique model to make it sufficiently aligned with Phillip over time. This is also easy to track in a low-tech way in a spreadsheet:</p>
<p><img src="https://hamel.dev/blog/posts/evals/images/score.png" class="img-fluid"></p>
<p>This is a screenshot of a spreadsheet where we recorded our attempts to align model-based eval with a human evaluator.</p>
<p>General tips on model-based eval:</p>
<ul>
<li>Use the most powerful model you can afford. It often takes advanced reasoning capabilities to critique something well. You can often get away with a slower, more powerful model for critiquing outputs relative to what you use in production.</li>
<li>Model-based evaluation is a meta-problem within your larger problem. You must maintain a mini-evaluation system to track its quality. I have sometimes fine-tuned a model at this stage (but I try not to).</li>
<li>After bringing the model-based evaluator in line with the human, you must continue doing periodic exercises to monitor the model and human agreement.</li>
</ul>
<p>My favorite aspect about creating a good evaluator model is that its critiques can be used to curate high-quality synthetic data, which I will touch upon later.</p>
</section>
</section>
<section id="level-3-ab-testing" class="level2">
<h2 class="anchored" data-anchor-id="level-3-ab-testing">Level 3: A/B Testing</h2>
<p>Finally, it is always good to perform A/B tests to ensure your AI product is driving user behaviors or outcomes you desire. A/B testing for LLMs compared to other types of products isn’t too different. If you want to learn more about A/B testing, I recommend reading the <a href="https://www.geteppo.com/blog">Eppo blog</a> (which was created by colleagues I used to work with who are rock stars in A/B testing).</p>
<p>It’s okay to put this stage off until you are sufficiently ready and convinced that your AI product is suitable for showing to real users. This level of evaluation is usually only appropriate for more mature products.</p>
</section>
<section id="evaluating-rag" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-rag">Evaluating RAG</h2>
<p>Aside from evaluating your system as a whole, you can evaluate sub-components of your AI, like RAG. Evaluating RAG is beyond the scope of this post, but you can learn more about this subject <a href="https://jxnl.github.io/blog/writing/2024/02/28/levels-of-complexity-rag-applications/">in a post by Jason Liu</a>.</p>
</section>
</section>
<section id="eval-systems-unlock-superpowers-for-free" class="level1">
<h1>Eval Systems Unlock Superpowers For Free</h1>
<p>In addition to iterating fast, eval systems unlock the ability to fine-tune and debug, which can take your AI product to the next level.</p>
<section id="fine-tuning" class="level2">
<h2 class="anchored" data-anchor-id="fine-tuning">Fine-Tuning</h2>
<p>Rechat resolved many failure modes through fine-tuning that were not possible with prompt engineering alone. <strong>Fine-tuning is best for learning syntax, style, and rules, whereas techniques like RAG supply the model with context or up-to-date facts.</strong></p>
<p>99% of the labor involved with fine-tuning is assembling high-quality data that covers your AI product’s surface area. However, if you have a solid evaluation system like Rechat’s, you already have a robust data generation and curation engine! I will expand more on the process of fine-tuning in a future post.<sup>4</sup></p>
<section id="data-synthesis-curation" class="level3">
<h3 class="anchored" data-anchor-id="data-synthesis-curation">Data Synthesis &amp; Curation</h3>
<p>To illustrate why data curation and synthesis come nearly for free once you have an evaluation system, consider the case where you want to create additional fine-tuning data for the listing finder mentioned earlier. First, you can use LLMs to generate synthetic data with a prompt like this:</p>
<pre class="text code-overflow-wrap"><code>Imagine if Zillow was able to parse natural language. Come up with 50 different ways users would be able to search listings there. Use real names for cities and neighborhoods.

You can use the following parameters:

&lt;ommitted for confidentiality&gt;

Output should be a JSON code block array. Example:

[
"Homes under $500k in New York"
]</code></pre>
<p>This is almost identical to the exercise for producing test cases! You can then use your Level 1 &amp; Level 2 tests to filter out undesirable data that fails assertions or that the critique model thinks are wrong. You can also use your existing human evaluation tools to look at traces to curate traces for a fine-tuning dataset.</p>
</section>
</section>
<section id="debugging" class="level2">
<h2 class="anchored" data-anchor-id="debugging">Debugging</h2>
<p>When you get a complaint or see an error related to your AI product, you should be able to debug this quickly. If you have a robust evaluation system, you already have:</p>
<ul>
<li>A database of traces that you can search and filter.</li>
<li>A set of mechanisms (assertions, tests, etc) that can help you flag errors and bad behaviors.</li>
<li>Log searching &amp; navigation tools that can help you find the root cause of the error. For example, the error could be RAG, a bug in the code, or a model performing poorly.</li>
<li>The ability to make changes in response to the error and quickly test its efficacy.</li>
</ul>
<p>In short, there is an incredibly large overlap between the infrastructure needed for evaluation and that for debugging.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>Evaluation systems create a flywheel that allows you to iterate very quickly. It’s almost always where people get stuck when building AI products. I hope this post gives you an intuition on how to go about building your evaluation systems. Some key takeaways to keep in mind:</p>
<ul>
<li>Remove ALL friction from looking at data.</li>
<li>Keep it simple. Don’t buy fancy LLM tools. Use what you have first.</li>
<li>You are doing it wrong if you aren’t looking at lots of data.</li>
<li>Don’t rely on generic evaluation frameworks to measure the quality of your AI. Instead, create an evaluation system specific to your problem.</li>
<li>Write lots of tests and frequently update them.</li>
<li>LLMs can be used to unblock the creation of an eval system. Examples include using a LLM to:
<ul>
<li>Generate test cases and write assertions</li>
<li>Generate synthetic data</li>
<li>Critique and label data etc.</li>
</ul></li>
<li>Re-use your eval infrastructure for debugging and fine-tuning.</li>
</ul>
<p>I’d love to hear from you if you found this post helpful or have any questions. My email is <code>hamel@parlance-labs.com</code>.</p>
<p><br></p>
<div class="acknowledgments">
<p><em>This article is an adaptation of <a href="https://www.youtube.com/watch?v=B_DMMlDuJB0">this conversation</a> I had with Emil Sedgh and Hugo Browne-Anderson on the <a href="https://vanishinggradients.fireside.fm/">Vanishing Gradients podcast</a>. Thanks to Jeremy Howard, Eugene Yan, Shreya Shankar, Jeremy Lewi, and Joseph Gleasure for reviewing this article.</em></p>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>This is not to suggest that people are lazy. Many don’t know how to set up eval systems and skip these steps.↩︎</p></li>
<li id="fn2"><p>Some examples include <a href="https://arize.com/">arize</a>, <a href="https://humanloop.com/">human loop</a>, <a href="https://github.com/traceloop/openllmetry">openllmetry</a> and <a href="https://www.honeyhive.ai/">honeyhive</a>.↩︎</p></li>
<li id="fn3"><p>A reasonable heuristic is to keep reading logs until you feel like you aren’t learning anything new.↩︎</p></li>
<li id="fn4"><p>If you cannot wait, I’ll be teaching <a href="https://maven.com/parlance-labs/fine-tuning">this course</a> on fine-tuning soon.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>LLMs</category>
  <category>evals</category>
  <guid>https://hamel.dev/blog/posts/evals/</guid>
  <pubDate>Fri, 29 Mar 2024 07:00:00 GMT</pubDate>
  <media:content url="https://hamel.dev/blog/posts/evals/images/diagram-cover.png" medium="image" type="image/png" height="77" width="144"/>
</item>
<item>
  <title>Is Fine-Tuning Still Valuable?</title>
  <dc:creator>Hamel Husain</dc:creator>
  <link>https://hamel.dev/blog/posts/fine_tuning_valuable.html</link>
  <description><![CDATA[ 




<p>Here is my personal opinion about the questions I posed in <a href="https://x.com/HamelHusain/status/1772426234032541962?s=20">this tweet</a>:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
There are a growing number of voices expressing disillusionment with fine-tuning. <br><br>I'm curious about the sentiment more generally. (I am withholding sharing my opinion rn). <br><br>Tweets below are from <a href="https://twitter.com/mlpowered?ref_src=twsrc%5Etfw"><span class="citation" data-cites="mlpowered">@mlpowered</span></a> <a href="https://twitter.com/abacaj?ref_src=twsrc%5Etfw"><span class="citation" data-cites="abacaj">@abacaj</span></a> <a href="https://twitter.com/emollick?ref_src=twsrc%5Etfw"><span class="citation" data-cites="emollick">@emollick</span></a> <a href="https://t.co/cU0hCdubBU">pic.twitter.com/cU0hCdubBU</a>
</p>
— Hamel Husain (<span class="citation" data-cites="HamelHusain">@HamelHusain</span>) <a href="https://twitter.com/HamelHusain/status/1772426234032541962?ref_src=twsrc%5Etfw">March 26, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<hr>
<p>I think that fine-tuning is still very valuable in many situations. I’ve done some more digging and I find that people who say that fine-tuning isn’t useful are indeed often working on products where fine-tuning isn’t likely to be useful:</p>
<ul>
<li>They are making developer tools - foundation models have been trained extensively on coding tasks.</li>
<li>They are building foundation models and testing for the most general cases. But the foundation models themselves are also being trained for the most general cases.</li>
<li>They are building a personal assistant that isn’t scoped to any type of domain or use case and is essentially similar to the same folks building foundation models.</li>
</ul>
<p>Another common pattern is that people often say this in earlier stages of their product development. One sign that folks are in really early stages is that they don’t have a domain-specific eval harness.</p>
<p><strong>It’s impossible to fine-tune effectively without an eval system which can lead to writing off fine-tuning if you haven’t completed this prerequisite.</strong> It’s also impossible to improve your product without a good eval system in the long term, fine-tuning or not.</p>
<p>You should do as much prompt engineering as possible before you fine-tune. But not for reasons you would think! The reason for doing lots of prompt engineering is that it’s a great way to stress test your eval system!</p>
<p>If you find that prompt-engineering works fine (and you are systematically evaluating your product) then it’s fine to stop there. I’m a big believer in using the simplest approach to solving a problem. I just don’t think you should write off fine-tuning yet.</p>
<section id="examples-where-ive-seen-fine-tuning-work-well" class="level3">
<h3 class="anchored" data-anchor-id="examples-where-ive-seen-fine-tuning-work-well">Examples where I’ve seen fine-tuning work well</h3>
<p>Generally speaking, fine-tuning works best to learn syntax, style and rules whereas techniques like RAG work best to supply the model with context or up-to-date facts.</p>
<p><em>These are some examples from companies I’ve worked with. Hopefully, we will be able to share more details soon.</em></p>
<ul>
<li><p><a href="https://www.honeycomb.io/blog/introducing-query-assistant">Honeycomb’s Natural Language Query Assistant</a> - previously, the “programming manual” for the Honeycomb query language was being dumped into the prompt along with many examples. While this was OK, fine-tuning worked much better to allow the model to learn the syntax and rules of this niche domain-specific language.</p></li>
<li><p><a href="https://www.youtube.com/watch?v=B_DMMlDuJB0">ReChat’s Lucy</a> - this is an AI real estate assistant integrated into an existing Real Estate CRM system. ReChat needs LLM responses to be provided in a very idiosyncratic format that weaves together structured and unstructured data to allow the front end to render widgets, cards and other interactive elements dynamically into the chat interface. Fine-tuning was the key to making this work correctly. <a href="https://www.youtube.com/watch?v=B_DMMlDuJB0">This talk</a> has more details.</p></li>
</ul>
<p>P.S. Fine-tuning is not only limited to open or “small” models. There are lots of folks who have been fine-tuning GPT-3.5, such as <a href="https://x.com/perplexity_ai/status/1695102998463009254?s=20">Perplexity.AI:</a> and <a href="https://casetext.com/blog/cocounsel-harnesses-gpt-4s-power-to-deliver-results-that-legal-professionals-can-rely-on/">CaseText</a>, to name a few.</p>


</section>

 ]]></description>
  <guid>https://hamel.dev/blog/posts/fine_tuning_valuable.html</guid>
  <pubDate>Wed, 27 Mar 2024 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Fuck You, Show Me The Prompt.</title>
  <dc:creator>Hamel Husain</dc:creator>
  <link>https://hamel.dev/blog/posts/prompt/</link>
  <description><![CDATA[ 




<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>There are many libraries that aim to make the output of your LLMs better by <strong>re-writing or constructing the prompt for you</strong>. These libraries purport to make the output of your LLMs:</p>
<ul>
<li>safer <a href="https://github.com/guardrails-ai/guardrails">(ex: guardrails)</a></li>
<li>deterministic <a href="https://github.com/guidance-ai/guidance">(ex: guidance)</a></li>
<li>structured <a href="https://github.com/jxnl/instructor">(ex: instructor)</a></li>
<li>resilient <a href="https://www.langchain.com/">(ex: langchain)</a></li>
<li>… or even optimized for an arbitrary metric <a href="https://github.com/stanfordnlp/dspy">(ex: DSPy)</a>.</li>
</ul>
<p>A common theme among <em>some</em> of these tools is they encourage users to disintermediate themselves from prompting.</p>
<blockquote class="blockquote">
<p><a href="https://github.com/stanfordnlp/dspy">DSPy</a>: “This is a new paradigm in which LMs and their prompts fade into the background …. you can compile your program again DSPy will create new effective prompts”</p>
</blockquote>
<blockquote class="blockquote">
<p><a href="https://github.com/guidance-ai/guidance">guidance</a> “guidance is a programming paradigm that offers superior control and efficiency compared to conventional prompting …”</p>
</blockquote>
<p>Even when tools don’t discourage prompting, I’ve often found it difficult to retrieve the final prompt(s) these tools send to the language model. <strong>The prompts sent by these tools to the LLM is a natural language description of what these tools are doing, and is the fastest way to understand how they work.</strong> Furthermore, some tools have <a href="https://github.com/stanfordnlp/dspy?tab=readme-ov-file#4-two-powerful-concepts-signatures--teleprompters">dense terminology</a> to describe internal constructs which can further obfuscate what they are doing.</p>
<p>For reasons I’ll explain below, I think most people would benefit from the following mindset:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/prompt/slap_3.jpeg" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>In this blog post, I’ll show you how you can <strong>intercept API calls w/prompts for any tool, without having to fumble through docs or read source code.</strong> I’ll show you how to setup and operate <a href="https://mitmproxy.org/">mitmproxy</a> with examples from the LLM the tools I previously mentioned.</p>
</section>
<section id="motivation-minimize-accidental-complexity" class="level2">
<h2 class="anchored" data-anchor-id="motivation-minimize-accidental-complexity">Motivation: Minimize accidental complexity</h2>
<p>Before adopting an abstraction, its important to consider the dangers of taking on <a href="https://dev.to/alexbunardzic/software-complexity-essential-accidental-and-incidental-3i4d">accidental complexity</a>. This danger is acute for LLM abstractions relative to programming abstractions. With LLM abstractions, we often force the user to regress towards writing code instead of conversing with the AI in natural language, which can run counter to the purpose of LLMs:</p>
<center>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Programming abstraction -&gt; a human-like language you can use to translate your task into machine code<br><br>LLM abstraction -&gt; an unintelligible framework you can use to translate your task into human language
</p>
— Hamel Husain (<span class="citation" data-cites="HamelHusain">@HamelHusain</span>) <a href="https://twitter.com/HamelHusain/status/1754315254413361553">February 5, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>
<p>While this is a cheeky comment, it’s worth keeping this in mind while evaluating tools. There are two primary types of automation that tools provide:</p>
<ul>
<li><strong>Interleaving code and LLMs:</strong> Expressing this automation is often best done through code, since code must be run to carry out the task. Examples include routing, executing functions, retries, chaining, etc.</li>
<li><strong>Re-Writing and constructing prompts</strong>: Expressing your intent is often best done through natural language. However, there are exceptions! For example, it is convenient to express a function definition or schema from code instead of natural language.</li>
</ul>
<p>Many frameworks offer both types of automation. However, going too far with the second type can have negative consequences. Seeing the prompt allows you decide:</p>
<ol type="1">
<li>Is this framework really necessary?</li>
<li>Should I just steal the final prompt (a string) and jettison the framework?</li>
<li>Can we write a better prompt than this (shorter, aligned with your intent, etc)?</li>
<li>Is this the best approach (do the # of API calls seem appropriate)?</li>
</ol>
<p>In my experience, seeing the prompts and API calls are essential to making informed decisions.</p>
</section>
<section id="intercepting-llm-api-calls" class="level2">
<h2 class="anchored" data-anchor-id="intercepting-llm-api-calls">Intercepting LLM API calls</h2>
<p>There are many possible ways to intercept LLM API calls, such as monkey patching source code or finding a user-facing option. I’ve found that those approaches take far too much time since the quality of source code and documentation can vary greatly. After all, I just want to see API calls without worrying about how the code works!</p>
<p>A framework agnostic way to see API calls is to setup a proxy that logs your outgoing API requests. This is easy to do with <a href="https://mitmproxy.org/">mitmproxy</a>, an free, open-source HTTPS proxy.</p>
<section id="setting-up-mitmproxy" class="level3">
<h3 class="anchored" data-anchor-id="setting-up-mitmproxy">Setting Up mitmproxy</h3>
<p>This is an opinionated way to setup <code>mitmproxy</code>that’s beginner-friendly for our intended purposes:</p>
<ol type="1">
<li><p>Follow the installation instructions <a href="https://mitmproxy.org/">on the website</a></p></li>
<li><p>Start the interactive UI by running <code>mitmweb</code> in the terminal. Pay attention to the url of the interactive UI in the logs which will look something like this: <code>Web server listening at http://127.0.0.1:8081/</code></p></li>
<li><p>Next, you need to configure your device (i.e.&nbsp;your laptop) to route all traffic through <code>mitproxy</code>, which listens on <code>http://localhost:8080</code>. Per the documentation:</p>
<blockquote class="blockquote">
<p>We recommend to simply search the web on how to configure an HTTP proxy for your system. Some operating system have a global settings, some browser have their own, other applications use environment variables, etc.</p>
</blockquote>
<p>In my case, A <a href="https://www.google.com/search?q=set+proxy+for+macos&amp;sca_esv=c51a80de1a7d45f0&amp;rlz=1C5CHFA_enUS1048US1049&amp;sxsrf=ACQVn0_ysjr6Kma2_lX8WbB06iPbDi5gUQ%3A1707764982232&amp;ei=9mzKZYXoDcfy0PEPpJqb2Ao&amp;ved=0ahUKEwiFu4CpwKaEAxVHOTQIHSTNBqsQ4dUDCBA&amp;uact=5&amp;oq=set+proxy+for+macos&amp;gs_lp=Egxnd3Mtd2l6LXNlcnAiE3NldCBwcm94eSBmb3IgbWFjb3MyBBAjGCcyBhAAGBYYHjIGEAAYFhgeMgYQABgWGB4yBhAAGBYYHjILEAAYgAQYigUYhgMyCxAAGIAEGIoFGIYDSMk-UMU7WMU7cAd4AZABAJgBVaABVaoBATG4AQPIAQD4AQHCAgoQABhHGNYEGLAD4gMEGAAgQYgGAZAGCA&amp;sclient=gws-wiz-serp">google search for “set proxy for macos”</a> returned these results:</p>
<blockquote class="blockquote">
<p>choose Apple menu &gt; System Settings, click Network in the sidebar, click a network service on the right, click Details, then click Proxies.</p>
</blockquote>
<p>I then insert <code>localhost</code> and <code>8080</code> in the following places in the UI:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/prompt/mac.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div></li>
<li><p>Next, navigate to <a href="http://mitm.it">http://mitm.it</a> and it will give you instructions on how to install the mitmproxy Certificate Authority (CA), which you will need for intercepting HTTPS requests. (You can also do this manually <a href="https://docs.mitmproxy.org/stable/concepts-certificates/#quick-setup">here</a>.) Also, take note of the location of the CA file as we will reference it later.</p></li>
<li><p>You can test that everything works by browsing to a website like <a href="https://mitmproxy.org/">https://mitmproxy.org/</a>, and seeing the corresponding output in the mtimweb UI which for me is located at <a href="http://127.0.0.1:8081/">http://127.0.0.1:8081/</a> (look at the logs in your terminal to get the URL).</p></li>
<li><p>Now that you set everything up, you can disable the proxy that you previously enabled on your network. I do this on my mac by toggling the proxy buttons in the screenshot I showed above. This is because we want to scope the proxy to only the python program to eliminate unnecessary noise.</p></li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Networking related software commonly allows you to proxy outgoing requests by setting environment variables. This is the approach we will use to scope our proxy to specific Python programs. However, I encourage you to play with other types of programs to see what you find after you are comfortable!</p>
</div>
</div>
</section>
<section id="environment-variables-for-python" class="level3">
<h3 class="anchored" data-anchor-id="environment-variables-for-python">Environment variables for Python</h3>
<p>We need to set the following environment variables so that the <code>requests</code> and <code>httpx</code> libraries will direct traffic to the proxy and reference the CA file for HTTPS traffic:</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Make sure you set these environment variables before running any of the code snippets in this blog post.</p>
</div>
</div>
<div id="07c4617c-1d52-4c99-9bed-645efd73ba71" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb1-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The location of my CA File</span></span>
<span id="cb1-3">cert_file <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'/Users/hamel/Downloads/mitmproxy-ca-cert.pem'</span> </span>
<span id="cb1-4">os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'REQUESTS_CA_BUNDLE'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cert_file</span>
<span id="cb1-5">os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'SSL_CERT_FILE'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cert_file</span>
<span id="cb1-6">os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'HTTPS_PROXY'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'http://127.0.0.1:8080'</span></span></code></pre></div>
</div>
<p>You can do a minimal test by running the following code:</p>
<div id="faf4a70a-bde5-47c0-b649-3179c233c189" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> requests</span>
<span id="cb2-2">requests.post(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'https://httpbin.org/post'</span>, </span>
<span id="cb2-3">              data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'key'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'value'</span>})</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>&lt;Response [200]&gt;</code></pre>
</div>
</div>
<p>This will appear in the UI like so:</p>
<p><img src="https://hamel.dev/blog/posts/prompt/mitm_01.png" class="img-fluid"></p>
</section>
</section>
<section id="examples" class="level2">
<h2 class="anchored" data-anchor-id="examples">Examples</h2>
<p>Now for the fun part, let’s run through some examples of LLM libraries and intercept their API calls!</p>
<section id="guardrails" class="level3">
<h3 class="anchored" data-anchor-id="guardrails">Guardrails</h3>
<p>Guardrails allows you specify structure and types, which it uses to validate and correct the outputs of large language models. This is a hello world example from the <a href="https://github.com/guardrails-ai/guardrails"><code>guardrails-ai/guardrails</code> README</a>:</p>
<div id="c746dbe7-e96f-4ea0-89d5-ca9b0b0685e8" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel, Field</span>
<span id="cb4-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> guardrails <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Guard</span>
<span id="cb4-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> openai</span>
<span id="cb4-4"></span>
<span id="cb4-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Pet(BaseModel):</span>
<span id="cb4-6">    pet_type: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Species of pet"</span>)</span>
<span id="cb4-7">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a unique pet name"</span>)</span>
<span id="cb4-8"></span>
<span id="cb4-9">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb4-10"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    What kind of pet should I get and what should I name it?</span></span>
<span id="cb4-11"></span>
<span id="cb4-12"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    $</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{gr.complete_json_suffix_v2}</span></span>
<span id="cb4-13"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb4-14">guard <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Guard.from_pydantic(output_class<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Pet, prompt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>prompt)</span>
<span id="cb4-15"></span>
<span id="cb4-16">validated_output, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>rest <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> guard(</span>
<span id="cb4-17">    llm_api<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>openai.completions.create,</span>
<span id="cb4-18">    engine<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-3.5-turbo-instruct"</span></span>
<span id="cb4-19">)</span>
<span id="cb4-20"></span>
<span id="cb4-21"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>validated_output<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{
    "pet_type": "dog",
    "name": "Buddy</code></pre>
</div>
</div>
<p>What is happening here? How is this structured output and validation working? Looking at the mitmproxy UI, I can see that the above code resulted in two LLM API calls, the first one with this prompt:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode txt code-overflow-wrap code-with-copy"><code class="sourceCode default"><span id="cb6-1">What kind of pet should I get and what should I name it?</span>
<span id="cb6-2"></span>
<span id="cb6-3">    </span>
<span id="cb6-4">Given below is XML that describes the information to extract from this document and the tags to extract it into.</span>
<span id="cb6-5"></span>
<span id="cb6-6">&lt;output&gt;</span>
<span id="cb6-7">    &lt;string name="pet_type" description="Species of pet"/&gt;</span>
<span id="cb6-8">    &lt;string name="name" description="a unique pet name"/&gt;</span>
<span id="cb6-9">&lt;/output&gt;</span>
<span id="cb6-10"></span>
<span id="cb6-11"></span>
<span id="cb6-12">ONLY return a valid JSON object (no other text is necessary), where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise.</span>
<span id="cb6-13"></span>
<span id="cb6-14">Here are examples of simple (XML, JSON) pairs that show the expected behavior:</span>
<span id="cb6-15">- `&lt;string name='foo' format='two-words lower-case' /&gt;` =&gt; `{'foo': 'example one'}`</span>
<span id="cb6-16">- `&lt;list name='bar'&gt;&lt;string format='upper-case' /&gt;&lt;/list&gt;` =&gt; `{"bar": ['STRING ONE', 'STRING TWO', etc.]}`</span>
<span id="cb6-17">- `&lt;object name='baz'&gt;&lt;string name="foo" format="capitalize two-words" /&gt;&lt;integer name="index" format="1-indexed" /&gt;&lt;/object&gt;` =&gt; `{'baz': {'foo': 'Some String', 'index': 1}}`</span></code></pre></div>
<p><strong>Followed by another call with this prompt:</strong></p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode txt code-overflow-wrap code-with-copy"><code class="sourceCode default"><span id="cb7-1">I was given the following response, which was not parseable as JSON.</span>
<span id="cb7-2"></span>
<span id="cb7-3">"{\n    \"pet_type\": \"dog\",\n    \"name\": \"Buddy"</span>
<span id="cb7-4"></span>
<span id="cb7-5">Help me correct this by making it valid JSON.</span>
<span id="cb7-6"></span>
<span id="cb7-7">Given below is XML that describes the information to extract from this document and the tags to extract it into.</span>
<span id="cb7-8"></span>
<span id="cb7-9">&lt;output&gt;</span>
<span id="cb7-10">    &lt;string name="pet_type" description="Species of pet"/&gt;</span>
<span id="cb7-11">    &lt;string name="name" description="a unique pet name"/&gt;</span>
<span id="cb7-12">&lt;/output&gt;</span>
<span id="cb7-13"></span>
<span id="cb7-14"></span>
<span id="cb7-15">ONLY return a valid JSON object (no other text is necessary), where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter `null`.</span></code></pre></div>
<p>Woof. That’s a whole lot of ceremony to get structured output! We learned that this library’s approach to structured output uses XML schemas (while others use function calling). It’s worth considering if you can fashion a better or simpler approach now that the magic has been lifted. Either way, we now have insight into how it works without dragging you into unnecessary complexity, which is a win.</p>
</section>
<section id="guidance" class="level3">
<h3 class="anchored" data-anchor-id="guidance">Guidance</h3>
<p>Guidance offers constrained generation and programming constructs for writing prompts. Let’s dive into a <a href="https://github.com/guidance-ai/guidance/blob/main/notebooks/tutorials/chat.ipynb">chat example from their tutorials</a>:</p>
<div id="cfe6882f-e22c-4666-9a66-6ce41262c6ea" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> guidance</span>
<span id="cb8-2">gpt35 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> guidance.models.OpenAI(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-3.5-turbo"</span>)</span>
<span id="cb8-3"></span>
<span id="cb8-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> re</span>
<span id="cb8-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> guidance <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> gen, select, system, user, assistant</span>
<span id="cb8-6"></span>
<span id="cb8-7"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@guidance</span></span>
<span id="cb8-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> plan_for_goal(lm, goal: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>):</span>
<span id="cb8-9">    </span>
<span id="cb8-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This is a helper function which we will use below</span></span>
<span id="cb8-11">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> parse_best(prosandcons, options):</span>
<span id="cb8-12">        best <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> re.search(<span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'Best=(\d+)'</span>, prosandcons)</span>
<span id="cb8-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> best:</span>
<span id="cb8-14">            best <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>  re.search(<span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'Best.*?(\d+)'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Best= option is 3'</span>)</span>
<span id="cb8-15">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> best:</span>
<span id="cb8-16">            best <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(best.group(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb8-17">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb8-18">            best <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb8-19">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> options[best]</span>
<span id="cb8-20"></span>
<span id="cb8-21">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Some general instruction to the model</span></span>
<span id="cb8-22">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> system():</span>
<span id="cb8-23">        lm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"You are a helpful assistant."</span></span>
<span id="cb8-24"></span>
<span id="cb8-25">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Simulate a simple request from the user</span></span>
<span id="cb8-26">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Note that we switch to using 'lm2' here, because these are intermediate steps (so we don't want to overwrite the current lm object)</span></span>
<span id="cb8-27">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> user():</span>
<span id="cb8-28">        lm2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"""</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb8-29"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">        I want to </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>goal<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb8-30"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">        Can you please generate one option for how to accomplish this?</span></span>
<span id="cb8-31"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">        Please make the option very short, at most one line."""</span></span>
<span id="cb8-32"></span>
<span id="cb8-33">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate several options. Note that this means several sequential generation requests</span></span>
<span id="cb8-34">    n_options <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span></span>
<span id="cb8-35">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> assistant():</span>
<span id="cb8-36">        options <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb8-37">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n_options):</span>
<span id="cb8-38">            options.append((lm2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> gen(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'option'</span>, temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>))[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"option"</span>])</span>
<span id="cb8-39"></span>
<span id="cb8-40">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Have the user request pros and cons</span></span>
<span id="cb8-41">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> user():</span>
<span id="cb8-42">        lm2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"""</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb8-43"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">        I want to </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>goal<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb8-44"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">        Can you please comment on the pros and cons of each of the following options, and then pick the best option?</span></span>
<span id="cb8-45"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">        ---</span></span>
<span id="cb8-46"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb8-47">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, opt <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(options):</span>
<span id="cb8-48">            lm2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Option </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>opt<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb8-49">        lm2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"""</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb8-50"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">        ---</span></span>
<span id="cb8-51"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">        Please discuss each option very briefly (one line for pros, one for cons), and end by saying Best=X, where X is the number of the best option."""</span></span>
<span id="cb8-52"></span>
<span id="cb8-53">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the pros and cons from the model</span></span>
<span id="cb8-54">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> assistant():</span>
<span id="cb8-55">        lm2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> gen(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'prosandcons'</span>, temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">600</span>, stop<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Best="</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Best="</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> gen(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"best"</span>, regex<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"[0-9]+"</span>) </span>
<span id="cb8-56"></span>
<span id="cb8-57">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The user now extracts the one selected as the best, and asks for a full plan</span></span>
<span id="cb8-58">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># We switch back to 'lm' because this is the final result we want</span></span>
<span id="cb8-59">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> user():</span>
<span id="cb8-60">        lm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"""</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb8-61"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">        I want to </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>goal<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb8-62"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">        Here is my plan: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>options[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(lm2[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"best"</span>])]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb8-63"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">        Please elaborate on this plan, and tell me how to best accomplish it."""</span></span>
<span id="cb8-64"></span>
<span id="cb8-65">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The plan is generated</span></span>
<span id="cb8-66">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> assistant():</span>
<span id="cb8-67">        lm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> gen(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'plan'</span>, max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>)</span>
<span id="cb8-68"></span>
<span id="cb8-69">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> lm</span></code></pre></div>
</div>
<div id="7cbd50af-7689-426c-8779-1b0d5e9bfe7a" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gpt35 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> plan_for_goal(goal<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"read more books"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre style="margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;"><div style="display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;"><div style="flex: 0 0 80px; opacity: 0.5;">system</div><div style="flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;">You are a helpful assistant.</div></div><div style="display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;"><div style="flex: 0 0 80px; opacity: 0.5;">user</div><div style="flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;">I want to read more books
Here is my plan: Set aside 30 minutes of dedicated reading time each day.
Please elaborate on this plan, and tell me how to best accomplish it.</div></div><div style="display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;"><div style="flex: 0 0 80px; opacity: 0.5;">assistant</div><div style="flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;"><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">Setting</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> aside</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> </span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">30</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> minutes</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> of</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> dedicated</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> time</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> each</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> day</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> is</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> great</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> plan</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> to</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> read</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> more</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> books</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Here</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> are</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> some</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> tips</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> to</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> help</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> you</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> accomplish</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> this</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> goal</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">:

</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">1</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Establish</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> routine</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">:</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Choose</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> specific</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> time</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> of</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> day</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> that</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> works</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> best</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> for</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> you</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> whether</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> it</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">'s</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> in</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> the</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> morning</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> during</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> lunch</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> break</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> or</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> before</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> bed</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Cons</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">istency</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> is</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> key</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> to</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> forming</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> habit</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.

</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">2</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Create</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">-friendly</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> environment</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">:</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Find</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> quiet</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> and</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> comfortable</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> spot</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> where</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> you</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> can</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> focus</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> on</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> your</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> without</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> distractions</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> It</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> could</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> be</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> cozy</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> corner</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> in</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> your</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> home</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> park</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> bench</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> or</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> local</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> library</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.

</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">3</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Mini</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">mi</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">ze</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> distractions</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">:</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Put</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> away</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> your</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> phone</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> turn</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> off</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> the</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> TV</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> and</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> avoid</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> any</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> other</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> potential</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> interruptions</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> during</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> your</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> dedicated</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> time</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> This</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> will</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> help</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> you</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> stay</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> focused</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> and</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> fully</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> immer</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">se</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> yourself</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> in</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> the</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> book</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.

</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">4</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Choose</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> books</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> that</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> interest</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> you</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">:</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Select</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> books</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> that</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> align</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> with</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> your</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> personal</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> interests</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> hobbies</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> or</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> goals</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> When</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> you</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">'re</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> genuinely</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> interested</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> in</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> the</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> subject</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> matter</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> you</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">'ll</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> be</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> more</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> motivated</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> to</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> read</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> regularly</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.

</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">5</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Start</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> with</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> manageable</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> goals</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">:</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> If</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> you</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">'re</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> new</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> to</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> or</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> have</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> busy</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> schedule</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> start</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> with</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> smaller</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> time</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> commitment</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> such</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> as</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> </span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">15</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> minutes</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> and</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> gradually</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> increase</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> it</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> to</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> </span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">30</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> minutes</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> or</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> more</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> as</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> you</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> become</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> more</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> comfortable</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.

</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">6</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Set</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> timer</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">:</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Use</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> timer</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> or</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> app</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> that</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> allows</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> you</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> to</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> track</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> your</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> time</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> This</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> will</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> help</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> you</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> stay</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> accountable</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> and</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> ensure</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> that</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> you</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> dedicate</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> the</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> full</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> </span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">30</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> minutes</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> to</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.

</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">7</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Make</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> enjoyable</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">:</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Create</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> cozy</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> atmosphere</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> by</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> lighting</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> candle</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> sip</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">ping</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> cup</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> of</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> tea</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> or</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> playing</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> soft</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> background</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> music</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Eng</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">aging</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> all</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> your</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> senses</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> can</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> enhance</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> your</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> experience</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.

</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">8</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Join</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> book</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> club</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> or</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> group</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">:</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Consider</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> joining</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> book</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> club</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> or</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> participating</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> in</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> group</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> to</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> connect</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> with</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> fellow</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> book</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> lovers</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> This</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> can</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> provide</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> additional</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> motivation</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> discussion</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> opportunities</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> and</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> book</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> recommendations</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.

</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">9</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Keep</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> log</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">:</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Maintain</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> record</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> of</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> the</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> books</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> you</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">'ve</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> read</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> along</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> with</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> your</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> thoughts</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> and</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reflections</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> This</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> can</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> help</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> you</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> track</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> your</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> progress</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> discover</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> patterns</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> in</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> your</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> preferences</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> and</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> serve</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> as</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> source</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> of</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> inspiration</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> for</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> future</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.

</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">10</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Be</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> flexible</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">:</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> While</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> it</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">'s</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> important</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> to</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> have</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> dedicated</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> time</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> be</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> flexible</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> and</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> adaptable</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Life</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> can</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> sometimes</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> get</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> busy</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> so</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> if</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> you</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> miss</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> day</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> don</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">'t</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> be</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> discouraged</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Simply</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> pick</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> up</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> where</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> you</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> left</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> off</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> and</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> continue</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> with</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> your</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> routine</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.

</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">Remember</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">,</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> the</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> goal</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> is</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> to</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> enjoy</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> the</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> process</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> of</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> and</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> make</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> it</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> a</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> regular</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> part</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> of</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> your</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> life</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">.</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> Happy</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0"> reading</span><span style="background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;" title="1.0">!</span></div></div></pre>
</div>
</div>
<p>This looks pretty neat! But what is it doing exactly? <strong>This makes a total of 7 calls to OpenAI</strong>, which I have put in <a href="https://gist.github.com/hamelsmu/d0d75bf702e56987f35cb715f7da4d6a">this gist</a>. <strong>5 of 7 of these API calls are “internal” thoughts asking the LLM to generate ideas.</strong> Even though the temperature is set to 1.0, <strong>these “ideas” are mostly redundant.</strong> The penultimate call to OpenAI enumerates these “ideas” which I’ve included below:</p>
<div id="a3a0664f-577d-4a0c-96e7-74527036a0be" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="cell-output cell-output-stdout">
<pre><code>I want to read more books
Can you please comment on the pros and cons of each of the following options, and then pick the best option?
---
Option 0: Set aside dedicated time each day for reading.
Option 1: Set aside 30 minutes of dedicated reading time each day.
Option 2: Set aside dedicated time each day for reading.
Option 3: Set aside dedicated time each day for reading.
Option 4: Join a book club.
---
Please discuss each option very briefly (one line for pros, one for cons), and end by saying Best=X, where X is the number of the best option.</code></pre>
</div>
</div>
<p>I know from experience that you are likely to get better results if you tell the language model to generate ideas in one shot. That way, the LLM can reference previous ideas and achieve more diversity. This is a good example of accidental complexity: its very tempting to take this design pattern and apply it blindly. This is less of a critique of this particular framework, since the code makes it clear that 5 independent calls will happen. Either way, its good idea to check your work by inspecting API calls!.</p>
</section>
<section id="langchain" class="level3">
<h3 class="anchored" data-anchor-id="langchain">Langchain</h3>
<p>Langchain is a multi-tool for all things LLM. Lots of people rely on Langchain when get started with LLMs. The core LangChain library doesn’t generally hide prompts from you, however there are experimental features that do. Let’s take a look at one of these features called <a href="https://api.python.langchain.com/en/latest/smart_llm/langchain_experimental.smart_llm.base.SmartLLMChain.html">SmartLLMChain</a>:</p>
<div id="600b1e60-6c01-429e-834b-470730b5ea26" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain.prompts <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PromptTemplate</span>
<span id="cb11-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_experimental.smart_llm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SmartLLMChain</span>
<span id="cb11-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ChatOpenAI</span>
<span id="cb11-4"></span>
<span id="cb11-5">hard_question <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"I have a 12 liter jug and a 6 liter jug.</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb11-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">I want to measure 6 liters. How do I do it?"</span></span>
<span id="cb11-7">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PromptTemplate.from_template(hard_question)</span>
<span id="cb11-8">llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ChatOpenAI(temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, model_name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-3.5-turbo"</span>)</span></code></pre></div>
</div>
<div id="bdb002f1-5f1b-40a7-ad4f-c9052813ef1f" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">chain <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SmartLLMChain(llm<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>llm, prompt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>prompt, </span>
<span id="cb12-2">                      n_ideas<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, </span>
<span id="cb12-3">                      verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb12-4">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> chain.run({})</span></code></pre></div>
</div>
<div id="13be7600-e9eb-4ed2-91d9-a8182858ca83" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(result)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Idea 1: 1. Fill the 12 liter jug completely.
2. Pour the contents of the 12 liter jug into the 6 liter jug. This will leave you with 6 liters in the 12 liter jug.
3. Empty the 6 liter jug.
4. Pour the remaining 6 liters from the 12 liter jug into the now empty 6 liter jug.
5. You now have 6 liters in the 6 liter jug.

Idea 2: 1. Fill the 12 liter jug completely.
2. Pour the contents of the 12 liter jug into the 6 liter jug. This will leave you with 6 liters in the 12 liter jug.
3. Empty the 6 liter jug.
4. Pour the remaining 6 liters from the 12 liter jug into the now empty 6 liter jug.
5. You now have 6 liters in the 6 liter jug.

Improved Answer:
1. Fill the 12 liter jug completely.
2. Pour the contents of the 12 liter jug into the 6 liter jug until the 6 liter jug is full. This will leave you with 6 liters in the 12 liter jug and the 6 liter jug completely filled.
3. Empty the 6 liter jug.
4. Pour the remaining 6 liters from the 12 liter jug into the now empty 6 liter jug.
5. You now have 6 liters in the 6 liter jug.

Full Answer:
To measure 6 liters using a 12 liter jug and a 6 liter jug, follow these steps:
1. Fill the 12 liter jug completely.
2. Pour the contents of the 12 liter jug into the 6 liter jug until the 6 liter jug is full. This will leave you with 6 liters in the 12 liter jug and the 6 liter jug completely filled.
3. Empty the 6 liter jug.
4. Pour the remaining 6 liters from the 12 liter jug into the now empty 6 liter jug.
5. You now have 6 liters in the 6 liter jug.</code></pre>
</div>
</div>
<p>Neat! So what happened exactly? While this API emits logs that show you a lot of information (available on <a href="https://gist.github.com/hamelsmu/abfb14b0af4c70e8532f9d4e0ef3e54e">this gist</a>), the API request pattern is interesting:</p>
<ol type="1">
<li><p>Two <em>seperate</em> api calls for each “idea”.</p></li>
<li><p>Another API call that incorporates the two ideas as context, with the prompt:</p>
<blockquote class="blockquote">
<p>You are a researcher tasked with investigating the 2 response options provided. List the flaws and faulty logic of each answer options. Let’w work this out in a step by step way to be sure we have all the errors:”</p>
</blockquote></li>
<li><p>A final API call that that takes the critique from step 2 and generates an answer.</p></li>
</ol>
<p>Its not clear that this approach is optimal. I am not sure it should take 4 separate API calls to accomplish this task. Perhaps the critique and the final answer could be generated in one step? Furthermore, the prompt has a spelling error (<code>Let'w</code>) and also overly focuses on the negative about identifying errors - which makes me skeptical that this prompt has been optimized or tested.</p>
</section>
<section id="instructor" class="level3">
<h3 class="anchored" data-anchor-id="instructor">Instructor</h3>
<p><a href="https://github.com/jxnl/instructor">Instructor</a> is a framework for structured outputs.</p>
<section id="structred-data-extraction-with-pydantic" class="level4">
<h4 class="anchored" data-anchor-id="structred-data-extraction-with-pydantic">Structred data extraction with Pydantic</h4>
<p>Here is a basic example from the project’s <a href="https://github.com/jxnl/instructor">README</a> that allows you to extract structured data by using Pydantic to define your schema.</p>
<div id="8469f9f6-6998-4de7-8551-c073929e385c" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> instructor</span>
<span id="cb15-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OpenAI</span>
<span id="cb15-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel</span>
<span id="cb15-4"></span>
<span id="cb15-5">client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> instructor.patch(OpenAI())</span>
<span id="cb15-6"></span>
<span id="cb15-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> UserDetail(BaseModel):</span>
<span id="cb15-8">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb15-9">    age: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span></span>
<span id="cb15-10"></span>
<span id="cb15-11">user <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> client.chat.completions.create(</span>
<span id="cb15-12">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-3.5-turbo"</span>,</span>
<span id="cb15-13">    response_model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>UserDetail,</span>
<span id="cb15-14">    messages<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Extract Jason is 25 years old"</span>}])</span></code></pre></div>
</div>
<p>We can see how this works by inspecting the API call logged to mitmproxy:</p>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode json code-overflow-wrap code-with-copy"><code class="sourceCode json"><span id="cb16-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb16-2">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"function_call"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb16-3">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"UserDetail"</span></span>
<span id="cb16-4">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb16-5">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"functions"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb16-6">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb16-7">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Correctly extracted `UserDetail` with all the required parameters with correct types"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb16-8">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"UserDetail"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb16-9">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"parameters"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb16-10">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"properties"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb16-11">                    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"age"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb16-12">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"title"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Age"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb16-13">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"integer"</span></span>
<span id="cb16-14">                    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb16-15">                    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb16-16">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"title"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb16-17">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"string"</span></span>
<span id="cb16-18">                    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb16-19">                <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb16-20">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"required"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb16-21">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"age"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb16-22">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span></span>
<span id="cb16-23">                <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb16-24">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"object"</span></span>
<span id="cb16-25">            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb16-26">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb16-27">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb16-28">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"messages"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb16-29">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb16-30">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"content"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Extract Jason is 25 years old"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb16-31">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"role"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span></span>
<span id="cb16-32">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb16-33">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb16-34">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"model"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-3.5-turbo"</span></span>
<span id="cb16-35"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
<p>This is great. For structured output - <strong>It does exactly what I want, and it correctly uses the OpenAI API the way I would use it</strong> if I were writing this manually (by defining a function schema). I would consider this specific API a zero-cost abstraction, meaning it does exactly what I expect it to with a minimal surface area.</p>
</section>
<section id="validation" class="level4">
<h4 class="anchored" data-anchor-id="validation">Validation</h4>
<p>However, instructor has other APIs that are more agressive and write prompts for you. For example, consider this <a href="https://python.useinstructor.com/tutorials/4-validation/">validation example</a>. Running through that example should trigger similar questions to the exploration of Langchain’s SmartLLMChain above. In this example, you will observe 3 LLM API calls to get the right answer, with the final payload looking like this:</p>
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb17-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-2">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"function_call"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-3">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Validator"</span></span>
<span id="cb17-4">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb17-5">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"functions"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-6">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-7">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Validate if an attribute is correct and if not,</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">return a new value with an error message"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-8">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Validator"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-9">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"parameters"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-10">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"properties"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-11">                    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"fixed_value"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-12">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"anyOf"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-13">                            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-14">                                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"string"</span></span>
<span id="cb17-15">                            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-16">                            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-17">                                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"null"</span></span>
<span id="cb17-18">                            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-19">                        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-20">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"default"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">null</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-21">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"If the attribute is not valid, suggest a new value for the attribute"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-22">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"title"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Fixed Value"</span></span>
<span id="cb17-23">                    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb17-24">                    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"is_valid"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-25">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"default"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">true</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-26">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Whether the attribute is valid based on the requirements"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-27">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"title"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Is Valid"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-28">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"boolean"</span></span>
<span id="cb17-29">                    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb17-30">                    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"reason"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-31">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"anyOf"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-32">                            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-33">                                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"string"</span></span>
<span id="cb17-34">                            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-35">                            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-36">                                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"null"</span></span>
<span id="cb17-37">                            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-38">                        <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-39">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"default"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">null</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-40">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The error message if the attribute is not valid, otherwise None"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-41">                        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"title"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Reason"</span></span>
<span id="cb17-42">                    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-43">                <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb17-44">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"required"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-45">                <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"object"</span></span>
<span id="cb17-46">            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-47">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-48">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-49">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"messages"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb17-50">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-51">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"content"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"You are a world class validation model. Capable to determine if the following value is valid for the statement, if it is not, explain why and suggest a new value."</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-52">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"role"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"system"</span></span>
<span id="cb17-53">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-54">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb17-55">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"content"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Does `According to some perspectives, the meaning of life is to find purpose, happiness, and fulfillment. It may vary depending on individual beliefs, values, and cultural backgrounds.` follow the rules: don't say objectionable things"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-56">            <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"role"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span></span>
<span id="cb17-57">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb17-58">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-59">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"model"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-3.5-turbo"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb17-60">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"temperature"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb17-61"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
<p>Concretely, I’m curious if these steps could be collapsed into two LLM calls instead of three. Furthermore, I wonder if generic validation functions (as supplied in the above payload) are the right way to critique output? I don’t know the answer, but this is an interesting design pattern that is worth poking at.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>As far as LLM frameworks go, I really like this one. The core functionality of defining schemas with Pydantic is very convenient. The code is also very readable and easy to understand. Despite this, I still found it helpful to intercept instructor’s API calls to get another perspective.</p>
<p>There is a way to set a logging level in instructor to see the raw API calls, however, I like using a framework agnostic approach :)</p>
</div>
</div>
</section>
</section>
<section id="dspy" class="level3">
<h3 class="anchored" data-anchor-id="dspy">DSPy</h3>
<p><a href="https://github.com/stanfordnlp/dspy">DSPy</a> is the framework that helps you optimize your prompts to optimize any arbitrary metric. There is a fairly steep learning curve to DSPy, partly because it introduces many new technical terms specific to its framework like compilers and teleprompters. However, we can quickly peel back the complexity by looking at the API calls that it makes!</p>
<p>Let’s run the <a href="https://dspy-docs.vercel.app/docs/quick-start/minimal-example">minimal working example</a>:</p>
<div id="a3e9870b-741b-4b48-8dd4-c7b619fe8693" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> time</span>
<span id="cb18-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> dspy</span>
<span id="cb18-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> dspy.datasets.gsm8k <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GSM8K, gsm8k_metric</span>
<span id="cb18-4">start_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time()</span>
<span id="cb18-5"></span>
<span id="cb18-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set up the LM</span></span>
<span id="cb18-7">turbo <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.OpenAI(model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gpt-3.5-turbo-instruct'</span>, max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">250</span>)</span>
<span id="cb18-8">dspy.settings.configure(lm<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>turbo)</span>
<span id="cb18-9"></span>
<span id="cb18-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load math questions from the GSM8K dataset</span></span>
<span id="cb18-11">gms8k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GSM8K()</span>
<span id="cb18-12">trainset, devset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gms8k.train, gms8k.dev</span></code></pre></div>
</div>
<div id="fba9a01d-da36-43ba-a2be-2c6801f9154e" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> CoT(dspy.Module):</span>
<span id="cb19-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb19-3">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb19-4">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.prog <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dspy.ChainOfThought(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question -&gt; answer"</span>)</span>
<span id="cb19-5">    </span>
<span id="cb19-6">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, question):</span>
<span id="cb19-7">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.prog(question<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>question)</span></code></pre></div>
</div>
<div id="95f7feaf-0ad0-4691-9488-a6214abc2bcd" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> dspy.teleprompt <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BootstrapFewShotWithRandomSearch</span>
<span id="cb20-2"></span>
<span id="cb20-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set up the optimizer: we want to "bootstrap" (i.e., self-generate) 8-shot examples of our CoT program.</span></span>
<span id="cb20-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The optimizer will repeat this 10 times (plus some initial attempts) before selecting its best attempt on the devset.</span></span>
<span id="cb20-5">config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>(max_bootstrapped_demos<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, max_labeled_demos<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, num_candidate_programs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, num_threads<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb20-6"></span>
<span id="cb20-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Optimize! Use the `gms8k_metric` here. In general, the metric is going to tell the optimizer how well it's doing.</span></span>
<span id="cb20-8">teleprompter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BootstrapFewShotWithRandomSearch(metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>gsm8k_metric, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>config)</span>
<span id="cb20-9">optimized_cot <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> teleprompter.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>(CoT(), trainset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>trainset, valset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>devset)</span></code></pre></div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This was not very minimal
</div>
</div>
<div class="callout-body-container callout-body">
<p>Despite this being the official <a href="https://dspy-docs.vercel.app/docs/quick-start/minimal-example">quick-start/minimal working</a> example, this code took <strong>more than 30 minutes to run, and made hundreds of calls to OpenAI!</strong> This cost non-trivial time (and money), especially as an entry-point to the library for someone trying to take a look. There was no prior warning that this would happen.</p>
</div>
</div>
<p>DSPy made 100s of API calls because it was iteratively sampling examples for a few-shot prompt and selecting the best ones according to the <code>gsm8k_metric</code> on a validation set. I was able to quickly understand this by scanning through the API requests logged to mitmproxy.</p>
<p>DSPy offers an <code>inspect_history</code> method which allows you to see the the last <code>n</code> prompts and their completions:</p>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">turbo.inspect_history(n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
<p>I was able to verify that these prompts matched the last few API calls being made in mitmproxy. Overall, I would be motivated to potentially keep the prompt and and jettison the library. That being said, I think I am curious to see how this library evolves.</p>
</section>
</section>
<section id="my-personal-experience" class="level2">
<h2 class="anchored" data-anchor-id="my-personal-experience">My Personal Experience</h2>
<p>Do I hate LLM libraries? No! I think many of the libraries in this blog post could be helpful if used thoughtfully in the right situations. However, I’ve witnessed too many people fall into the trap of using these libraries without understanding what they are doing.</p>
<p>One thing I focus on as an independent consultant is to make sure my clients don’t take on accidental complexity. It’s very tempting to adopt additional tools given all the excitement around LLMs. Looking at prompts is one way to mitigate that temptation.</p>
<p>I’m wary of frameworks that distance the human too far from LLMs. By whispering <em>“Fuck you, show me the prompt!”</em> when using these tools, you are empowered to decide for yourself.<sup>1</sup></p>
<p><br> <br></p>
<div class="acknowledgments">
<p><em>Acknowledgments: Thanks to <a href="https://twitter.com/jeremyphoward">Jeremy Howard</a> and <a href="https://twitter.com/bclavie">Ben Clavie</a> for thoughtfully reviewing this post.</em></p>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>You don’t have to whisper. Saying it out loud is fine too - let others know!↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>llms</category>
  <category>ml</category>
  <guid>https://hamel.dev/blog/posts/prompt/</guid>
  <pubDate>Wed, 14 Feb 2024 08:00:00 GMT</pubDate>
  <media:content url="https://hamel.dev/blog/posts/prompt/slap_3.png" medium="image" type="image/png" height="72" width="144"/>
</item>
<item>
  <title>How To Debug Axolotl</title>
  <dc:creator>Hamel Husain</dc:creator>
  <link>https://hamel.dev/blog/posts/axolotl/</link>
  <description><![CDATA[ 




<p><img src="https://hamel.dev/blog/posts/axolotl/images/debug_axolotl.png" class="img-fluid"></p>
<section id="motivation" class="level2">
<h2 class="anchored" data-anchor-id="motivation">Motivation</h2>
<p><a href="https://github.com/OpenAccess-AI-Collective/axolotl">Axolotl</a> is a great project for fine-tuning LLMs. I started contributing to the project, and I found that it was difficult to debug. I wanted to share some tips and tricks I learned along the way, along with configuration files for debugging with VSCode. Moreover, I think being able to debug axolotl empowers developers who encounter bugs or want to understand how the code works. I hope this document helps you get started.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This content is now part of the Axolotl docs!
</div>
</div>
<div class="callout-body-container callout-body">
<p><a href="https://github.com/OpenAccess-AI-Collective/axolotl/pull/1089">I contributed</a> this blog post’s contents as documentation for the axolotl project. <strong>You can find this content <a href="https://github.com/OpenAccess-AI-Collective/axolotl/blob/main/docs/debugging.md">in the axolotl repo here</a></strong>.</p>
</div>
</div>
</section>
<section id="general-tips" class="level2">
<h2 class="anchored" data-anchor-id="general-tips">General Tips</h2>
<p>While debugging, it’s helpful to simplify your test scenario as much as possible. Here are some tips for doing so:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>All of these tips are incorporated into the example configuration for debugging with VSCode below.</p>
</div>
</div>
<ol type="1">
<li><p><strong>Make sure you are using the latest version of axolotl</strong>: This project changes often and bugs get fixed fast. Check your git branch and make sure you have pulled the latest changes from <code>main</code>.</p></li>
<li><p><strong>Eliminate Concurrency</strong>: Restrict the number of processes to 1 for both training and data preprocessing:</p>
<ul>
<li>Set <code>CUDA_VISIBLE_DEVICES</code> to a single GPU, ex: <code>export CUDA_VISIBLE_DEVICES=0</code>.</li>
<li>Set <code>dataset_processes: 1</code> in your axolotl config or run the training command with <code>--dataset_processes=1</code>.</li>
</ul></li>
<li><p><strong>Use a small dataset</strong>: Construct or use a small dataset from HF Hub. When using a small dataset, you will often have to make sure <code>sample_packing: False</code> and <code>eval_sample_packing: False</code> to avoid errors. If you are in a pinch and don’t have time to construct a small dataset but want to use from the HF Hub, you can shard the data (this will still tokenize the entire dataset but will only use a fraction of the data for training. For example, to shard the dataset into 20 pieces, add the following to your axolotl config):</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dataset</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb1-2"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    ...</span></span>
<span id="cb1-3"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">shards</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span></span></code></pre></div></li>
<li><p><strong>Use a small model</strong>: A good example of a small model is <a href="https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0">TinyLlama/TinyLlama-1.1B-Chat-v1.0</a>.</p></li>
<li><p><strong>Minimize iteration time</strong>: Make sure the training loop finishes as fast as possible, with these settings.</p>
<ul>
<li><code>micro_batch_size: 1</code></li>
<li><code>max_steps: 1</code></li>
<li><code>val_set_size: 0</code></li>
</ul></li>
<li><p><strong>Clear Caches:</strong> Axolotl caches certain steps and so does the underlying HuggingFace trainer. You may want to clear some of these caches when debugging.</p>
<ul>
<li>Data preprocessing: When debugging data preprocessing, which includes prompt template formation, you may want to delete the directory set in <code>dataset_prepared_path:</code> in your axolotl config. If you didn’t set this value, the default is <code>last_run_prepared</code>.</li>
<li>HF Hub: If you are debugging data preprocessing, you should clear the relevant HF cache <a href="https://huggingface.co/docs/datasets/cache">HuggingFace cache</a>, by deleting the appropriate <code>~/.cache/huggingface/datasets/...</code> folder(s).</li>
<li><strong>The recommended approach is to redirect all outputs and caches to a temporary folder and delete selected subfolders before each run. This is demonstrated in the example configuration below.</strong></li>
</ul></li>
</ol>
</section>
<section id="debugging-with-vscode" class="level2">
<h2 class="anchored" data-anchor-id="debugging-with-vscode">Debugging with VSCode</h2>
<section id="background" class="level3">
<h3 class="anchored" data-anchor-id="background">Background</h3>
<p>The below example shows how to configure VSCode to debug data preprocessing of the <code>sharegpt</code> format. This is the format used when you have the following in your axolotl config:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb2-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">datasets</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb2-2"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">-</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">path</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> &lt;path to your sharegpt formatted dataset&gt;</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"> # example on HF Hub: philschmid/guanaco-sharegpt-style</span></span>
<span id="cb2-3"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">type</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> sharegpt</span></span></code></pre></div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>If you are already familiar with advanced VSCode debugging, you can skip the below explanation and look at the files <a href="../.vscode/launch.json">.vscode/launch.json</a> and <a href="https://github.com/OpenAccess-AI-Collective/axolotl/blob/main/.vscode/tasks.json">.vscode/tasks.json</a> for an example configuration.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>If you prefer to watch a video, rather than read, you can skip to the video tutorial below (but doing both is recommended).</p>
</div>
</div>
</section>
<section id="setup" class="level3">
<h3 class="anchored" data-anchor-id="setup">Setup</h3>
<p>Make sure you have an <a href="https://setuptools.pypa.io/en/latest/userguide/development_mode.html">editable install</a> of Axolotl, which ensures that changes you make to the code are reflected at runtime. Run the following commands from the root of this project:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip3</span> install packaging</span>
<span id="cb3-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip3</span> install <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-e</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'.[flash-attn,deepspeed]'</span></span></code></pre></div>
<section id="remote-hosts" class="level4">
<h4 class="anchored" data-anchor-id="remote-hosts">Remote Hosts</h4>
<p>If you developing on a remote host, you can easily use VSCode to debug remotely. To do so, you will need to follow this <a href="https://code.visualstudio.com/docs/remote/ssh">remote - SSH guide</a>. You can also see the video below on Docker and Remote SSH debugging.</p>
</section>
</section>
<section id="configuration" class="level3">
<h3 class="anchored" data-anchor-id="configuration">Configuration</h3>
<p>The easiest way to get started is to modify the <a href="https://github.com/OpenAccess-AI-Collective/axolotl/blob/main/.vscode/launch.json">.vscode/launch.json</a> file in the axolotl GitHub repo. This is just an example configuration, so you may need to modify or copy it to suit your needs.</p>
<p>For example, to mimic the command <code>cd devtools &amp;&amp; CUDA_VISIBLE_DEVICES=0 accelerate launch -m axolotl.cli.train dev_sharegpt.yml</code>, you would use the below configuration<sup>1</sup>. Note that we add additional flags that override the axolotl config and incorporate the tips above (see the comments). We also set the working directory to <code>devtools</code> and set the <code>env</code> variable <code>HF_HOME</code> to a temporary folder that is later partially deleted. This is because we want to delete the HF dataset cache before each run in order to ensure that the data preprocessing code is run from scratch.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// https://github.com/OpenAccess-AI-Collective/axolotl/blob/main/.vscode/launch.json</span></span>
<span id="cb4-2">{</span>
<span id="cb4-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"version"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0.2.0"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb4-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configurations"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> [</span>
<span id="cb4-5">        {</span>
<span id="cb4-6">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Debug axolotl prompt - sharegpt"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb4-7">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"python"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb4-8">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"module"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"accelerate.commands.launch"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb4-9">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"request"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"launch"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb4-10">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"args"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> [</span>
<span id="cb4-11">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"-m"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"axolotl.cli.train"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"dev_sharegpt.yml"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb4-12">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// The flags below simplify debugging by overriding the axolotl config </span></span>
<span id="cb4-13">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// with the debugging tips above.  Modify as needed.</span></span>
<span id="cb4-14">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"--dataset_processes=1"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span>      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// limits data preprocessing to one process</span></span>
<span id="cb4-15">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"--max_steps=1"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span>              <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// limits training to just one step</span></span>
<span id="cb4-16">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"--batch_size=1"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span>             <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// minimizes batch size</span></span>
<span id="cb4-17">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"--micro_batch_size=1"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span>       <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// minimizes batch size</span></span>
<span id="cb4-18">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"--val_set_size=0"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span>           <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// disables validation</span></span>
<span id="cb4-19">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"--sample_packing=False"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span>     <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// disables sample packing which is necessary for small datasets</span></span>
<span id="cb4-20">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"--eval_sample_packing=False"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// disables sample packing on eval set</span></span>
<span id="cb4-21">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"--dataset_prepared_path=temp_debug/axolotl_outputs/data"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// send data outputs to a temp folder</span></span>
<span id="cb4-22">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"--output_dir=temp_debug/axolotl_outputs/model"</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// send model outputs to a temp folder</span></span>
<span id="cb4-23">                ]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb4-24">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"console"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"integratedTerminal"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span>      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// show output in the integrated terminal</span></span>
<span id="cb4-25">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cwd"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"${workspaceFolder}/devtools"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// set working directory to devtools from the root of the project</span></span>
<span id="cb4-26">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"justMyCode"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">true</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span>                   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// step through only axolotl code</span></span>
<span id="cb4-27">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"env"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CUDA_VISIBLE_DEVICES"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Since we aren't doing distributed training, we need to limit to one GPU</span></span>
<span id="cb4-28">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HF_HOME"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"${workspaceFolder}/devtools/temp_debug/.hf-cache"</span>}<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// send HF cache to a temp folder</span></span>
<span id="cb4-29">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"preLaunchTask"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cleanup-for-dataprep"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// delete temp folders (see below)</span></span>
<span id="cb4-30">        }</span>
<span id="cb4-31">    ]</span>
<span id="cb4-32">}</span></code></pre></div>
<p><strong>Additional notes about this configuration:</strong></p>
<ul>
<li>The argument <code>justMyCode</code> is set to <code>true</code> such that you step through only the axolotl code. If you want to step into dependencies, set this to <code>false</code>.</li>
<li>The <code>preLaunchTask</code>: <code>cleanup-for-dataprep</code> is defined in <a href="https://github.com/OpenAccess-AI-Collective/axolotl/blob/main/.vscode/tasks.json">.vscode/tasks.json</a> and is used to delete the following folders before debugging, which is essential to ensure that the data pre-processing code is run from scratch:
<ul>
<li><code>./devtools/temp_debug/axolotl_outputs</code></li>
<li><code>./devtools/temp_debug/.hf-cache/datasets</code></li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>You may not want to delete these folders. For example, if you are debugging model training instead of data pre-processing, you may NOT want to delete the cache or output folders. You may also need to add additional tasks to the <code>tasks.json</code> file depending on your use case.</p>
</div>
</div>
<p>Below is the <a href="https://github.com/OpenAccess-AI-Collective/axolotl/blob/main/.vscode/tasks.json">./vscode/tasks.json</a> file that defines the <code>cleanup-for-dataprep</code> task. This task is run before each debugging session when you use the above configuration. Note how there are two tasks that delete the two folders mentioned above. The third task <code>cleanup-for-dataprep</code> is a composite task that combines the two tasks. A composite task is necessary because VSCode does not allow you to specify multiple tasks in the <code>preLaunchTask</code> argument of the <code>launch.json</code> file.</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// https://github.com/OpenAccess-AI-Collective/axolotl/blob/main/.vscode/tasks.json</span></span>
<span id="cb5-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// this file is used by launch.json</span></span>
<span id="cb5-3">{</span>
<span id="cb5-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"version"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"2.0.0"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb5-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tasks"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> [</span>
<span id="cb5-6">      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// this task changes into the devtools directory and deletes the temp_debug/axolotl_outputs folder</span></span>
<span id="cb5-7">      {</span>
<span id="cb5-8">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"label"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"delete-outputs"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb5-9">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"shell"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb5-10">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"command"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rm -rf temp_debug/axolotl_outputs"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb5-11">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"options"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>{ <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cwd"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"${workspaceFolder}/devtools"</span>}<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb5-12">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"problemMatcher"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> []</span>
<span id="cb5-13">      }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb5-14">      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// this task changes into the devtools directory and deletes the `temp_debug/.hf-cache/datasets` folder</span></span>
<span id="cb5-15">      {</span>
<span id="cb5-16">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"label"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"delete-temp-hf-dataset-cache"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb5-17">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"shell"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb5-18">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"command"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rm -rf temp_debug/.hf-cache/datasets"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb5-19">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"options"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>{ <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cwd"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"${workspaceFolder}/devtools"</span>}<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb5-20">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"problemMatcher"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> []</span>
<span id="cb5-21">      }<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb5-22">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// this task combines the two tasks above</span></span>
<span id="cb5-23">      {</span>
<span id="cb5-24">       <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"label"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cleanup-for-dataprep"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb5-25">       <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"dependsOn"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"delete-outputs"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"delete-temp-hf-dataset-cache"</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb5-26">      }</span>
<span id="cb5-27">    ]</span>
<span id="cb5-28">}</span></code></pre></div>
</section>
<section id="customizing-your-debugger" class="level3">
<h3 class="anchored" data-anchor-id="customizing-your-debugger">Customizing your debugger</h3>
<p>Your debugging use case may differ from the example above. The easiest thing to do is to put your own axolotl config in the <code>devtools</code> folder and modify the <code>launch.json</code> file to use your config. You may also want to modify the <code>preLaunchTask</code> to delete different folders or not delete anything at all.</p>
</section>
<section id="video-tutorial" class="level3">
<h3 class="anchored" data-anchor-id="video-tutorial">Video Tutorial</h3>
<p>The following video tutorial walks through the above configuration and demonstrates how to debug with VSCode:</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/xUUB11yeMmc" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
</section>
<section id="debugging-with-docker" class="level2">
<h2 class="anchored" data-anchor-id="debugging-with-docker">Debugging With Docker</h2>
<p>Using <a href="https://hub.docker.com/r/winglian/axolotl/tags">official Axolotl Docker images</a> is a great way to debug your code, and is a very popular way to use Axolotl. Attaching VSCode to Docker takes a few more steps.</p>
<section id="setup-1" class="level3">
<h3 class="anchored" data-anchor-id="setup-1">Setup</h3>
<p>On the host that is running axolotl (ex: if you are using a remote host), clone the axolotl repo and change your current directory to the root:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> clone https://github.com/OpenAccess-AI-Collective/axolotl</span>
<span id="cb6-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">cd</span> axolotl</span></code></pre></div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>If you already have axolotl cloned on your host, make sure you have the latest changes and change into the root of the project.</p>
</div>
</div>
<p>Next, run the desired docker image and mount the current directory. Below is a docker command you can run to do this:<sup>2</sup></p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">docker</span> run <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--privileged</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--gpus</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'"all"'</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--shm-size</span> 10g <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--rm</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-it</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--name</span> axolotl <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--ipc</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>host <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--ulimit</span> memlock=-1 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--ulimit</span> stack=67108864 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--mount</span> type=bind,src=<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">${PWD}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,target=/workspace/axolotl <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-v</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">${HOME}</span>/.cache/huggingface:/root/.cache/huggingface winglian/axolotl:main-py3.10-cu118-2.0.1</span></code></pre></div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>To understand which containers are available, see the <a href="../README.md#docker">Docker section of the README</a> and the <a href="https://hub.docker.com/r/winglian/axolotl/tags">DockerHub repo</a>. For details of how the Docker containers are built, see axolotl’s <a href="../.github/workflows/main.yml">Docker CI builds</a>.</p>
</div>
</div>
<p>You will now be in the container. Next, perform an editable install of Axolotl:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip3</span> install packaging</span>
<span id="cb8-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip3</span> install <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-e</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'.[flash-attn,deepspeed]'</span></span></code></pre></div>
</section>
<section id="attach-to-container" class="level3">
<h3 class="anchored" data-anchor-id="attach-to-container">Attach To Container</h3>
<p>Next, if you are using a remote host, <a href="https://code.visualstudio.com/docs/remote/ssh">Remote into this host with VSCode</a>. If you are using a local host, you can skip this step.</p>
<p>Next, select <code>Dev Containers: Attach to Running Container...</code> using the command palette (<code>CMD + SHIFT + P</code>) in VSCode. You will be prompted to select a container to attach to. Select the container you just created. You will now be in the container with a working directory that is at the root of the project. Any changes you make to the code will be reflected both in the container and on the host.</p>
<p>Now you are ready to debug as described above (see Debugging with VSCode).</p>
</section>
<section id="video---attaching-to-docker-on-remote-host" class="level3">
<h3 class="anchored" data-anchor-id="video---attaching-to-docker-on-remote-host">Video - Attaching To Docker On Remote Host</h3>
<p>Here is a short video that demonstrates how to attach to a Docker container on a remote host:</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/0AuoR7QnHR0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>


</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>The config actually mimics the command <code>CUDA_VISIBLE_DEVICES=0 python -m accelerate.commands.launch -m axolotl.cli.train devtools/sharegpt.yml</code>, but this is the same thing.↩︎</p></li>
<li id="fn2"><p>Many of the below flags are recommended best practices by Nvidia when using nvidia-container-toolkit. You can read more about these flags <a href="https://docs.nvidia.com/deeplearning/frameworks/user-guide/index.html">here</a>.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>LLMs</category>
  <category>fine-tuning</category>
  <category>axolotl</category>
  <guid>https://hamel.dev/blog/posts/axolotl/</guid>
  <pubDate>Thu, 11 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="https://hamel.dev/blog/posts/axolotl/images/debug_axolotl_small.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Dokku: my favorite personal serverless platform</title>
  <dc:creator>Hamel Husain</dc:creator>
  <link>https://hamel.dev/blog/posts/dokku/</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/dokku/images/serverless.png" class="img-fluid figure-img"></p>
<figcaption>With Dokku, you can turn a VPS into a powerful serverless platform</figcaption>
</figure>
</div>
<section id="what-is-dokku" class="level2">
<h2 class="anchored" data-anchor-id="what-is-dokku">What is Dokku?</h2>
<p><a href="https://dokku.com/">Dokku</a> is an open-source Platform as a Service (PaaS) that runs on a single server of your choice. <strong>It’s like <a href="https://www.heroku.com/">Heroku</a>, but you own it.</strong> It is a great way to get the benefits of Heroku without the costs (Heroku can get quite expensive!). I need to deploy many applications for my <a href="https://parlance-labs.com/">LLM consulting work</a>. Having a cost-effective, easy-to-use serverless platform is essential for me.</p>
<p><strong>I run a Dokku server on a $7/month VPS on <a href="https://us.ovhcloud.com/">OVHcloud</a></strong> for non-gpu workloads. These applications include things like <a href="https://nbsanity.com/">nbsanity</a> and <a href="https://langfree.parlance-labs.com/tutorials/shiny.html#run-the-shiny-app-locally">data cleaning tools for LLMs</a>.</p>
<p>Some of the features I love about Dokku:</p>
<ul>
<li>Easy to use (like Heroku).</li>
<li>Automatic SSL certificate management via <a href="https://letsencrypt.org/">Let’s Encrypt</a>.</li>
<li>Basic Auth support so I can password-protect sites.</li>
<li>Scale up and down with a single command.</li>
<li>Flexibility to handle any application (Node, Python, etc), including defining a Docker container.</li>
<li>Lots of <a href="https://dokku.com/docs/community/plugins/?h=plugins#official-plugins">official plugins</a> that do almost anything I want.</li>
<li>Easily deploy with git commands.</li>
</ul>
</section>
<section id="minimal-dokku-examples" class="level1">
<h1>Minimal Dokku Examples</h1>
<p>Make sure you <a href="https://dokku.com/docs/getting-started/installation/">install Dokku</a> on your VPS. As I mentioned, I use <a href="https://us.ovhcloud.com/">OVH</a>.</p>
<section id="deploying-apps-as-a-docker-container" class="level2">
<h2 class="anchored" data-anchor-id="deploying-apps-as-a-docker-container">Deploying Apps as A Docker Container</h2>
<p>An easy way to deploy applications is with a Docker container.</p>
<p>To deploy a Docker container, I put a Dockerfile in the root of my git repo like this:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>Dockerfile</strong></pre>
</div>
<div class="sourceCode" id="cb1" data-filename="Dockerfile" style="background: #f1f3f5;"><pre class="sourceCode dockerfile code-with-copy"><code class="sourceCode dockerfile"><span id="cb1-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">FROM</span> python:3.10</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">COPY</span> . /app</span>
<span id="cb1-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">WORKDIR</span> /app</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install the local package</span></span>
<span id="cb1-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">RUN</span> <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install .</span>
<span id="cb1-8"></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This directory contains app.py, a FastApi app</span></span>
<span id="cb1-10"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">WORKDIR</span> /app/</span>
<span id="cb1-11"></span>
<span id="cb1-12"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">ENTRYPOINT</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./entrypoint.sh"</span>]</span></code></pre></div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <code>entrypoint.sh</code> script allows me to easily run the app locally or in a Docker container. It looks like this:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>entrypoint.sh</strong></pre>
</div>
<div class="sourceCode" id="cb2" data-filename="entrypoint.sh" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#!/bin/bash</span></span>
<span id="cb2-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">exec</span> uvicorn main:app <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--port</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$PORT</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--host</span> 0.0.0.0</span></code></pre></div>
</div>
</div>
</div>
<p>On the Dokku host, create the app:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">dokku</span> apps:create myapp</span></code></pre></div>
<p><strong>Locally</strong>, set up access to the Dokku host and name it <code>dokku</code> in your <code>~/.ssh/config</code> file. For example, here is mine:</p>
<pre><code>Host dokku
  HostName &lt;The external IP address of your Dokku host&gt;
  User ubuntu
  IdentityFile /Users/hamel/.ssh/dokku</code></pre>
<p>Locally, add the Dokku host as a remote and push to it:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> remote add dokku dokku@dokku:myapp</span>
<span id="cb5-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> push dokku main</span></code></pre></div>
<p>That’s it - your app should be running on the Dokku host! Your local logs will print the URL that your application is served on, which by default will be <code>myapp.yourdomain.com</code>. You can also scale it up/down with the following command:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#scale to two workers</span></span>
<span id="cb6-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">dokku</span> ps:scale myapp web=2</span></code></pre></div>
<p>We are just scratching the surface. For more details, see the <a href="https://dokku.com/docs/">Dokku docs</a>.</p>
</section>
<section id="static-sites" class="level2">
<h2 class="anchored" data-anchor-id="static-sites">Static Sites</h2>
<p>GitHub Pages is annoying in that you can’t easily deploy private static sites without paying for an expensive Enterprise account. With Dokku, you can easily deploy a static site from a private GitHub Repo and password-protect it.</p>
<p>We will assume that you have a static site in a git repo in a folder named <code>_site</code>.</p>
<p><strong>On the Dokku host</strong>, create an app named <code>mysite</code> and set the <code>NGINX_ROOT</code> environment variable to <code>_site</code>:</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">dokku</span> apps:create mysite</span>
<span id="cb7-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">dokku</span> config:set static-site NGINX_ROOT=_site</span></code></pre></div>
<p>Also on the Dokku host, install <a href="https://github.com/dokku/dokku-http-auth">basic auth</a> and <a href="https://github.com/dokku/dokku-http-auth/issues/15#issuecomment-1637058437">set permissions</a> so the plugin can work properly.</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># do setup for the auth plugin that we will use later</span></span>
<span id="cb8-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> dokku plugin:install https://github.com/dokku/dokku-http-auth.git</span>
<span id="cb8-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> chmod +x /home/dokku</span></code></pre></div>
<p>Then execute the following commands from the root of your git repo that contains the static site. :</p>
<div class="sourceCode" id="annotated-cell-8" style="background: #f1f3f5;"><pre class="sourceCode bash code-annotation-code code-with-copy code-annotated"><code class="sourceCode bash"><a class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-8-1" class="code-annotation-target"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">touch</span> .static</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-8-2" class="code-annotation-target"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">echo</span> BUILDPACK_URL=https://github.com/dokku/buildpack-nginx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> .env</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-8-3" class="code-annotation-target"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> remote add dokku dokku@dokku:mysite</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-8" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="1" data-code-annotation="1">tells <code>dokku</code> that this is a static site</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="2" data-code-annotation="2">tells <code>dokku</code> to use the nginx buildpack for static sites (it will usually automatically detect this, but if you have a project with code and a static site, you need to tell it to use the nginx buildpack so it doesn’t get confused).</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="3" data-code-annotation="3">add the <code>dokku</code> host as a remote. For this to work, make sure <code>dokku</code> is a hostname in your <code>~/.ssh/config</code> file as described in the previous section.</span>
</dd>
</dl>
<p>Finally, deploy your application:</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> push dokku main</span></code></pre></div>
<p>You can now add auth by running the following command on the Dokku host:</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">dokku</span> http-auth:enable mysite <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span>username<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span>password<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span></span></code></pre></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>You can add multiple usernames/passwords and even filter specific IPs. See <a href="https://github.com/dokku/dokku-http-auth">the docs</a>.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
SSL / HTTPS
</div>
</div>
<div class="callout-body-container callout-body">
<p>It’s often desirable to have HTTPS for your site. Dokku makes this easy with the <a href="https://github.com/dokku/dokku-letsencrypt">Let’s Encrypt Plugin</a>, which will even auto-renew for you. I don’t use this, because I’m letting <a href="https://developers.cloudflare.com/dns/manage-dns-records/reference/proxied-dns-records/">Cloudflare handle this with its proxy</a>.</p>
<p>If you are using Cloudflare this way, activating this plugin will mess things up (don’t worry its easy to disable). Honestly, I think it’s easier to let Cloudflare handle it if you are already doing so.</p>
</div>
</div>
</section>
</section>
<section id="deploying-with-github-actions" class="level1">
<h1>Deploying With GitHub Actions</h1>
<p>You can automatically deploy Dokku apps with GitHub Actions, which is helpful if you don’t want to fiddle with pushing to the Dokku host. Here is an example GitHub Action workflow that does this:</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>deploy-dokku.yml</strong></pre>
</div>
<div class="sourceCode" id="cb11" data-filename="deploy-dokku.yml" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb11-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">name</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> CI</span></span>
<span id="cb11-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">on</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-3"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">workflow_dispatch</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-4"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">push</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-5"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">branches</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">[</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">main</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">]</span></span>
<span id="cb11-6"></span>
<span id="cb11-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">concurrency</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"> # Cancel previous jobs to avoid deploy locks on dokku</span></span>
<span id="cb11-8"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">group</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> ${{ github.ref }}</span></span>
<span id="cb11-9"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cancel-in-progress</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">true</span></span>
<span id="cb11-10"></span>
<span id="cb11-11"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">jobs</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-12"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">deploy-dokku</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-13"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">runs-on</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> ubuntu-latest</span></span>
<span id="cb11-14"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">steps</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-15"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">-</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">name</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> Checkout code</span></span>
<span id="cb11-16"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">        </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">uses</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> actions/checkout@v2</span></span>
<span id="cb11-17"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">        </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">with</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-18"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">          </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fetch-depth</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb11-19"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span></span>
<span id="cb11-20"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">-</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">name</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> Install SSH key</span></span>
<span id="cb11-21"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">        run</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">: </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">|</span></span>
<span id="cb11-22">          echo "${{ secrets.DOKKU_SSH_PRIVATE_KEY }}" &gt; private_key.pem</span>
<span id="cb11-23">          chmod 600 private_key.pem</span>
<span id="cb11-24"></span>
<span id="cb11-25"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">-</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">name</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> Add remote and push</span></span>
<span id="cb11-26"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">        run</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">: </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">|</span></span>
<span id="cb11-27">          git remote add dokku dokku@rechat.co:llm-eval</span>
<span id="cb11-28">          GIT_SSH_COMMAND="ssh -i private_key.pem -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no" git push dokku main -f</span></code></pre></div>
</div>
</section>
<section id="miscellaneous-tips" class="level1">
<h1>Miscellaneous Tips</h1>
<p>These are things I often forget, so I’m writing them down here. For these examples, assume my app is named <code>llm-eval</code> and my host is <code>rechat.co</code>.</p>
<section id="run-commands-remotely" class="level2">
<h2 class="anchored" data-anchor-id="run-commands-remotely">Run commands remotely</h2>
<p>You don’t have to ssh into the Dokku host just to execute commands. You can execute them remotely via the <code>dokku</code> user like this:</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># https://dokku.com/docs/deployment/application-management/</span></span>
<span id="cb12-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ssh</span> dokku@rechat.co apps:list</span></code></pre></div>
</section>
<section id="docker-cache" class="level2">
<h2 class="anchored" data-anchor-id="docker-cache">Docker cache</h2>
<p>This is how you can <a href="https://dokku.com/docs/advanced-usage/repository-management/">invalidate the docker cache</a> for a fresh build:</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb13-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ssh</span> dokku@rechat.co repo:purge-cache llm-eval</span></code></pre></div>
</section>
<section id="rebuild-without-pushing" class="level2">
<h2 class="anchored" data-anchor-id="rebuild-without-pushing">Rebuild without pushing</h2>
<p>Sometimes you want to rebuild without pushing. There are <a href="https://dokku.com/docs/processes/process-management/">many ways to do this</a>, but one way is like this:</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb14-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ssh</span> dokku@rechat.co ps:rebuild llm-eval</span></code></pre></div>
</section>
</section>
<section id="why-did-i-write-this" class="level1">
<h1>Why Did I Write This?</h1>
<p>I had to dig up these details whenever I wanted to deploy a new app, so I had to write it up anyway. I hope you find it useful, too!</p>


</section>

 ]]></description>
  <category>infra</category>
  <category>severless</category>
  <guid>https://hamel.dev/blog/posts/dokku/</guid>
  <pubDate>Tue, 09 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="https://hamel.dev/blog/posts/dokku/images/serverless.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Tokenization Gotchas</title>
  <link>https://hamel.dev/notes/llm/finetuning/tokenizer_gotchas.html</link>
  <description><![CDATA[ 




<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>Lots of people experience fiddly behavior when using LLMs. For example:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Unironically I found this to be very helpful when prompting LLMs. Giving them spaces and new lines <a href="https://t.co/vVuxcCuDzB">pic.twitter.com/vVuxcCuDzB</a>
</p>
— anton (<span class="citation" data-cites="abacaj">@abacaj</span>) <a href="https://twitter.com/abacaj/status/1728190808191537604?ref_src=twsrc%5Etfw">November 24, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>If you aren’t careful, these can be very hard to debug. This is because of the subtle ways tokenizers work that is not always easy to see by looking at the text.</p>
</section>
<section id="example" class="level2">
<h2 class="anchored" data-anchor-id="example">Example</h2>
<p>The below example demonstrates how things can get confusing and can drift between training and inference time.</p>
<div id="a14be044-f279-4856-8980-e7b15912f6a5" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoTokenizer</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> functools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> partial</span>
<span id="cb1-3">model_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Open-Orca/Mistral-7B-OpenOrca'</span></span>
<span id="cb1-4">tok <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoTokenizer.from_pretrained(model_id)</span></code></pre></div>
</div>
<div id="e0817615-1661-4fda-8757-4d0c7c51a2a6" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">enc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> partial(tok.encode, add_special_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb2-2">dec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> partial(tok.decode)</span></code></pre></div>
</div>
<section id="many-frameworks-do-prompt-construction-by-concatenating-tokens" class="level3">
<h3 class="anchored" data-anchor-id="many-frameworks-do-prompt-construction-by-concatenating-tokens">Many frameworks do prompt construction by concatenating tokens</h3>
<p>Popular frameworks like <a href="https://github.com/OpenAccess-AI-Collective/axolotl">axolotl</a> construct prompts by concatenating tokens instead of strings.<sup>1</sup> It is reasonable to decode the training data to check what the prompt template is:</p>
<p>For example, a prompt may be constructed like this:</p>
<div id="9c960919-7671-4493-b9c5-381da8d77ac6" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">axolotl <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> enc(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Ok</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> enc(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'&lt;|im_start|&gt;'</span>)</span>
<span id="cb3-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(dec(axolotl))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Ok
&lt;|im_start|&gt;</code></pre>
</div>
</div>
</section>
<section id="lets-say-you-have-an-inference-server" class="level3">
<h3 class="anchored" data-anchor-id="lets-say-you-have-an-inference-server">Let’s say you have an inference server</h3>
<p>It’s common for inference servers to assemble the prompt for you. The below looks like it should be fine, right?</p>
<div id="f93f0316-971e-44fd-8c97-a5c8df57f610" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> inf_server(inp): </span>
<span id="cb5-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>inp<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;|im_start|&gt;'</span></span>
<span id="cb5-3"></span>
<span id="cb5-4">srv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> inf_server(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Ok'</span>)</span>
<span id="cb5-5"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(srv)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Ok
&lt;|im_start|&gt;</code></pre>
</div>
</div>
</section>
<section id="drift-between-your-server-and-the-way-the-model-is-trained" class="level3">
<h3 class="anchored" data-anchor-id="drift-between-your-server-and-the-way-the-model-is-trained">Drift between your server and the way the model is trained</h3>
<p>Wrong! Notice the difference in the decoding of the prompt vs the training data. This is a subtle problem that can be hard to debug.</p>
<div id="7870389c-4a67-4542-bedb-e506e55993df" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'axolotl training data:  </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>axolotl<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb7-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"your server's decoding: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>enc(srv)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>axolotl training data:  [6504, 13, 32001]
your server's decoding: [6504, 32001]</code></pre>
</div>
</div>
</section>
</section>
<section id="solutions" class="level2">
<h2 class="anchored" data-anchor-id="solutions">Solutions</h2>
<section id="decode-your-inference-data" class="level3">
<h3 class="anchored" data-anchor-id="decode-your-inference-data">1. Decode your inference data</h3>
<p>Decode your inference data right before your forward pass. For example, you’ll notice the newline is missing if you do this. This is one way to tell that something fishy is going on.</p>
<div id="246702e3-1282-4250-80c4-5976db96e42e" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">dec(enc(srv))</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>'Ok&lt;|im_start|&gt;'</code></pre>
</div>
</div>
</section>
<section id="use-hf-chat-templating" class="level3">
<h3 class="anchored" data-anchor-id="use-hf-chat-templating">2. Use HF chat templating</h3>
<p>Use the new HuggingFace <a href="https://huggingface.co/docs/transformers/chat_templating">chat template</a> when possible. This will help avoid these issues (however, I would still check using method #1 to be sure!). Related GitHub Issue <a href="https://github.com/huggingface/transformers/issues/25304#issuecomment-1728111915">comment</a>.</p>
</section>
</section>
<section id="example-axolotl-vs.-huggingface-chat-templates" class="level2">
<h2 class="anchored" data-anchor-id="example-axolotl-vs.-huggingface-chat-templates">Example: Axolotl vs.&nbsp;HuggingFace Chat Templates</h2>
<p>This is real example of how tokenization drift can bite you.</p>
<section id="chat-template-from-huggingface" class="level3">
<h3 class="anchored" data-anchor-id="chat-template-from-huggingface">Chat Template From HuggingFace</h3>
<div id="d8375302-88c3-43f4-863d-2240283cb3c4" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoTokenizer</span>
<span id="cb11-2">tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoTokenizer.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"NousResearch/Llama-2-7b-chat-hf"</span>)</span>
<span id="cb11-3"></span>
<span id="cb11-4">chat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb11-5">   {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"system"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lorem"</span>},</span>
<span id="cb11-6">   {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"abc"</span>},</span>
<span id="cb11-7">   {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"assistant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ipsum"</span>},</span>
<span id="cb11-8">   {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"123"</span>},</span>
<span id="cb11-9">   {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"assistant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sit"</span>},</span>
<span id="cb11-10">]</span>
<span id="cb11-11"></span>
<span id="cb11-12">ids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer.apply_chat_template(chat)</span>
<span id="cb11-13"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(tokenizer.decode(ids))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;
lorem
&lt;&lt;/SYS&gt;&gt;

abc [/INST] ipsum&lt;/s&gt;&lt;s&gt;[INST] 123 [/INST] sit&lt;/s&gt;</code></pre>
</div>
</div>
</section>
<section id="same-thing-decoded-from-axolotl-with-a-space-after-s" class="level3">
<h3 class="anchored" data-anchor-id="same-thing-decoded-from-axolotl-with-a-space-after-s">Same thing decoded from Axolotl (with a space after <code>&lt;s&gt;</code>)</h3>
<p>Got the token ids from <a href="https://github.com/OpenAccess-AI-Collective/axolotl/pull/952/files#diff-e2bb558861fee0a2caf4307a1613cd7f19e01e206f771ce7ec4644488acdfd2fR133-R146">this test</a>.</p>
<div id="f3cd6a66-3bc0-4575-8f52-6e425ad901be" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">axolotl_ids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">518</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25580</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29962</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3532</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14816</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29903</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6778</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">13</span>, </span>
<span id="cb13-2">                <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29880</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3668</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">13</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29966</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">829</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14816</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29903</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6778</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">13</span>, </span>
<span id="cb13-3">                <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">13</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10736</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">518</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29914</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25580</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29962</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">23421</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, </span>
<span id="cb13-4">                <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">518</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25580</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29962</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29871</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29896</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29906</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29941</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">518</span>, </span>
<span id="cb13-5">                <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29914</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25580</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29962</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7845</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb13-6"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(tokenizer.decode(axolotl_ids))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;s&gt; [INST] &lt;&lt;SYS&gt;&gt;
lorem
&lt;&lt;/SYS&gt;&gt;

abc [/INST] ipsum&lt;/s&gt;&lt;s&gt; [INST] 123 [/INST] sit&lt;/s&gt;</code></pre>
</div>
</div>
</section>
<section id="lets-decode-hf-tokens-one-at-a-time" class="level3">
<h3 class="anchored" data-anchor-id="lets-decode-hf-tokens-one-at-a-time">Let’s decode HF tokens one at a time</h3>
<div id="dcbc326c-802b-42f3-a173-19aedc31baaf" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> ids[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>]:</span>
<span id="cb15-2">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>tokenizer<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>decode(i)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1: &lt;s&gt;
29961: [
25580: INST
29962: ]
3532: &lt;&lt;
14816: SY
29903: S
6778: &gt;&gt;
13: 
</code></pre>
</div>
</div>
</section>
<section id="lets-decode-axolotl-tokens-one-at-a-time" class="level3">
<h3 class="anchored" data-anchor-id="lets-decode-axolotl-tokens-one-at-a-time">Let’s decode Axolotl tokens one at a time</h3>
<p>See the second token <code>518</code> this is a mismatch with the HF Chat template which is <code>29961</code></p>
<div id="1409ec09-89eb-429b-a846-c30a802a8647" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> axolotl_ids[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>]:</span>
<span id="cb17-2">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>tokenizer<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>decode(i)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1: &lt;s&gt;
518: [
25580: INST
29962: ]
3532: &lt;&lt;
14816: SY
29903: S
6778: &gt;&gt;
13: 
</code></pre>
</div>
</div>
</section>
</section>
<section id="why-does-this-happen" class="level2">
<h2 class="anchored" data-anchor-id="why-does-this-happen">Why does this happen?</h2>
<p>Axolotl assembles prompts in token space rather than string space.</p>
<div id="c00acd59-7f69-49ad-ada7-286ca7b13c63" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">tokenizer.encode(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'&lt;s&gt;'</span>, add_special_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> tokenizer.encode(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'[INST]'</span>, add_special_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>[1, 518, 25580, 29962]</code></pre>
</div>
</div>
<p>HF Chat templates interpolate strings instead</p>
<div id="db856a19-cbdb-4ae7-a515-675ee31ff21f" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">tokenizer.encode(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'&lt;s&gt;[INST]'</span>, add_special_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>[1, 29961, 25580, 29962]</code></pre>
</div>
</div>
</section>
<section id="other-examples" class="level2">
<h2 class="anchored" data-anchor-id="other-examples">Other Examples</h2>
<p>These are other examples of people being bitten by drift between differences in tokenization between training and inference time:</p>
<ol type="1">
<li>This <a href="https://github.com/huggingface/transformers/issues/25304">GitHub Issue</a>.</li>
<li>This <a href="https://twitter.com/johnowhitaker/status/1732097798286475578">Tweet</a>.</li>
</ol>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>This is for good reason, as masking must also be done at the token level.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>LLMs</category>
  <category>Notes</category>
  <guid>https://hamel.dev/notes/llm/finetuning/tokenizer_gotchas.html</guid>
  <pubDate>Sun, 17 Dec 2023 08:00:00 GMT</pubDate>
</item>
<item>
  <title>Tools for curating LLM Data</title>
  <link>https://hamel.dev/</link>
  <description>A review of tools for curating LLMs, and why you should build your own.
</description>
  <category>LLMs</category>
  <category>Notes</category>
  <guid>https://hamel.dev/</guid>
  <pubDate>Wed, 15 Nov 2023 08:00:00 GMT</pubDate>
</item>
<item>
  <title>vLLM &amp; Large Models</title>
  <link>https://hamel.dev/</link>
  <description>Using tensor parallelism w/ vLLM &amp; Modal to run Llama 70b
</description>
  <category>LLMs</category>
  <category>Notes</category>
  <guid>https://hamel.dev/</guid>
  <pubDate>Sat, 28 Oct 2023 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Optimizing LLM latency</title>
  <link>https://hamel.dev/</link>
  <description>An exploration of ways to optimize LLM latency.
</description>
  <category>LLMs</category>
  <category>Notes</category>
  <guid>https://hamel.dev/</guid>
  <pubDate>Sun, 15 Oct 2023 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Why Should ML Engineers Learn Kubernetes?</title>
  <dc:creator>Hamel Husain</dc:creator>
  <link>https://hamel.dev/blog/posts/k8s/</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
K8s For Data Scientists Course
</div>
</div>
<div class="callout-body-container callout-body">
<p>If you came here looking for the course, feel free to jump ahead to: K8s For Data Scientists.</p>
</div>
</div>
<p><a href="https://kubernetes.io/">Kubernetes</a>, known as K8s, is an open-source system for deploying and managing containerized applications in the cloud. An increasing amount of modern web applications are deployed on K8s. If you are an ML engineer, it is increasingly likely that either the infrastructure you use to train, monitor, or orchestrate your models is deployed on K8s, or downstream applications that consume your models are running on K8s. However, K8s is a complex system that can be intimidating to learn.</p>
<p>I agree with Chip Huyen that, in theory, <a href="https://huyenchip.com/2021/09/13/data-science-infrastructure.html">Data Scientists <strong>shouldn’t need to</strong> learn K8s</a>. However, the truth is: <strong>Even though you shouldn’t have to, it’s really beneficial if you do!</strong> I’ve found that I’m often constrained by infrastructure and that infrastructure is increasingly hosted on Kubernetes.</p>
<p>For example, I’m rarely given access to a cloud provider’s console, and instead, I have access to a K8s cluster with some data tools already installed. When something goes awry, it’s beneficial to know enough about K8s to debug the issue. Additionally, familiarity with basic concepts allows me to have more productive conversations with my team about infrastructure.</p>
<p><a href="https://twitter.com/vboykis/status/1596610600511102976">Vicki Boykis</a> seems to agree that the investment in learning this technology is worthwhile<sup>1</sup>:</p>
<p><img src="https://hamel.dev/blog/posts/k8s/course_img/20221212131043.png" class="img-fluid"></p>
<p>Below, I outline several reasons why learning K8s is a good idea for machine learning engineers<sup>2</sup>.</p>
<section id="hosted-dataml-tools-are-not-always-an-option" class="level2">
<h2 class="anchored" data-anchor-id="hosted-dataml-tools-are-not-always-an-option">Hosted data/ML tools are not always an option</h2>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/k8s/course_img/bellman.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>A robot concierge helping a scientist</figcaption>
</figure>
</div>
<p>Large cloud providers offer their flavors of ML infrastructure as hosted solutions<sup>3</sup>. However, there is often a gap between these offerings and the needs of machine learning teams. For example, I’ve seen the following tools deployed alongside or in place of hosted solutions:</p>
<ul>
<li><a href="https://metaflow.org/">Metaflow</a></li>
<li><a href="https://www.kubeflow.org/">Kubeflow</a></li>
<li><a href="https://argoproj.github.io/argo/">Argo</a></li>
<li><a href="https://jupyter.org/hub">JupyterHub</a></li>
<li><a href="https://www.dask.org/">Dask</a></li>
<li>etc.</li>
</ul>
<p>When open source isn’t enough, third-party vendors are happy to install their software on your cloud. However, you often need basic infrastructure skills to enable this. These skills often intersect with Kubernetes. While you may not be responsible for deploying the infrastructure yourself, it is helpful to understand the basics of how things work so that you can do basic debugging and troubleshooting. For example, knowing where to find logs or an API/HTTPS endpoint can unblock you in many cases.</p>
</section>
<section id="nobody-is-coming-to-save-you" class="level2">
<h2 class="anchored" data-anchor-id="nobody-is-coming-to-save-you">Nobody is coming to save you</h2>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/k8s/course_img/superhero.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>A super hero</figcaption>
</figure>
</div>
<p>A typical first experience as a machine learning professional is that you don’t have the necessary tools to get started. This is incredibly frustrating, as making progress without the proper tools can be hard. This experience usually culminates in a conversation like this:</p>
<hr>
<p><em>ML Eng: I’m excited to join ACME company! You’ve hired me to optimize marketing spending with predictive models. The issue is that we don’t have the basic infrastructure or tools necessary for me to work efficiently.</em></p>
<p><em>Manager: I’m confused. Can’t you install the tools you need? Isn’t that what you are for? I was expecting that you would figure it out.</em></p>
<p><em>ML Eng: No, I don’t know how to set up and deploy infrastructure. We need a special infrastructure or DevOps person for that.</em></p>
<p><em>Manager: It will be hard to ask for more resources if we don’t know the expected return on investment. Can you do the ML project first, demonstrate some value, and then we can invest in infrastructure?</em></p>
<p><em>ML Eng: I need some minimum tools to experiment more quickly and develop a proof of concept. Also, I need tools that might help me collaborate better with my team…</em></p>
<hr>
<p>My experience is that DevOps teams are chronically understaffed and overworked. While it usually isn’t advisable to deploy enterprise software yourself on Kubernetes for security concerns, having basic skills can lift a tremendous burden off your DevOps counterparts and make it tractable for them to help you.</p>
<p>K8s are not a panacea for all infrastructure problems. You must operate within the constraints of your organization and existing software stack.<sup>4</sup> However, with its growing popularity, it is increasingly likely that learning this technology will help you.</p>
</section>
<section id="ml-research-is-crowded.-compete-on-swe-skills." class="level2">
<h2 class="anchored" data-anchor-id="ml-research-is-crowded.-compete-on-swe-skills.">ML research is crowded. Compete on SWE skills.</h2>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/k8s/course_img/crowd.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>An overcrowded room of scientists</figcaption>
</figure>
</div>
<p>One of the best ways to set yourself apart as a data scientist is through your skills. Traditional education often emphasizes learning the latest ML techniques. However, cutting-edge ML research is very competitive. It’s also an extremely crowded space.</p>
<p>In my experience, the bottleneck many teams face is not a lack of knowledge of cutting-edge ML techniques but software engineering skills and partners to help operationalize models. If you take some time to learn how to stand up tools and infrastructure, you will be invaluable to your team.</p>
<p>More importantly, deploying and integrating models into services and applications is critical to connecting ML to business problems. Learning K8s will help you do this.</p>
</section>
<section id="your-company-likely-already-runs-k8s" class="level2">
<h2 class="anchored" data-anchor-id="your-company-likely-already-runs-k8s">Your company likely already runs K8s</h2>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/k8s/course_img/meeting.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>A scientist shaking hands with someone who runs infrastructure</figcaption>
</figure>
</div>
<p>Just as Python is the lingua franca of data science, K8s is becoming the lingua franca of cloud infrastructure. According to a <a href="https://www.cncf.io/reports/cncf-annual-survey-2021/">2021 Survey by CNCF</a>, 96% of organizations are either using or evaluating Kubernetes. Furthermore, Stack Overflow’s <a href="https://survey.stackoverflow.co/2022/#section-most-loved-dreaded-and-wanted-other-tools">2022 Developer Survey</a> shows that Docker and Kubernetes are the number one and two most loved and wanted tools, respectively. This is a strong indicator that K8s are here to stay.</p>
<p>Basic proficiency with K8s will drastically increase your chances of garnering support for your desired tools in many organizations. Proficiency with K8s increases the likelihood that:</p>
<ul>
<li>Your DevOps counterparts will feel comfortable with the tools you want to deploy</li>
<li>You will have a shared language in which to talk to your application administrators</li>
<li>You will be more likely to attract people to help you with infra <sup>5</sup></li>
</ul>
<p>These factors make it much more likely that you will get the tools that meet you where you are as opposed to something a software engineer without any data science experience thinks is a good idea (which I’ve seen happen a lot!).</p>
</section>
<section id="but-isnt-it-overkill" class="level2">
<h2 class="anchored" data-anchor-id="but-isnt-it-overkill">But isn’t it overkill?</h2>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/k8s/course_img/orange.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>Cutting oranges with a chainsaw</figcaption>
</figure>
</div>
<p>For simple apps that you want to stand up quickly or prototype, K8s is overkill. Instead, I’m advocating knowledge of K8s as useful when working within the environments found in many companies. For example, hosting your data product on a single VM is often insufficient if you want to deploy production software. Many companies even have infrastructure that may block you from doing this with paved paths that only include Kubernetes.</p>
<p>Even if you are not deploying any production software, K8s can be invaluable in allowing you to deploy the tools you need. In many cases using K8s can make tasks easier. Enterprises have necessarily invested resources in creating guardrails to control costs and security. Those guardrails are increasingly built around K8s patterns<sup>6</sup>. Understanding these concepts can make operating within the confines of your company’s cloud stack easier.</p>
</section>
<section id="you-dont-need-to-be-an-expert" class="level2">
<h2 class="anchored" data-anchor-id="you-dont-need-to-be-an-expert">You don’t need to be an expert</h2>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://hamel.dev/blog/posts/k8s/course_img/student.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>A student sitting at a desk in a library</figcaption>
</figure>
</div>
<p>K8s are complicated, but you don’t need to become an expert to unlock great value as a Data Scientist. I’m not suggesting that data scientists become K8s administrators. K8s Administration is a very involved task and worthy of its own role. Unfortunately, nearly all educational material around K8s is focused on being an administrator, which is overkill for what most data scientists need.</p>
</section>
<section id="a-course" class="level2">
<h2 class="anchored" data-anchor-id="a-course">A course?</h2>
<p>I haven’t yet found a good resource for people like data scientists to learn Kubernetes without wading through lots of irrelevant material geared towards administrators. So my colleagues and I are considering creating a free course with data scientists in mind. If this sounds interesting, you <a href="https://k8scourse.com/">can sign up here</a>.</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><a href="https://vickiboykis.com/">Vicki</a> is not someone who is impressed by flashy or new technologies and is someone who takes a pragmatic approach to get the job done. When she says you should learn K8s, you should pay attention!↩︎</p></li>
<li id="fn2"><p>Each subsection of this article has a picture that has been generated by Stable diffusion with a prompt that very similar to the image caption.↩︎</p></li>
<li id="fn3"><p>These systems are AWS - <a href="https://aws.amazon.com/sagemaker/">Sagemaker</a>, Azure - <a href="https://azure.microsoft.com/en-us/products/machine-learning/#product-overview">AzureML</a> and GCP - <a href="https://cloud.google.com/vertex-ai-workbench">VertexAI</a>.↩︎</p></li>
<li id="fn4"><p>Some organizations have built solutions that avoid K8s. For example, <a href="https://www.bighatbio.com/">BigHat</a> uses a solution based on AWS SageMaker + Lambda and other hosted solutions. So it might be a mistake to try to move over to K8s in that example – you should try to leverage your company’s existing tech stack where possible!↩︎</p></li>
<li id="fn5"><p>My friend <a href="https://twitter.com/_inc0_">Michał Jastrzębski</a>, who specializes in ML infrastructure, has shared the following colorful anecdote with me: “when I hear Data Scientists shouldn’t learn K8s”, I hear “DevOps needs to learn Airflow”.↩︎</p></li>
<li id="fn6"><p>Specifically, K8s concepts that are relevant are namespaces, labels and RBAC.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>K8s</category>
  <guid>https://hamel.dev/blog/posts/k8s/</guid>
  <pubDate>Mon, 16 Jan 2023 08:00:00 GMT</pubDate>
  <media:content url="https://user-images.githubusercontent.com/1483922/209075410-b31ad913-282c-4619-87ad-3a7679e92baf.png" medium="image" type="image/png"/>
</item>
<item>
  <title>nbdev + Quarto: A new secret weapon for productivity</title>
  <link>https://hamel.dev/</link>
  <description>Our favorite tool for software engineering productivity–nbdev, now re-written with Quarto.
</description>
  <category>Jupyter</category>
  <category>Quarto</category>
  <category>nbdev</category>
  <guid>https://hamel.dev/</guid>
  <pubDate>Thu, 28 Jul 2022 07:00:00 GMT</pubDate>
</item>
</channel>
</rss>
