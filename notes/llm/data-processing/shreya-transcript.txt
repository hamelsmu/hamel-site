[00:00:02] Welcome everybody. Today we're very
[00:00:06] excited to have our very own Shrea Shrea
[00:00:09] Shankar host the session and today she's
[00:00:10] going to be talking about the
[00:00:14] culmination of all of her work over the
[00:00:16] last 5 years and beyond. This is her
[00:00:18] website
[00:00:20] sh-raa.com
[00:00:22] visit it. It's kind of a compilation of
[00:00:24] a lot of her work. So Shay has done a
[00:00:26] lot of things in her career. uh she
[00:00:29] started working with MLOps
[00:00:32] and more recently working on data
[00:00:37] processing and how LLMs and AI can apply
[00:00:40] to that and also eval as she's done some
[00:00:43] work in academia. She kind of pivoted a
[00:00:44] little bit to work in a startup for a
[00:00:47] while then she came back to academia and
[00:00:50] she's a very unique academic. I've I've
[00:00:53] always been very surprised by the flavor
[00:00:55] of of what she produced. I want to tell
[00:00:56] you why you should pay attention. It's
[00:00:59] not your typical and academic body of
[00:01:02] Shrea skws really like very closely to
[00:01:04] applied and let me just show you what
[00:01:06] this means. So, so Shrea does a lot of
[00:01:09] interesting work not only with LM ops
[00:01:13] but also with human computer interfaces
[00:01:15] and UX design and thinks deeply about
[00:01:16] and UX design and thinks deeply about
[00:01:17] tools. So all the different pain points
[00:01:20] that you have when developing AI
[00:01:23] applications, Shrea tends to focus on
[00:01:24] applications, Shrea tends to focus on
[00:01:26] that and tries to find ways to make your
[00:01:29] life easier as a developer and as an AI
[00:01:32] engineer. What you'll find is not all
[00:01:34] papers are like this that Trey is
[00:01:36] involved with but a very high percentage
[00:01:39] is you'll see
[00:01:42] working software user interface a
[00:01:44] breakdown of an industry problem that
[00:01:46] people are facing when they're
[00:01:50] developing products with AI and she'll
[00:01:52] present software
[00:01:56] a user interface a workflow
[00:01:59] and some algorithms and also all the you
[00:02:01] know work behind it and the studies
[00:02:05] behind it and so she'll often also
[00:02:07] survey lots of users do lots of
[00:02:09] interviews and so what I like to joke
[00:02:11] with Treya about is you look let's look
[00:02:12] at another one this is called rag
[00:02:15] without the lag so this is a this is a
[00:02:18] really nice paper it goes into
[00:02:20] developer workflows
[00:02:22] of how you can iterate and debug
[00:02:25] retrieval
[00:02:28] again we're presented with software user
[00:02:31] interfaces is exploring user interfaces
[00:02:32] and if you read this there's like
[00:02:35] studies on the productivity
[00:02:38] impacts that developers had while using
[00:02:40] this similarly there's something called
[00:02:42] docket now this paper talks about
[00:02:46] algorithms and effective ways of
[00:02:49] processing documents at scale with AI
[00:02:51] but then there's also this paper that
[00:02:53] builds on top of that which is kind of
[00:02:54] what I would call the product layer
[00:02:58] almost which is again you have software
[00:03:02] that helps you interact with these tools
[00:03:04] in a very applied sense. And this has
[00:03:07] been these ideas have been shipped to
[00:03:08] industry. There's companies that are
[00:03:10] using these tools. A lot of this stuff
[00:03:13] has been adopted by various vendors in
[00:03:15] the AI space um because it's it's all
[00:03:17] very real. So what I like to joke with
[00:03:21] Treya about is these are all startup
[00:03:23] pitch decks in my mind because they have
[00:03:26] all the sort of ingredients. They have
[00:03:29] working software. They interview lots of
[00:03:32] users and their pain points. She does a
[00:03:34] lot of product discovery. She's solving
[00:03:36] an applied painoint
[00:03:39] and she's has building a product and
[00:03:41] she's she also she doesn't stop there.
[00:03:44] She works with companies and uses these
[00:03:47] products to solve problems. So that's
[00:03:49] why I'm really excited to have Shrea
[00:03:52] talk about all of this work in a
[00:03:54] cohesive way. So that's why you should
[00:03:57] pay attention to this session. On inso
[00:03:58] I'll just hand it over to Shrea.
[00:04:00] &gt;&gt; Wow. Thanks for the amazing
[00:04:03] introduction. I really appreciated that.
[00:04:05] I'm really excited to share my work on
[00:04:07] AI powered data processing and document
[00:04:09] processing. I want to start out by
[00:04:11] telling people about data systems. I
[00:04:12] work in data systems. Most people are
[00:04:14] already very familiar with data systems,
[00:04:16] but I think it's one of the greatest
[00:04:17] success stories of computing. They've
[00:04:19] been around for quite some time. There's
[00:04:21] been five plus decades of work. And
[00:04:23] we've done groundbreaking research in
[00:04:25] data systems. All these decades we've
[00:04:27] built new sub fields of work that still
[00:04:29] live on. We've also been able to
[00:04:31] collaborate with a range of fields in
[00:04:33] computer science. Pretty much every area
[00:04:35] in computer science you can see those
[00:04:37] techniques being infused into data
[00:04:39] management systems. I think as a result
[00:04:41] we've been able to have amazing reach,
[00:04:43] amazing impact. There's so many
[00:04:44] companies out there that build data
[00:04:46] systems. It's a trillion dollar
[00:04:48] industry. Every application and every
[00:04:50] company uses some sort of data
[00:04:52] management system. [gasps] So now what's
[00:04:54] next? Right, for this data management
[00:04:58] community, I'd like to think that we've
[00:05:00] only seen the tip of the iceberg. A lot
[00:05:02] of these data systems in the world only
[00:05:04] focus on relational data or you might
[00:05:06] think of this as tabular data,
[00:05:08] structured data, data that lives in
[00:05:10] tables. There's a whole lot of data out
[00:05:12] there in this world that people really
[00:05:14] want to query and none of our data
[00:05:17] systems can really help people do these
[00:05:19] kinds of queries. And I'll give you an
[00:05:21] example kind of unstructured data
[00:05:23] processing task. And this comes from our
[00:05:25] users, people that we directly work with
[00:05:27] with the docet project, which I'll talk
[00:05:30] about in a little bit. But these public
[00:05:32] defender data analysts want to help
[00:05:35] represent their defendants very well. So
[00:05:36] represent their defendants very well. So
[00:05:37] there's a lot of data that corresponds
[00:05:39] to every defendant. And this is very
[00:05:41] heterogeneous data. So think like court
[00:05:43] transcripts, police reports, news
[00:05:46] articles, even images, videos, whatnot.
[00:05:49] and the user, the data analyst wants to
[00:05:52] figure out, are there any mentions of
[00:05:54] racial bias somewhere in the case?
[00:05:56] Because maybe if that's true, we can
[00:05:58] figure out how to make the sentence more
[00:06:01] just or fair for that defendant. Now,
[00:06:03] why is this also interesting from a
[00:06:05] technical perspective? Well, there's a
[00:06:07] lot of reasoning that's required in
[00:06:10] order to do this task, right? Something
[00:06:12] like implicit or explicit bias is
[00:06:14] somewhat subjective, difficult to find.
[00:06:16] I can't really write a program to do it.
[00:06:18] And to do this at the scale that the
[00:06:21] public defenders want would cost so much
[00:06:23] money if they wanted to analyze all of
[00:06:26] their data, all of their cases with
[00:06:28] these state-of-the-art large language
[00:06:31] models out there. So clearly people need
[00:06:32] models out there. So clearly people need
[00:06:33] better solutions in order to do this
[00:06:35] kind of analysis. Just having AI doesn't
[00:06:37] quite solve all of the unstructured data
[00:06:40] processing problems out there. Now in
[00:06:42] the data management community or in the
[00:06:43] data systems community there's a new
[00:06:45] field of data processing emerging called
[00:06:48] semantic data processing and the idea
[00:06:50] behind semantic data processing is you
[00:06:51] have your favorite data processing
[00:06:52] have your favorite data processing
[00:06:55] operators such as map reduce filter etc.
[00:06:57] You express each operator in natural
[00:06:59] language and the outputs of these
[00:07:01] operators can be very open-ended. So to
[00:07:03] give a concrete example of what a
[00:07:05] pipeline with semantic operators might
[00:07:07] look like is say I have a data frame or
[00:07:10] a collection of court transcripts. Think
[00:07:11] of that as a data frame with just one
[00:07:12] of that as a data frame with just one
[00:07:14] column that's text. Maybe I'll run a map
[00:07:16] operation over every row in that data
[00:07:18] frame that's going to extract the name
[00:07:20] of the judge and some statements that
[00:07:22] are indicating bias. Then I'll want to
[00:07:25] do a semantic group by or reduce which
[00:07:27] groups by the judge and creates a
[00:07:29] summary per judge. I'll go into this
[00:07:31] example in a little bit more detail
[00:07:33] later on, but I just want to give you a
[00:07:34] flavor for how the data systems
[00:07:37] community is thinking about using AI
[00:07:39] infusing those into existing data
[00:07:41] processing systems like Spark, like AIS
[00:07:43] SQL and whatnot. And this is not just
[00:07:45] something that I'm inventing like, oh,
[00:07:47] here's there's this new way of thinking
[00:07:49] about AI and data processing. Actually,
[00:07:51] it's been shipped across lots and lots
[00:07:53] of different industrial databases. For
[00:07:55] example, data bricks introduced this a
[00:07:57] few years ago. It's in the Google
[00:08:00] BigQuery. It's called AIS SQL. It's in
[00:08:02] Cortex AI since it's snowflake which
[00:08:04] recently announced a huge partnership
[00:08:05] with Anthropic like yesterday. It's in
[00:08:06] with Anthropic like yesterday. It's in
[00:08:07] duct DB. All your favorite database
[00:08:09] support this notion of semantic
[00:08:12] operators. So my research really looks
[00:08:14] at two big questions in semantic
[00:08:16] operators on the system side. How do we
[00:08:19] make them scalable? And then on the
[00:08:21] steerability side and the userfacing
[00:08:23] side, AI never works off the shelf. AI
[00:08:24] side, AI never works off the shelf. AI
[00:08:26] needs to be controllable. So, how can we
[00:08:28] enable users to control these pipelines
[00:08:31] much better? I've done work in both
[00:08:32] areas. I'm definitely not going to talk
[00:08:33] about all of them today. I'll talk about
[00:08:34] about all of them today. I'll talk about
[00:08:37] a few in each area. And what I do want
[00:08:39] to point out is while my work is quite
[00:08:40] grounded in data processing, I've been
[00:08:42] pleasantly surprised by the impact my
[00:08:44] work has had outside of the database
[00:08:47] community. So not just ideas integrated
[00:08:49] into industrial databases but also
[00:08:51] adopted in bigger software systems and
[00:08:54] also powering data analysis and actual
[00:08:57] stuff that society uses. So without
[00:08:59] further ado I'll talk a little bit first
[00:09:01] about the docet system the system side
[00:09:03] of things. Both of these are very
[00:09:05] important sides. Assume for now that
[00:09:07] users find utility in authoring these
[00:09:08] users find utility in authoring these
[00:09:09] semantic operator pipelines. We'll talk
[00:09:11] about the usability stuff in the latter
[00:09:13] part of the talk, but for now, let's
[00:09:15] talk about how we build these systems to
[00:09:18] accelerate semantic operator queries.
[00:09:20] So, in my PhD, I led the development of
[00:09:22] DOETL, which is an open source system
[00:09:25] for semantic operators over text. Let me
[00:09:27] illustrate some semantic operators to
[00:09:30] you. First, the semantic map operator.
[00:09:33] Now, in DOCTL, a data set is a
[00:09:35] collection of dictionaries. Think of
[00:09:38] this as a JSON. So a list of JSON
[00:09:41] objects. Now every attribute think of it
[00:09:43] as a column in a table. You can map this
[00:09:45] to a table or a relational database if
[00:09:47] you would like. Now if I want to run an
[00:09:49] operator on such a data set, a semantic
[00:09:51] map operator. First I define the type of
[00:09:54] operator map which means one to one. And
[00:09:55] then I define my natural language
[00:09:56] then I define my natural language
[00:09:58] description or the prompt. So maybe
[00:10:00] that's extract all the statements made
[00:10:01] by the judge that indicates some
[00:10:04] implicit bias with some explanation. And
[00:10:06] then I define an output schema. This
[00:10:08] third part and the schema, think of
[00:10:09] these as new attributes that are going
[00:10:10] these as new attributes that are going
[00:10:11] to be created in each document when I
[00:10:14] run the semantic map operator. So
[00:10:15] results from running the semantic
[00:10:16] results from running the semantic
[00:10:18] operator is the data set of the same
[00:10:21] size. But now two new attributes are
[00:10:23] created perhaps by a large language
[00:10:25] model or some LLM powered algorithm
[00:10:27] under the hood. The same number of
[00:10:28] documents that comes in is the same
[00:10:31] number of documents that comes out. So
[00:10:33] that's a semantic map operator. A
[00:10:36] semantic filter operator is very similar
[00:10:39] except for the operator is some sort of
[00:10:41] yes or no task. So keep documents that
[00:10:43] satisfy this condition described in
[00:10:45] natural language. Did it in indicate
[00:10:46] natural language. Did it in indicate
[00:10:48] implicit bias? And the resulting data
[00:10:52] set same shape fewer number of documents
[00:10:54] we just drop documents that don't meet
[00:10:56] this criteria. So think of semantic
[00:10:59] filter as a semantic map but with filter
[00:11:01] semantics. The third reduce sorry the
[00:11:03] third semantic operator I'll describe
[00:11:05] the last one is a semantic reduce
[00:11:07] operator. Now this is a little bit more
[00:11:09] complex. The idea here is say we have
[00:11:11] our same document collection of court
[00:11:13] transcripts and we have another
[00:11:15] attribute that's the judge name. Maybe
[00:11:16] attribute that's the judge name. Maybe
[00:11:18] we want to give a summary for every
[00:11:21] judge judge's transcripts. So we specify
[00:11:23] a reduce key which is the name of the
[00:11:26] judge and then we specify the prompt or
[00:11:28] the task that is going to be applied to
[00:11:31] every group of documents. So every judge
[00:11:33] is assigned or every document is
[00:11:35] assigned to its judge group and then we
[00:11:38] have a summary that's created per judge.
[00:11:41] Now the data input and output looks very
[00:11:42] different right we have the AI is
[00:11:44] generated entirely different summary new
[00:11:46] summary and there's fewer number of
[00:11:48] documents because now every document
[00:11:51] pertains to a group. So those are three
[00:11:53] very very different and powerful types
[00:11:55] of semantic operators. And what makes
[00:11:57] the semantic data processing paradigm so
[00:11:58] the semantic data processing paradigm so
[00:11:59] powerful is the ability to compose
[00:12:02] together operators in a pipeline. So for
[00:12:04] example, if I had my data set of court
[00:12:06] transcripts, which is just one single
[00:12:09] column or one attribute, maybe first
[00:12:12] what I want to do is extract the judge
[00:12:14] name from each transcript and then I
[00:12:16] want to group by that judge name and
[00:12:19] then come up with the summary per judge.
[00:12:20] Okay, so this is just an example of a
[00:12:23] real query that somebody has written.
[00:12:25] I've simplified it quite a bit, of
[00:12:27] course, the prompts at least. Um, but
[00:12:29] now you can see the kind of like
[00:12:31] powerful data processing that's enabled
[00:12:34] if I'm able to orchestrate these kinds
[00:12:36] of semantic operators.
[00:12:38] So now the question from the data
[00:12:39] systems perspective is okay, people have
[00:12:41] authored this, they find this outputs
[00:12:44] meaningful. Okay, how do we run this at
[00:12:46] scale and make sure that it works, that
[00:12:49] people actually get value out of it? And
[00:12:50] the way that we like to think about it
[00:12:52] from a data systems perspective, of
[00:12:54] course, is how do you optimize this
[00:12:56] query? And optimize is a very broad
[00:12:58] here. It means how do you make sure it's
[00:12:59] accurate and how do you make sure it's
[00:13:00] cheap? Because if you're going to run
[00:13:03] this on tens of thousands of transcripts
[00:13:05] with each transcript hundreds of pages
[00:13:06] long, if you're going to run this with
[00:13:08] state-of-the-art models, it can cost you
[00:13:10] lots and lots of money, as I'll show you
[00:13:12] later. So how do we do query
[00:13:15] optimization? I'll bring in a mindset of
[00:13:17] traditional database query optimization.
[00:13:18] There are kind of three components to a
[00:13:21] query optimizer. First is what is the
[00:13:23] space of query plans that we're going to
[00:13:26] consider. Second is how do we model the
[00:13:28] cost of each query plan? Because what
[00:13:29] we're going to end up doing is searching
[00:13:32] over these possible query plans and
[00:13:34] picking the one with the cheapest cost.
[00:13:37] And I'll go through this exercise of
[00:13:38] kind of showing you where each of these
[00:13:40] kind of break down for the semantic data
[00:13:42] processing pipeline or at least what we
[00:13:44] know how to do breaks down and all the
[00:13:45] new things we had to come up with at
[00:13:47] research. So first let's talk about the
[00:13:49] plan space. Okay, what does that even
[00:13:51] mean in traditional database systems or
[00:13:53] something like Spark, right? What are
[00:13:54] the different plans that are considered
[00:13:56] for a Spark query? Well, if you think
[00:13:58] about the operators that are in a Spark
[00:14:00] query or a data pipeline, right, we have
[00:14:02] different algorithms for implementing
[00:14:03] all of those operators. For example, in
[00:14:04] all of those operators. For example, in
[00:14:06] a join, you could do different types of
[00:14:08] joins. For scans, you could do different
[00:14:10] types of scans. Now, you don't need to
[00:14:11] know what all of these are, but the
[00:14:13] point is that there's there's a variety
[00:14:14] point is that there's there's a variety
[00:14:15] of different implementations of the
[00:14:16] of different implementations of the
[00:14:18] pipeline that all could vary depending
[00:14:20] on the characteristics of the data and
[00:14:22] the query. So, what does that kind of
[00:14:24] look like in the semantic pipeline
[00:14:25] setting? Well, there's all sorts of
[00:14:27] implementations you can have of these
[00:14:29] semantic operators, right? I just said
[00:14:30] map and reduce, but you could have
[00:14:32] different large language models that are
[00:14:33] running each of these operators. You
[00:14:34] could use different prompting
[00:14:36] strategies. You could use ensembles of
[00:14:38] LLMs, right? pretty much any strategy
[00:14:41] that from any LLM powered algorithm that
[00:14:43] you can think of to execute a semantic
[00:14:46] operator is super fair game. So we did
[00:14:47] that. We tried coming up with some very
[00:14:49] good implementations of semantic
[00:14:51] operators, put it in front of real users
[00:14:53] and journalists and see what happens.
[00:14:55] And they all said that man this is not
[00:14:58] accurate for my real world tasks. And
[00:15:00] I'll give you an example of this. So for
[00:15:02] maybe the pipeline first has some sort
[00:15:04] of map operation to create a very
[00:15:06] comprehensive summary, right? Most
[00:15:08] people when they want a summary, they
[00:15:10] actually want their summary to include
[00:15:12] many different attributes. So maybe
[00:15:14] you're summarizing very long transcripts
[00:15:16] and you want there to be four parts to
[00:15:18] the summary analyzing different aspects
[00:15:21] of the transcript. You might run this
[00:15:22] with a state-of-the-art language model
[00:15:27] like Gemini 3.0 and find that the output
[00:15:28] is simply not accurate enough. The
[00:15:30] transcript is hundreds of pages long. Oh
[00:15:33] no, what can we do? LLM is not good. We
[00:15:36] maybe missed two parts here. And you
[00:15:38] might think, okay, so what, right? Like
[00:15:40] we'll just wait. Maybe maybe a better
[00:15:42] LLM will come out next year and solve
[00:15:44] the problem and like we just kind of
[00:15:46] table until we get something good
[00:15:49] enough. Well, what we realize is that
[00:15:52] even when the operators are accurate,
[00:15:54] often users will write the semantic
[00:15:56] operators, specify their favorite large
[00:15:58] language model to do it, and it's not
[00:16:00] well scoped to the large language model.
[00:16:02] So perhaps maybe this operation is very
[00:16:06] complex and only a model like GBT 51 and
[00:16:09] Gemini 3 Pro are the only ones that can
[00:16:11] accurately do the semantic operator or
[00:16:12] accurately do the semantic operator or
[00:16:13] get the correct answer. So if only
[00:16:16] expensive models can do the operation
[00:16:19] then any plan that we consider in our
[00:16:20] query planner is going to be very
[00:16:22] expensive right we just cannot run this
[00:16:25] at scale. So the interesting research
[00:16:27] questions become okay like can we
[00:16:29] rewrite these pipelines to somehow be
[00:16:31] more accurate and also somehow be
[00:16:33] cheaper like what is the right framework
[00:16:35] to think about rewriting these semantic
[00:16:38] operator pipelines to be better scoped
[00:16:41] to large language model capabilities.
[00:16:43] So we draw inspiration from query
[00:16:45] rewriting in traditional database. So it
[00:16:48] turns out that when you execute a
[00:16:50] database query, the query optimizer does
[00:16:52] a lot of rewriting under the hood to
[00:16:54] make it a good logical form. So some of
[00:16:56] these you might have heard of a
[00:16:58] selection push down. Some of these you
[00:17:00] might think make sense, like if you have
[00:17:02] two numbers that you're adding in your
[00:17:03] predicate, like you might as well just
[00:17:04] predicate, like you might as well just
[00:17:05] only add those once so you don't have to
[00:17:07] keep adding it every single time you
[00:17:09] look at a candidate. um you might
[00:17:11] reorder your joins, you might rewrite
[00:17:13] your subqueries, things that will be
[00:17:16] better suited to optimization.
[00:17:18] So the question to ask is okay can we
[00:17:20] what does a rule-based engine look like
[00:17:22] when optimizing semantic data
[00:17:24] processing? And this is different for
[00:17:26] semantic operators because these
[00:17:28] semantic operators are fuzzy operations,
[00:17:30] right? They're described in natural
[00:17:31] language. So you kind of have to
[00:17:33] understand the semantics of that to
[00:17:35] understand how you're going to rewrite
[00:17:38] it. And you might need to rewrite
[00:17:41] operations that already that are defined
[00:17:44] on atomic units. So in a database, every
[00:17:46] row is an atomic unit pretty much or
[00:17:49] like every cell in a table. In docet or
[00:17:51] in document processing, a user might
[00:17:54] think of a document as an atomic unit.
[00:17:55] But if that document is like tens of
[00:17:57] thousands of pages, large language model
[00:17:59] will never be able to run accurately on
[00:18:01] that. And we need to somehow be able to
[00:18:04] break that down even though it was
[00:18:07] atomic or considered atomic by the user.
[00:18:08] So these are the challenges, right? I'm
[00:18:09] I'm setting up the stage for thinking
[00:18:11] about rewriting semantic operator
[00:18:13] pipelines and how we have to think about
[00:18:15] it differently. So what we realized in
[00:18:17] the docl project is that you actually
[00:18:20] can systematically decompose tasks. And
[00:18:22] I'll give you an example. So in the same
[00:18:24] kind of implicit bias example, imagine
[00:18:25] we have a map operator on a very long
[00:18:26] we have a map operator on a very long
[00:18:28] document to extract all statements of
[00:18:30] implicit bias. It's not going to work if
[00:18:33] I run it with Gemini 3.0. If there are
[00:18:35] like hundreds of statements of implicit
[00:18:37] bias, it just simply will not accurately
[00:18:39] recall all of them. But one way to
[00:18:42] improve the recall is to break it up as
[00:18:45] follows. First, I split this document
[00:18:47] into smaller chunks.
[00:18:48] into smaller chunks.
[00:18:50] Then run the large language model to do
[00:18:53] the task over each chunk.
[00:18:55] Now take those results, feed them into a
[00:18:58] semantic reduce operator and then get
[00:19:00] the same answer that I hope will
[00:19:02] actually be accurate. Now these are all
[00:19:04] new operators, right? This is an
[00:19:05] entirely different pipeline. You need to
[00:19:06] entirely different pipeline. You need to
[00:19:07] instantiate them in some way. So I need
[00:19:09] to have some chunk size that's defined.
[00:19:12] So maybe my split operator says 1500
[00:19:14] words per chunk is pretty well scoped to
[00:19:16] the LLM. Maybe my map operator, I need
[00:19:18] to rewrite the prompt a little bit to be
[00:19:21] specific to processing that chunk. And
[00:19:23] then the reduce operator. Maybe I need
[00:19:25] to come up with a good prompt that
[00:19:27] indicates, oh, I want to combine all the
[00:19:31] extracted implicit biases into one list.
[00:19:33] And so you can probably imagine, right?
[00:19:35] Like, oh yes, this kind of rewrite makes
[00:19:36] Like, oh yes, this kind of rewrite makes
[00:19:39] sense, right? Like I can now improve the
[00:19:41] recall. I can improve the accuracy of
[00:19:44] the outputs if the LLM is looking at
[00:19:47] smaller pieces of data. So this is one
[00:19:50] way to do systematic data decomposition.
[00:19:52] You don't have to just decompose along
[00:19:54] the data axis. You can also decompose
[00:19:57] wrong along the task complexity. Now the
[00:19:59] real world settings, right? Nobody
[00:20:00] writes those simple one-s sentence
[00:20:02] prompts. People actually write really
[00:20:04] detailed prompts. They define implicit
[00:20:07] bias in really great detail. Well, what
[00:20:09] we could do is rewrite this into the
[00:20:12] following pipeline. Each map operation
[00:20:14] does a different component of implicit
[00:20:16] biases defined in the original task. And
[00:20:19] then we have a final operation to unify
[00:20:21] all of those results together thereby
[00:20:24] hopefully improving the accuracy.
[00:20:26] So we generalized this in our firstl
[00:20:30] rewrite or sorry firstl paper into the
[00:20:32] notion of rewrite directives and rewrite
[00:20:34] directives are these kinds of templates
[00:20:36] that describe how to rewrite
[00:20:38] subsequences of operators. So here are
[00:20:40] the two examples that I showed you
[00:20:42] previously. There are more like you can
[00:20:45] imagine inserting a map operation to
[00:20:47] make any semantic operator easy not just
[00:20:51] a semantic map and the one thing that's
[00:20:53] interesting that we do is that we use
[00:20:57] LLM agents to instantiate them. So
[00:20:59] something so we use LLM agents to come
[00:21:01] up with the prompts of the new operators
[00:21:03] that are substituted into the query plan
[00:21:06] the prompts the output schemas the chunk
[00:21:08] sizes whatever it is because those
[00:21:10] decisions are going to be very specific
[00:21:13] to the data and specific to the task.
[00:21:14] Now, as part of these rewrite
[00:21:16] directives, in our original paper, we
[00:21:18] came up with 13. And in a follow-up
[00:21:20] paper, now we have 30 plus that's
[00:21:23] currently in DOCTL, we had to come up
[00:21:26] with new operator types to enable these
[00:21:27] rewrites, right? It's not just semantic
[00:21:28] rewrites, right? It's not just semantic
[00:21:30] map reduce filter anymore. We also have
[00:21:33] these nonlm empowered and some empowered
[00:21:35] operators. We came up with a bunch of
[00:21:37] new ones. But before I go into that, I
[00:21:38] also want to show you that you can use
[00:21:41] rewrite directives to also improve the
[00:21:43] cost, not just the accuracy. So for
[00:21:46] example, I could combine two operators
[00:21:48] together. Maybe two of them are fairly
[00:21:51] easy to do. So I can make the entire
[00:21:53] pipeline cheaper by just fusing two
[00:21:55] operators together. And then I can
[00:21:58] eliminate one LLM call, basically one
[00:22:01] entire LLM pass over the documents,
[00:22:04] making it cheaper. My favorite some of
[00:22:05] my favorites one is you can replace
[00:22:07] different operator semantic operators
[00:22:10] with code. So some of these that are
[00:22:11] simply just adding up the results
[00:22:13] together or like concatenating results
[00:22:15] into a list. Turns out you can replace
[00:22:16] into a list. Turns out you can replace
[00:22:18] those with an agent synthesized Python
[00:22:21] function that simply just concatenates.
[00:22:23] Right? That's [snorts] zero cost
[00:22:25] compared to the l. And then my favorite
[00:22:28] one is super it's a little bit complex
[00:22:30] but very inspired by projection push
[00:22:33] down in databases but the idea here is
[00:22:36] if that your task doesn't need to read
[00:22:38] the entire document. So if there are
[00:22:40] cheap ways of identifying the portions
[00:22:43] of the document that are relevant to all
[00:22:45] of the tasks in your pipeline then you
[00:22:47] can synthesize an operator to just
[00:22:49] quickly find those. So maybe it's just a
[00:22:51] keyword search that'll find those. Maybe
[00:22:53] it's an embedding based lookup that is
[00:22:56] going to find those small portions and
[00:22:57] then push that operator down in the
[00:22:58] then push that operator down in the
[00:23:00] query plan and so now the size of your
[00:23:03] document is much smaller for all of the
[00:23:06] downstream semantic operators. So this
[00:23:08] overall can reduce cost if you're able
[00:23:10] to synthesize such an operator. So those
[00:23:12] are the flavors of rewrite directives
[00:23:13] that we consider as what rewrite
[00:23:14] directives I think are the biggest
[00:23:16] contribution that the DOETL project kind
[00:23:19] of gave to the database community. And
[00:23:21] I'd also had to I also mentioned as
[00:23:23] coming up with these rewrite directives,
[00:23:25] we came up with new operators. I'll talk
[00:23:27] about two of them. For example, one of
[00:23:29] them is the gather operator. We realize
[00:23:32] when you split documents into chunks,
[00:23:34] when you look at individual chunks, it's
[00:23:35] very difficult to make sense of it in
[00:23:37] isolation. If you feed that into a large
[00:23:39] language model, it's just simply not
[00:23:42] going to understand who he is. So our
[00:23:45] solution is to basically augment each
[00:23:47] chunk with useful context that's
[00:23:48] chunk with useful context that's
[00:23:50] surrounding or other context in the
[00:23:51] document that's needed to help make
[00:23:53] sense of it. For example, you can think
[00:23:55] of windowing idea like always have the
[00:23:56] of windowing idea like always have the
[00:23:58] previous chunk appended to a chunk that
[00:23:59] you're looking at. You can think about
[00:24:00] you're looking at. You can think about
[00:24:02] having a summary of all previous chunks.
[00:24:04] You can think about having the metadata
[00:24:06] or some table of contents included
[00:24:08] that's always in the beginning of the
[00:24:09] document. Well, you can also include
[00:24:12] that in every single chunk so the LLM
[00:24:14] can make sense of it in this split map
[00:24:16] reduce rewrite.
[00:24:19] Another operator we had to do was this
[00:24:21] resolve operator. We basically elevated
[00:24:22] entity resolution as a first class
[00:24:25] citizen. Why do we need it? Well, if you
[00:24:27] want to group by an LLM extracted
[00:24:30] attribute, often the LLM extracts things
[00:24:32] inconsistently. So, you need to do some
[00:24:34] sort of entity resolution before you're
[00:24:36] doing the group by. So you can make sure
[00:24:38] all of the documents are in the same
[00:24:40] group that you intended.
[00:24:42] So if I'm going to bubble up back to
[00:24:44] where I was before, what's the plan
[00:24:47] space looking like for semantic data
[00:24:48] processing? Well, it's different. It is
[00:24:50] kind of what you think. You take
[00:24:52] strategies from the a IML community for
[00:24:54] how to execute these operators, but also
[00:24:56] we come up with this notion of rewrite
[00:24:58] directives and we also instantiate them
[00:25:01] with LLM agents. Um, so they can be very
[00:25:03] very tailored to the task that the user
[00:25:04] writes.
[00:25:07] So next I want to briefly talk about the
[00:25:09] cost model. Okay. So say I've got a
[00:25:11] collection of plans or a way to
[00:25:12] collection of plans or a way to
[00:25:14] enumerate the plan space for a semantic
[00:25:16] operator pipeline. How do I know which
[00:25:18] ones are good, right? Which ones are
[00:25:20] cheap. For example, in traditional data
[00:25:22] processing, imagine you're writing a
[00:25:23] Spark pipeline. There are many different
[00:25:24] Spark pipeline. There are many different
[00:25:26] Spark plans. Spark wants to know what's
[00:25:28] the lowest latency. So how do they do
[00:25:29] this? Well, they have good ways to
[00:25:32] estimate kind of IO, CPU cost. They use
[00:25:34] cardality estimates of their data sets
[00:25:36] and ultimately like these kinds of cost
[00:25:38] models are very quick right you run them
[00:25:41] you see you get you figure out what the
[00:25:43] cost is of your query plan now in
[00:25:44] semantic data processing things are
[00:25:46] different because cost is not just
[00:25:49] latency anymore right you these semantic
[00:25:51] operator plans can vary in accuracy a
[00:25:52] operator plans can vary in accuracy a
[00:25:53] lot and there's no point doing something
[00:25:56] with very low accuracy so we also now
[00:25:58] have to model accuracy we have to model
[00:26:00] latency accuracy and dollar costs right
[00:26:01] we're paying open AI people don't want
[00:26:03] to pay millions of dollars to OpenAI for
[00:26:05] a query plan. And so it's hard to
[00:26:06] a query plan. And so it's hard to
[00:26:08] estimate accuracy, right? There's like
[00:26:09] if you think about these semantic
[00:26:12] operator pipelines, I have a pipeline
[00:26:15] like this. How do we know how accurate
[00:26:17] it's going to be? If we do some sort of
[00:26:19] rem rewrite, say like I'm going to do a
[00:26:21] task decomposition and I'm going to use
[00:26:22] task decomposition and I'm going to use
[00:26:24] cheaper models. Who here can tell me
[00:26:27] exactly what accuracy this rewritten
[00:26:29] plan is going to give me? Unfortunately,
[00:26:31] in order to estimate the accuracy of the
[00:26:33] rewrite, the only solution I have is to
[00:26:35] execute it on samples, which kind of
[00:26:37] sucks, right? Because that is very
[00:26:39] expensive and I have to wait a very long
[00:26:41] time to figure out, okay, after this
[00:26:43] plan is executed on samples, what's the
[00:26:45] sample accuracy?
[00:26:47] [gasps] So, what we thought about is
[00:26:49] like, okay, is there a how do we think
[00:26:51] about coming up with rewrite directives
[00:26:53] that guarantee
[00:26:55] that the rewritten plan is within a
[00:26:58] target accuracy of the old plan? Because
[00:27:01] now if I can do this rewrite and by
[00:27:03] construction I'm able to guarantee that
[00:27:05] the accuracy is very close to the
[00:27:07] original one then I can avoid rerunning
[00:27:09] or I can avoid running this candidate
[00:27:12] plan on samples to estimate accuracy.
[00:27:14] So if that's a little bit to wrap your
[00:27:16] head around that's okay. I can get into
[00:27:19] that at the end if there's Q&amp;A about it.
[00:27:22] But for now like assume what if we can
[00:27:24] do this? Well it turns out that we
[00:27:27] actually can. What we can do is we
[00:27:29] actually look at the related literature
[00:27:32] around cost optimization from the ML and
[00:27:34] video processing video graphics
[00:27:36] community. So the idea is that you can
[00:27:39] actually reduce cost while maintaining a
[00:27:42] target accuracy by routing inputs
[00:27:45] through a sequence of model of various
[00:27:47] costs. So I'll concretely explain what
[00:27:49] that looks like. Say I want to run my
[00:27:51] map operation over lots of long
[00:27:54] documents. Well, first what I can do is
[00:27:56] route that through a proxy or a cheap
[00:27:59] model. Now if that cheap model is very
[00:28:02] confident in its prediction or its
[00:28:05] output, then I can just accept it. And
[00:28:08] if it's not, well then I can route it to
[00:28:10] the original plan or the Oracle plan and
[00:28:13] then accept that prediction. So this
[00:28:15] kind of c model cascade architecture
[00:28:18] works really well if I'm able to route
[00:28:20] most of my queries through the proxy
[00:28:23] only like I can bypass going through the
[00:28:28] Oracle model and this also works only if
[00:28:30] I'm able to pick some confidence
[00:28:32] thresholds to meet the Oracle accuracy.
[00:28:35] So that is the proxy model is correlated
[00:28:37] with the accuracy for many many
[00:28:39] documents.
[00:28:41] So in the literature in the model
[00:28:43] cascade literature the algorithms that
[00:28:45] people people typically do is they run
[00:28:47] the proxy on samples they iterate
[00:28:49] through various thresholds confidence
[00:28:51] thresholds in those samples they come up
[00:28:53] with the minimum threshold that is going
[00:28:55] to meet the oracle target accuracy and
[00:28:56] they ship that off and it works like
[00:28:58] that that is a good algorithm that has
[00:29:00] worked many many times over the last dec
[00:29:01] decades.
[00:29:03] So what we did was we thought okay how
[00:29:06] are we going to apply this idea to our
[00:29:09] docl style rewrites. So we came up with
[00:29:11] this generalization of the model cascade
[00:29:15] idea called task cascades. So it turns
[00:29:17] out that models are not the only factor
[00:29:19] of cost or not the only thing you can
[00:29:21] vary in a cascade. You could also vary
[00:29:24] how much of the data or what slice of
[00:29:27] the document in LLMC's and you can also
[00:29:30] vary how complex the operation is. So
[00:29:32] there's no you don't need to send the
[00:29:34] same prompt to the proxy model. you
[00:29:36] could send a simpler prompt to a proxy
[00:29:39] model that simply correlates with your
[00:29:41] original operation prompt. So this kind
[00:29:43] of unifies insights from both rewrite
[00:29:44] of unifies insights from both rewrite
[00:29:45] directives where we're able to create
[00:29:47] simpler or cheaper variants of the task
[00:29:50] that are predictive as well as MLS
[00:29:52] insights where if we run on smaller
[00:29:55] document samples or we kind of manage
[00:29:58] our KV catch very well then perhaps we
[00:30:01] can reduce overall cost. And so very
[00:30:04] broadly speaking like visualizing a task
[00:30:07] cascade imagine I have an operation on
[00:30:10] these court opinions or court documents
[00:30:12] and I have segmented my document into
[00:30:15] pieces. Now the Oracle task or the
[00:30:18] pre-rewritten plan is as follows just
[00:30:20] running that operation as is with the
[00:30:22] most expensive model. At the time we
[00:30:24] wrote this paper was GBT40 but
[00:30:26] substitute that in for whatever model
[00:30:28] it's going to be. And you run this on
[00:30:31] the full document. So now a bunch of
[00:30:33] proxy tasks can be as follows, right?
[00:30:35] Maybe it's varying the operation. A
[00:30:38] simpler task is is there any lower court
[00:30:40] mentioned? If there's no lower court
[00:30:42] mentioned, then there's no way it can be
[00:30:44] overturning the lower court, right? So
[00:30:46] this is a simpler version of the task
[00:30:48] that correlates a lot with the original.
[00:30:50] We can run that on maybe a smaller
[00:30:52] portion of the document. And like that,
[00:30:54] we can vary different tasks, right? Does
[00:30:56] it say does it have specific keywords?
[00:30:58] again something that a cheap proxy model
[00:31:00] can do much more accurately and you
[00:31:02] don't need to do on the entire document.
[00:31:05] Um so the idea of a task cascade is to
[00:31:08] then assemble the sequence of tasks in
[00:31:11] order to minimize cost. So you want to
[00:31:13] resolve as many documents early on so
[00:31:15] that very few documents pass to that
[00:31:17] oracle task. So in our paper we
[00:31:18] oracle task. So in our paper we
[00:31:19] formalize the idea of this rewrite the
[00:31:22] task cascade rewrite and it's a little
[00:31:24] bit involved to construct these task
[00:31:26] cascades but because we can guarantee
[00:31:29] the accuracy probabilistically
[00:31:31] it's okay we don't it's okay to spend
[00:31:33] money instantiating this directive
[00:31:35] because we know it will be useful we
[00:31:36] show that in our paper constructing
[00:31:38] optimal task cascade isn't hard in the
[00:31:40] task space and that motivates a greedy
[00:31:42] algorithm to do it I won't get into the
[00:31:43] details I also won't get into the
[00:31:45] details around the accuracy I think that
[00:31:47] if you're interested in reading the
[00:31:48] paper, you absolutely should look into
[00:31:51] that. But the point is that constructing
[00:31:53] these task cascades in these rewrites,
[00:31:56] we're able to reduce cost compared to
[00:32:00] the pipeline before rewriting to 86% on
[00:32:02] average, which is awesome. Staying
[00:32:05] within a 90% target accuracy.
[00:32:07] So bubbling back up to the cost model
[00:32:10] here, expense, estimating accuracy of
[00:32:12] plants is very expensive because you
[00:32:14] have to like run it on samples and
[00:32:16] figure out. But for some certain
[00:32:19] rewrites for task cascade rewrites we
[00:32:20] are able to guarantee that accuracy by
[00:32:24] construction and so we can help reduce
[00:32:27] the cost of exploration there.
[00:32:28] All right. So the last thing I want to
[00:32:31] touch on before moving to the latter
[00:32:33] part of the talk is the search
[00:32:35] algorithm. So we talked about how to
[00:32:37] enumerate plans for semantic operator.
[00:32:39] We talked about how to estimate the cost
[00:32:41] and accuracy and latency of semantic
[00:32:44] operators. Now, how do you search over
[00:32:46] this plan space to pick the best plan?
[00:32:48] And in traditional data processing,
[00:32:49] there's a bunch of different query
[00:32:51] optimizers and databases. And the idea
[00:32:54] is to find a single optimal cheap plan.
[00:32:56] And the way that these query optimizers
[00:32:58] work is they break down your SQL query
[00:33:00] or your Spark pipeline or whatever into
[00:33:03] subp expressions, optimize individual
[00:33:05] sub expressions, and then use a dynamic
[00:33:06] programming algorithm to figure out the
[00:33:09] optimal entire query plan. So what's
[00:33:11] different now in semantic data
[00:33:13] processing and semantic operators? Well,
[00:33:16] first is from the user perspective,
[00:33:18] there isn't really a concept of a single
[00:33:21] optimal plan. Like what does that mean?
[00:33:24] Plans vary in accuracy, in quality, and
[00:33:27] cost, right? So maybe if somebody has a
[00:33:30] very big budget, then they're willing to
[00:33:31] get very high acc they're willing to
[00:33:33] search for very high accuracy. Maybe if
[00:33:34] somebody doesn't have a very large
[00:33:35] budget, they just want the highest
[00:33:38] accuracy within that budget. Well, then
[00:33:39] we're going to get something else on
[00:33:40] that curve, right? So, you want to be
[00:33:42] able to showcase multiple plans that are
[00:33:44] available and then have the user be able
[00:33:46] to pick. And then the second thing
[00:33:49] that's a little bit more subtle is that
[00:33:52] it's not great to locally optimize parts
[00:33:54] of these semantic operator pipelines.
[00:33:57] And I'll give you an example here. So,
[00:33:59] in traditional databases, we can we
[00:34:01] locally optimize compose optimal
[00:34:03] subplans. But say we have our semantic
[00:34:05] operator pipeline. Again, this is just
[00:34:06] something that was from an earlier
[00:34:09] slide. We had four map operators.
[00:34:11] Suppose I wanted to just locally
[00:34:15] optimize this third map operator, right?
[00:34:16] Maybe I come up with some great solution
[00:34:20] to do it, maximize the accuracy of this.
[00:34:23] Awesome. But now if I want to consider
[00:34:25] that in context of the entire end-to-end
[00:34:27] pipeline, perhaps there are other
[00:34:29] operators in the pipeline that can
[00:34:31] correct or augment or change or
[00:34:33] interpret the results differently of
[00:34:35] these other operators. So in other
[00:34:38] words, the way that I execute my third
[00:34:40] operator actually depends on the
[00:34:42] implementations that I choose for other
[00:34:45] operators. So it's not optimal to then
[00:34:47] just individually optimize different
[00:34:49] parts of the query plan. we kind of want
[00:34:52] to consider a very global search. So in
[00:34:54] our recent preprint, we come up with a
[00:34:56] global search algorithm to look over
[00:34:57] these rewrite directives. It's very much
[00:34:58] these rewrite directives. It's very much
[00:35:00] inspired by Monte Carlo tree search
[00:35:02] mechanisms from the AI community. But we
[00:35:04] treat this as a graph search problem.
[00:35:06] Every node in the graph is a complete
[00:35:08] pipeline. Every edge is some sort of
[00:35:10] rewrite. So an instantiation of a
[00:35:12] rewrite directive and we keep exploring
[00:35:14] different query plans until some sort of
[00:35:16] budget is exhausted. So this is actually
[00:35:19] a real sample of one of the public
[00:35:21] defenders workloads. They authored their
[00:35:24] semantic operator pipeline used GPT5 and
[00:35:26] it gave them it's actually not accuracy.
[00:35:30] F1 score of 47%. Which is abysmal like
[00:35:32] it's not usable. Um so they needed
[00:35:33] something more accurate and also they
[00:35:34] wanted something cheaper because they
[00:35:36] didn't want to spend that much money. So
[00:35:37] by searching through our react
[00:35:39] directives, right, we were able to find
[00:35:47] So how do we do that? Well, we go
[00:35:49] through this three-step search. First
[00:35:50] selecting the pipeline we want to
[00:35:52] rewrite, then rewriting the pipeline
[00:35:55] using the LLM agent, and then evaluating
[00:35:57] on samples when needed to get estimates
[00:36:00] of cost and accuracy. How do we do
[00:36:03] selection? Well, we use a UCB inspired
[00:36:04] algorithm. Again, I was talking about
[00:36:06] MCTS. The idea is that we select
[00:36:08] pipelines that we believe are very good
[00:36:10] to rewrite. So they have high accuracy
[00:36:12] themselves and they lead to children
[00:36:15] that also lie on the Pareto frontier. So
[00:36:17] we were prioritize rewriting those
[00:36:19] pipelines. And then we use LLM agents.
[00:36:20] pipelines. And then we use LLM agents.
[00:36:21] Say we want to rewrite this pipeline
[00:36:24] circled in red. We use LLM agents to
[00:36:26] then instantiate the rewrite. So it
[00:36:29] figures out given our directive registry
[00:36:32] of 30 plus rewrite directives which
[00:36:35] directive applies best here because it's
[00:36:37] the LLM agent is allowed to read sample
[00:36:39] data look at the history of pipelines
[00:36:41] executed whatnot to make intelligent
[00:36:43] decisions and then it also does the
[00:36:44] decisions and then it also does the
[00:36:45] instantiation. So it comes up with the
[00:36:47] prompts for the new operators. So say it
[00:36:49] wants to create a new summary operator
[00:36:51] to reduce the cost of this pipeline.
[00:36:52] to reduce the cost of this pipeline.
[00:36:53] Well, then it will come up with this
[00:36:55] prompt to summarize the document and
[00:36:56] then that smaller version of the
[00:36:58] document will be submitted to all the
[00:37:01] downstream operators and then we execute
[00:37:04] that on samples, record the cost and
[00:37:06] accuracy, update our estimates and so
[00:37:08] forth.
[00:37:11] So the final thing was okay we did so
[00:37:13] much how well does this do? So we take
[00:37:16] some real workloads how well how
[00:37:18] accurate of plans are we able to find
[00:37:19] and how cheap of plans are we able to
[00:37:20] and how cheap of plans are we able to
[00:37:22] find? So we've got a bunch of workloads
[00:37:26] inspired by real users of docet. We also
[00:37:28] use three different baselines. So
[00:37:29] there's a semantic operator system at
[00:37:31] Stanford called Lotus that they're
[00:37:33] building. There's a semantic operator
[00:37:35] system at MIT called Polyest and the new
[00:37:38] optimizer for it called Abacus. And we
[00:37:40] basically allowed these systems to
[00:37:43] choose from 11 different models like all
[00:37:45] of the GBT variants, all the Gemini
[00:37:47] variants.
[00:37:50] And we found that every time we produce
[00:37:51] the most accurate query plan, which is
[00:37:54] very exciting. Um, and often it can be
[00:37:57] 2x times the accuracy of what the other
[00:37:59] systems can find. This GPT5 agent
[00:38:02] baseline is basically I gave the docl
[00:38:04] query engine to GPT5 and the
[00:38:07] documentation for docket and GPT5 is
[00:38:10] allowed to test pipelines on samples, do
[00:38:12] whatever it wants and give us the best
[00:38:13] pipeline that it thinks it can come up
[00:38:16] with. Um so this kind of underscores
[00:38:18] that okay having these carefully
[00:38:20] designed rewrite directives for data
[00:38:23] processing can outperform that agent
[00:38:25] right we're able to find plans that are
[00:38:26] right we're able to find plans that are
[00:38:28] more accurate and the other thing is if
[00:38:30] you look at the most accurate plan that
[00:38:32] each one of these baseline system found
[00:38:35] docl's optimizer is able to find a plan
[00:38:37] with matching accuracy at a small
[00:38:39] fraction of the cost so this also
[00:38:41] underscores right if you're able to
[00:38:43] search the parto frontier and search
[00:38:46] well search intelligently, maybe you can
[00:38:47] find very cheap plans that are within
[00:38:48] find very cheap plans that are within
[00:38:49] budget.
[00:38:52] So, wrapping all of that up, optimizing
[00:38:55] semantic data pipelines. Here we talked
[00:38:57] about, okay, what are the different
[00:38:59] types of rewrites that we want to do in
[00:39:01] semantic operator pipelines? Well, in
[00:39:03] DOCTL, we came up with rewrite
[00:39:06] directives to improve accuracy and cost.
[00:39:08] And the second thing we talked about is
[00:39:10] really search and cost modeling, right?
[00:39:12] We search over complete plans in DOC
[00:39:14] ETL. That's very different from
[00:39:16] traditional data systems. We use learn
[00:39:18] heruristics to come up with what plans
[00:39:20] are good to rewrite. We use statistical
[00:39:22] tools to estimate whether rewrites will
[00:39:24] be helpful. Going back to that task
[00:39:26] cascades idea. So wrapping that all up
[00:39:27] together when you think about how to
[00:39:29] build scalable semantic data processing
[00:39:30] build scalable semantic data processing
[00:39:31] systems. I like to say well we don't
[00:39:33] just throw out all the database
[00:39:36] foundations ever. We definitely build on
[00:39:37] top of all we know for how to build good
[00:39:39] data systems. We also are not afraid to
[00:39:40] data systems. We also are not afraid to
[00:39:41] adapt them pretty significantly for the
[00:39:45] realities of LLM workloads.
[00:39:49] All right, so that was the meat of the
[00:39:51] talk. I have about 10 minutes left of
[00:39:54] content on thinking about how to make
[00:39:57] really good experiences for people to
[00:39:59] author these kinds of semantic operator
[00:40:01] pipelines.
[00:40:03] All right.
[00:40:05] So,
[00:40:07] I'd mentioned the word steering and
[00:40:11] steering is really this idea of trying
[00:40:13] to get the AI to do what you want to do.
[00:40:17] So, in complex tasks like docet
[00:40:19] pipelines, steering is very hard, right?
[00:40:21] Because you're trying to express a very
[00:40:23] complex idea or concept, something like
[00:40:25] extract racially charged statements,
[00:40:27] right? This is not a real prompt. Nobody
[00:40:29] can write such a prompt and expect to
[00:40:31] get good results from even the best LLM
[00:40:34] in the world. Operator descriptions must
[00:40:37] figure out users must figure out how do
[00:40:39] you express the fuzzy task very very
[00:40:41] precisely
[00:40:43] and often that involves encompassing a
[00:40:45] lot of edge cases in the data that they
[00:40:48] didn't know about. So concretely right
[00:40:51] expressing a fuzzy task precisely if you
[00:40:52] have ever written a prompt that this is
[00:40:54] hard right you have to think about okay
[00:40:56] what does racially charged mean? what
[00:40:57] are the different ways things can be
[00:40:59] racially charged and you have to figure
[00:41:00] out how to express that in English or
[00:41:03] some some way to communicate to the LLM.
[00:41:04] some some way to communicate to the LLM.
[00:41:05] And then the second part is you might
[00:41:08] not be familiar with all of the inputs
[00:41:10] that are going to go to your system and
[00:41:12] some of them might be edge cases and you
[00:41:14] kind of do need to explain that behavior
[00:41:17] or in some way maybe provide examples
[00:41:19] whatnot to the LLM in order to
[00:41:21] accurately do the task. So we realized
[00:41:23] that this the steering problem was hard.
[00:41:25] So maybe we should build a specialized
[00:41:28] interface for people to write docu
[00:41:29] pipelines. And so that's exactly what we
[00:41:31] did with the doc wrangler project. The
[00:41:33] doc wrangler project is very much
[00:41:36] inspired by work in good idees. It's two
[00:41:38] parts. There's a pipeline editor. Think
[00:41:39] of it as like a very notebooky e
[00:41:40] of it as like a very notebooky e
[00:41:42] pipeline editor. The second half of it
[00:41:44] is the input and output inspector that
[00:41:45] allows you to richly look at the
[00:41:47] semantic operator outputs and make
[00:41:51] decisions on those. Now, when we built
[00:41:53] this, we thought, "Oh man, we can build
[00:41:55] all sorts of features to help users
[00:41:57] steer AI, right? I bet if I asked every
[00:41:59] person here, everyone could come up with
[00:42:02] some AI cool AI feature to help people
[00:42:04] use, I don't know, to write a semantic
[00:42:06] operator." But that alone was not
[00:42:08] interesting because you can come up with
[00:42:10] anything. What we really wanted to know
[00:42:13] was okay, can we come up with a theory
[00:42:16] of tools to help users steer AI? Like a
[00:42:18] complete theory of tools. Where are
[00:42:20] tools needed? What is the complete class
[00:42:23] of problems users have? So that anybody
[00:42:27] can easily build tools for users now on.
[00:42:29] So in order to come up with this mental
[00:42:30] model, we look to challenges and related
[00:42:33] domains. So for example, in data
[00:42:34] cleaning, many of you might be familiar
[00:42:37] with data cleaning or data wrangling.
[00:42:40] Now in data cleaning, the user wants to
[00:42:42] clean their data before they do some
[00:42:44] analysis or machine learning or whatever
[00:42:46] on it. One challenge is knowing what is
[00:42:48] in the data, right? You can't write your
[00:42:50] data cleaning code if you have no idea
[00:42:51] what's in the data, what all the errors
[00:42:53] are in your data. And then the second
[00:42:56] challenge is even if all the errors in
[00:42:58] your data, what is all the code that you
[00:43:00] need to write to clean it, right? You
[00:43:02] need to write all sorts of pandas
[00:43:03] expressions, all sorts of regular
[00:43:05] expressions, all sorts of weird
[00:43:07] transformations, right? Not everybody
[00:43:09] can author all of those exhaustively.
[00:43:10] can author all of those exhaustively.
[00:43:11] So our community has come up with a
[00:43:13] bunch of tools for each, right? Knowing
[00:43:14] what's in the data. Think about
[00:43:16] structured data and tables. If you log
[00:43:18] into your Snowflake database, there's
[00:43:20] visualizations of your data, right?
[00:43:22] There's summary statistics. You can find
[00:43:24] outliers in your data. We have
[00:43:26] algorithms to help you do that with your
[00:43:27] databases.
[00:43:30] For knowing what code to write in data
[00:43:32] cleaning, we also have tools to help you
[00:43:34] with this. Folks might be familiar with
[00:43:37] flashfill, for example, in Excel for
[00:43:39] prediction interaction. Jupyter
[00:43:41] notebooks are a great example of a tool
[00:43:43] where you can quickly prototype
[00:43:44] different data cleaning or data
[00:43:46] transformations to figure out what works
[00:43:49] for your class for your task. Right? So
[00:43:51] we've come up with a good mental model
[00:43:53] of data cleaning challenges. Now what we
[00:43:55] realized is to extend this to the
[00:43:57] semantic operator setting all we had to
[00:44:00] do is add a new island. So now we have
[00:44:02] challenges between the user writing the
[00:44:04] pipeline the data that they're trying to
[00:44:06] run the pipeline on as well as the
[00:44:08] pipeline itself. right? Because those
[00:44:10] are fuzzy and executed by LLMs in their
[00:44:12] own world. So you gain names for all of
[00:44:14] these three gulfs. And if you're
[00:44:17] familiar with Norman's Gulf and HCI,
[00:44:18] right, you'll know that Norman's Gulf
[00:44:20] applies to every single interface. So
[00:44:21] these are not gulfs in the sense of
[00:44:22] these are not gulfs in the sense of
[00:44:24] Norman's gulfs. Not every tool needs to
[00:44:26] solve all three gulfs. Think of these as
[00:44:28] three gaps that users have to face or
[00:44:30] three sets of challenges that users have
[00:44:32] to face in semantic data processing
[00:44:35] entirely. So I'll talk a little bit
[00:44:36] about them and then how we solved each
[00:44:38] one or how we built a solution to solve
[00:44:39] each one of them but you could build
[00:44:42] infinitely many solutions in each gulf.
[00:44:44] So first is gulf of comprehension right
[00:44:46] and unstructured data we don't have good
[00:44:48] visualizations we don't have good ways
[00:44:51] to like identify outliers in documents
[00:44:53] right we don't have algorithm for that
[00:44:55] so how do we solve that the second one
[00:44:56] so how do we solve that the second one
[00:44:57] is even if users know what's in their
[00:44:59] data now they have to write the code or
[00:45:00] they have to write the semantic operator
[00:45:03] to process it how do they express their
[00:45:06] complex query as some prompts and then
[00:45:08] the third is even if they've expressed
[00:45:10] the pipeline very well and it works on
[00:45:12] say 100 documents ments. Maybe if you
[00:45:14] try to generalize that to your entire
[00:45:16] document corpus, LLM simply make
[00:45:18] mistakes. They're imperfect and so it
[00:45:22] breaks at scale. So in doc wrangler, we
[00:45:24] contribute this three golf framework and
[00:45:26] we also build a feature to assist users
[00:45:28] in each gulf for the gulf of
[00:45:30] comprehension. I'm going to ground kind
[00:45:33] of my demonstration of this in a task
[00:45:36] from a medical analyst. So a medical
[00:45:38] analyst go through a co corpus of doctor
[00:45:40] patient conversations and maybe they
[00:45:42] want to extract all the medications from
[00:45:44] each transcript and this is just
[00:45:46] conversations think like zoom
[00:45:48] transcripts right so medications are
[00:45:50] just mentioned in text in there now the
[00:45:51] interface might look something like this
[00:45:53] they write their semantic operator in
[00:45:55] the top part of it don't worry about
[00:45:57] what's in there and then they want to
[00:45:59] inspect the outputs because they they
[00:46:01] don't really know what's in their data
[00:46:02] so now the challenge with gulf of
[00:46:04] comprehension is to just figure out
[00:46:08] what's in the data. So we have a feature
[00:46:10] so they can expand all of the rows one
[00:46:13] by one read the outputs kind of see how
[00:46:15] they compare. So on the left is the
[00:46:17] extracted medications on the right is
[00:46:20] the original source transcript and the
[00:46:21] key thing that we do here is offer the
[00:46:23] ability to provide feedback on the
[00:46:25] outputs. So this is our way of helping
[00:46:26] outputs. So this is our way of helping
[00:46:28] people find the outliers, find the
[00:46:30] patterns in the data. So perhaps they
[00:46:33] notice something interesting like oh
[00:46:35] when I see these medications I also see
[00:46:38] the dosages associated with them. I
[00:46:40] indeed would like my dosages also
[00:46:42] extracted as part of the analysis. How
[00:46:43] would they have known this? Right? They
[00:46:44] would they have known this? Right? They
[00:46:45] didn't know this at the time that they
[00:46:47] were writing the operation. They just
[00:46:48] they discovered it by looking at the
[00:46:50] data. So they needed this tool to be
[00:46:51] able to look at the data and arrive at
[00:46:54] the con the conclusion. And similarly,
[00:46:56] they might run into other sort of
[00:46:58] realizations, right? Maybe they have
[00:47:02] decided that they also um in this one
[00:47:03] they don't want over-the-counter
[00:47:05] medications extracted, right? So they
[00:47:07] don't want Tylenol, they don't want
[00:47:08] ibuprofen, just prescription
[00:47:10] medications. They could note that as a
[00:47:12] note and all of the notes in Doc
[00:47:14] Wrangler kind of persists in the sidebar
[00:47:15] so users don't have to forget. And in
[00:47:16] so users don't have to forget. And in
[00:47:17] practice, people can go up to like we've
[00:47:20] seen 25 30 notes. People just really
[00:47:21] look at their examples, provide
[00:47:23] feedback. If you've taken the eval
[00:47:25] course that this is open coding, right?
[00:47:27] You have to kind of do this process to
[00:47:29] get a good sense of what's happening in
[00:47:31] your pipeline, what's happening in your
[00:47:32] data.
[00:47:35] So now after this
[00:47:37] for the next gulf, bridging the gulf of
[00:47:39] specification or specifying a good
[00:47:42] pipeline, we just turn people's notes
[00:47:44] into better specifications. So we
[00:47:46] provide an interactive interface. What
[00:47:48] you'll see here is some green and some
[00:47:50] red. This is a new prompt that Doc
[00:47:53] wrangler has suggested based on your
[00:47:55] notes and you can iterate on this as you
[00:47:57] if you would like. You can directly edit
[00:47:59] it. You can add some feedback, have the
[00:48:01] AI edit it, whatever. We have a
[00:48:03] interface for that. But the point is
[00:48:05] here is assisted specification, right?
[00:48:07] People cannot specify the whole thing
[00:48:09] themselves. They need tools to assist in
[00:48:11] that specification.
[00:48:13] Then the last gulf gulf of
[00:48:15] generalization
[00:48:16] we find that users kind of get to a
[00:48:18] point where the operation gets very
[00:48:20] complex right they keep iterating on the
[00:48:23] data they keep iterating on their prompt
[00:48:25] prompt sometimes ask to do too much
[00:48:26] maybe we've tried to create three
[00:48:29] attributes in a single LLM call and one
[00:48:31] of these attributes for example
[00:48:34] extracting the primary complaint is not
[00:48:37] very accurately performed by the LLM. So
[00:48:39] what we do is every time the user
[00:48:41] actually runs an operation, we run an
[00:48:44] expensive LLM judge in the back and to
[00:48:48] run on a sample and see maybe are one of
[00:48:51] these inaccurate and if so we'll suggest
[00:48:53] hey maybe you should decompose this
[00:48:56] operation and propose a decomposition
[00:48:59] law rewrite directives. So that kind of
[00:49:01] brings it all back together. We replace
[00:49:03] the pipeline in there. In this case, our
[00:49:04] the pipeline in there. In this case, our
[00:49:06] rewrite ended up breaking down each
[00:49:08] individual attribute, I guess, into an
[00:49:10] operation. Like you could also imagine
[00:49:12] maybe we'd do a data decomposition. We'd
[00:49:14] split up the doc the transcripts into
[00:49:15] chunks. I don't know, whatever is the
[00:49:18] most accurate there.
[00:49:20] All right, so those are kind of how we
[00:49:22] went about Docker Wrangler designing for
[00:49:23] those three gulfs, right? New
[00:49:25] interactions, new mechanisms for users
[00:49:28] to bridge their challenges. And we
[00:49:29] actually did an online we did both an
[00:49:31] inerson study as well as an online
[00:49:33] deployment and evaluation. We learned a
[00:49:35] lot of stuff from it. We learned that
[00:49:37] people invented their own strategies to
[00:49:39] bridge the three gulfs which I thought
[00:49:41] was very fascinating. So for example to
[00:49:42] bridge the gulf of comprehension just
[00:49:45] knowing what's in the data. People would
[00:49:47] write these throwaway pipelines like
[00:49:49] summarize these documents extract the
[00:49:51] key ideas things that would just teach
[00:49:52] them more about the data before they
[00:49:54] actually did the analysis that they
[00:49:55] intended which I thought was
[00:49:57] interesting. People also tried to
[00:50:00] repurpose their operations for quick
[00:50:03] validation. So we have histograms for
[00:50:05] any float valued or numerical valued
[00:50:08] attribute that docl generates. So people
[00:50:10] would just add like boolean attributes
[00:50:12] or add numerical things so they could
[00:50:15] quickly kind of sanity check how did the
[00:50:17] LLM do. And we have a bunch of different
[00:50:19] observations that we write about in the
[00:50:21] paper across all of these pipeline runs.
[00:50:23] people from a bunch of organizations at
[00:50:25] least this is like what doc wrangler was
[00:50:27] able to identify do we use doc wrangler
[00:50:29] to analyze the doc wrangler logs we came
[00:50:30] to analyze the doc wrangler logs we came
[00:50:31] up with a sample of companies of people
[00:50:33] who used it which is exciting and what I
[00:50:36] think is very cool also tying this back
[00:50:39] to kind of the research arc is being
[00:50:40] able to build such a solution also grew
[00:50:43] the docket community quite a bit all
[00:50:47] right now the last three minutes I
[00:50:51] suppose I want to talk about kind of A
[00:50:53] third problem that we've been seeing
[00:50:55] that's underlying theme throughout
[00:50:57] pretty much all of the work um which is
[00:50:59] now when you have systems like docket
[00:51:02] and doc wrangler right how do you run
[00:51:04] those at scale and then know that the
[00:51:06] analysis is actually good and working on
[00:51:09] this problem actually motivated the eval
[00:51:11] course me working together with Hamill
[00:51:13] so pretty much people will very much
[00:51:15] resonate hopefully with these insights
[00:51:17] now when we thought about this question
[00:51:19] from the research perspective I was I
[00:51:20] was thinking about it from a very docky
[00:51:22] DTL perspective which is people come in
[00:51:24] to do their data analysis tasks with no
[00:51:27] label data and their evaluation criteria
[00:51:28] is very complex. So when I looked at a
[00:51:30] lot of like these ML benchmarks and
[00:51:32] these literatures a lot of the
[00:51:34] evaluation criteria or these kinds of RL
[00:51:36] evals a lot of them were quote unquote
[00:51:39] verifiable they're very easy to measure
[00:51:41] for example did the code run or not but
[00:51:42] that's just not the case for a lot of
[00:51:45] data processing. So we thought okay how
[00:51:47] can we kind of improve the eval
[00:51:50] experience for people with these complex
[00:51:52] tasks. So one system that we built
[00:51:54] called evalgen the paper is called who
[00:51:56] validates the val validators it's the
[00:51:59] most cited paper at w 2024. The idea
[00:52:02] that we had here was anyways when people
[00:52:03] are running these kinds of batch LL
[00:52:06] pipelines they spend a lot of time
[00:52:08] waiting for the results right if you
[00:52:10] want to run docetail pipelines on tens
[00:52:12] of thousands of documents you're kind of
[00:52:13] sitting there and waiting or I don't
[00:52:14] know doing your own thing before the
[00:52:18] results come back what if we can use the
[00:52:21] users input and feedback
[00:52:22] users input and feedback
[00:52:24] to figure out what makes for good and
[00:52:26] bad quality outputs so that's exactly
[00:52:29] the premise behind evalgen which is we
[00:52:31] built this kind of interface and this
[00:52:34] algorithmic flow that solicited labels
[00:52:37] on outputs as they were generated. Then
[00:52:41] created evaluators based on those labels
[00:52:43] and then was able to communicate at the
[00:52:46] end how well the outputs aligned with
[00:52:48] the user's intentions. And a video kind
[00:52:50] of looks kind of like this. We built it
[00:52:53] in the chain forge AI. We you suggest
[00:52:55] some criteria, you label some examples,
[00:52:57] just going through really fast. you get
[00:53:00] a report card and then you get a table
[00:53:02] of basically all of the LLM judges that
[00:53:04] we've created that align with the labels
[00:53:07] that you have generated. So we built
[00:53:09] this interface and again like think of
[00:53:11] this in the context of batch style tasks
[00:53:14] right so this is not just oneoff AI task
[00:53:16] this is I have a pipeline that is going
[00:53:18] to run on tens of thousands of users
[00:53:21] inputs and I want to figure out how to
[00:53:23] label how to evaluate at scale and when
[00:53:25] we did our user studies what we found
[00:53:27] was very surprising at least to us from
[00:53:29] a machine learning perspective which is
[00:53:32] that the evaluation criteria drifts
[00:53:35] across these many outputs so when users
[00:53:38] were were grading the LLM outputs, they
[00:53:39] decided they want to change or refine
[00:53:42] their criteria. So a concrete example in
[00:53:45] a data processing setting that we did
[00:53:48] was we did an entity extraction task and
[00:53:51] users were supposed to basically extract
[00:53:53] or the task was to extract entities from
[00:53:56] tweets and one of the eval criteria was
[00:53:59] don't extract hashtags as entities. Now
[00:54:01] when users were grading and they saw
[00:54:03] hashtags they'd be like yeah like that's
[00:54:04] that's not good. You don't want that
[00:54:07] extracted. But when they saw that happen
[00:54:09] frequently, they changed their mind
[00:54:11] sometimes. For example, what Colin
[00:54:13] Kaepernick, a famous football player,
[00:54:15] they thought, hm, yeah, I guess I said
[00:54:18] no hashtags entities, but this this one
[00:54:19] is actually kind of correct. I'm glad
[00:54:22] this was extracted. And when they saw it
[00:54:25] again, they realized like, oh man, like
[00:54:27] the LLM has done this several times. I
[00:54:28] actually agree with the LLM here. I want
[00:54:31] to kind of change my eval criteria. I
[00:54:33] still don't want hashtags extracted as
[00:54:35] entities unless they're a notable entity
[00:54:38] in the hashtag. So that was crazy to us
[00:54:40] because we were like, oh man, like we
[00:54:41] need these interfaces. We need these
[00:54:44] ongoing labeling processes processes to
[00:54:46] infer what evaluation criteria we should
[00:54:48] have. And users wanted to add new
[00:54:50] criteria, right? As they reviewed
[00:54:51] outputs, they learned about new failure
[00:54:53] modes. They also wanted to reinterpret
[00:54:55] criteria to better fit the LLM's
[00:54:57] behavior. Like as I showed in this
[00:54:59] example here, you know, better fit the
[00:55:00] LLM behavior. That's something that you
[00:55:02] can only figure out after you've
[00:55:05] observed enough LLM behavior. And this
[00:55:07] also, if you've taken the EVL's course,
[00:55:09] kind of motivated how we go through an
[00:55:11] iterative process to kind of do e to to
[00:55:15] evaluate outputs until the criteria
[00:55:18] drift kind of stabilizes to some extent.
[00:55:20] So all of this work kind of around doc
[00:55:22] wrangler around evalgen the papers that
[00:55:23] we've written have very excitingly been
[00:55:25] adopted by various tech companies. Um
[00:55:27] it's not that people have to adopt the
[00:55:29] tools as is. is really the ideas,
[00:55:31] intellectual merit behind them, but very
[00:55:34] very popular LLM ops companies kind of
[00:55:36] adopted these ideas and the ideas have
[00:55:38] seated the course kind of that Haml and
[00:55:40] I have co-taught. There's a really
[00:55:43] exciting article in the OpenAI cookbook
[00:55:45] about kind of our eval workflow that we
[00:55:47] created together where we adapt kind of
[00:55:49] qualitative coding and iterative coding
[00:55:52] ideas to do eval. And the course has
[00:55:54] gotten a lot of traction. So with that,
[00:55:55] that kind of concludes all of the
[00:55:58] research portion of my talk. I talked
[00:56:00] about both the scalable side of semantic
[00:56:02] data processing. I talked about some of
[00:56:05] the userf facing the AI alignment side
[00:56:08] of semantic data processing and I I
[00:56:11] remain super positive kind of we're so
[00:56:12] well on our way to kind of building this
[00:56:15] next generation of great data systems
[00:56:16] right you think about many eras of data
[00:56:19] systems the next one is coming we have
[00:56:21] already done a lot of work to get us
[00:56:23] there um we've kind of come up with new
[00:56:25] query optimizers we've come up with new
[00:56:27] eval methods right it's not just me
[00:56:29] there's a lot of work in the data
[00:56:31] communities the AI communities the HCI
[00:56:33] communities. Um, and there's a lot more
[00:56:35] that we can do that's going to get us
[00:56:37] there. We really deeply optimize on the
[00:56:39] system side. We cover the entire life
[00:56:41] cycle, right? What does EDA look like
[00:56:42] cycle, right? What does EDA look like
[00:56:44] for unstructured data? What does BI look
[00:56:46] like for unstructured data? Lots of
[00:56:48] exciting questions there. And thanks so
[00:56:49] much. Happy to take any questions.
[00:56:50] much. Happy to take any questions.
[00:56:51] &gt;&gt; Yeah. Would it be okay if I ask you some
[00:56:52] questions?
[00:56:53] &gt;&gt; Yeah, please.
[00:56:57] &gt;&gt; The Doc Wrangler UX and workflow, I
[00:56:58] &gt;&gt; The Doc Wrangler UX and workflow, I
[00:57:01] really love it. I find that when I saw
[00:57:04] it, I immediately recognized that it's
[00:57:08] not it's not relevant to just processing
[00:57:10] documents at scale or in like it's not
[00:57:13] it doesn't feel only relevant to let's
[00:57:16] say the docet kind of work. It feels
[00:57:19] like I always want this kind of workflow
[00:57:23] when iterating on any AI because like I
[00:57:27] want to try prompts against a lot of
[00:57:29] different examples. I want to see what
[00:57:31] happens. I want to iteratively do that.
[00:57:34] I want to refine my prompt if it feels
[00:57:38] like a good UX.
[00:57:40] Do you
[00:57:42] have you thought about that like the
[00:57:45] general the generalization of this UX
[00:57:46] general the generalization of this UX
[00:57:48] like how do you feel it applies across
[00:57:50] other problems? Have you thought about
[00:57:51] that?
[00:57:53] &gt;&gt; Yeah. No, it's a good question. So when
[00:57:55] we came up with this interfa when we
[00:57:57] came up with doc wringler and we came up
[00:57:59] with these three gulfs we did not do
[00:58:01] this for the purpose of like
[00:58:03] generalizing to AI systems. I really
[00:58:05] deeply thought that this was specific to
[00:58:06] deeply thought that this was specific to
[00:58:08] data processing where users just don't
[00:58:10] know what's like it's very hard to read
[00:58:11] documents and know what's in your data
[00:58:14] the tasks are complex and so forth and
[00:58:16] only after doing the user studies and
[00:58:18] people in the user studies who also are
[00:58:20] generally familiar like build AI agents
[00:58:22] like for their work and stuff people in
[00:58:24] my user studies are typically I always
[00:58:26] try to do half like engineers people who
[00:58:28] are really in the AI space and half like
[00:58:31] people who are not at all AI engineers
[00:58:32] people who are not at all AI engineers
[00:58:34] but do data analysis. So, I'm like just
[00:58:36] trying to see what sticks throughout
[00:58:38] both. And all the AI engineers were
[00:58:41] like, "Oh my god, like I I love this
[00:58:44] like ability to give feedback." Like I I
[00:58:46] didn't think to do like I didn't think
[00:58:47] that this was possible. And I think this
[00:58:49] speaks to your point about the
[00:58:52] generalization because when agents
[00:58:54] people are programming agents, agents
[00:58:57] exhibit behavior that people like don't
[00:58:58] really know what to anticipate. Like
[00:59:01] agents make tool calls. nobody knows
[00:59:02] what's happening in those tool calls.
[00:59:04] Are those tool calls going to generalize
[00:59:06] to all of the inputs? Even if the inputs
[00:59:08] are small and users have a pretty good
[00:59:11] sense of what those inputs might be,
[00:59:12] they still don't know how to anticipate
[00:59:15] the agent behavior. And I think that was
[00:59:17] like a key insight for me in terms of
[00:59:19] like, oh, maybe this model generalizes.
[00:59:21] And so when you and I taught the course,
[00:59:23] I was thinking, okay, how do we like
[00:59:25] what do we need to do to adapt this
[00:59:27] model? It probably will help. And the
[00:59:31] idea behind open coding on agent traces
[00:59:33] like looking at traces looking at all
[00:59:35] the tool calls providing feedback on
[00:59:37] kind of where the LLM behavior was a
[00:59:39] mistake. It was very key right in this
[00:59:42] eval life cycle. Whereas in document
[00:59:44] processing a lot of it is looking at the
[00:59:47] original source data. It's the the LLM
[00:59:49] behavior in relation to the source like
[00:59:51] I also want medication and dosages
[00:59:53] extracted and things that I only see
[00:59:55] when uncovering the original data. So
[00:59:57] those are kind of I think the comparison
[00:59:59] and the contrast. I think the model
[01:00:01] definitely generalizes but kind of
[01:00:03] specifically what you look at like tool
[01:00:06] calls might be different.
[01:00:09] Another question I have is and this is a
[01:00:10] serious question even though I give you
[01:00:12] a hard time about it sometimes or I like
[01:00:15] to joke is I really it is quite
[01:00:18] fascinating that a lot of your work in
[01:00:19] papers
[01:00:22] really look like a product like because
[01:00:24] in and whenever I show it to someone
[01:00:27] else they're like oh where can we buy it
[01:00:29] because and the reason that we feel that
[01:00:32] way is hey there's
[01:00:34] of course there's the user studies
[01:00:36] there's the theory and the grounding of
[01:00:39] that theory and all of that's regular
[01:00:41] like normal stuff. But then what we see
[01:00:43] is like okay we see software, we see
[01:00:47] user interfaces, we see uh all the user
[01:00:51] studies at like real companies and then
[01:00:54] kind of like all the sort of
[01:00:55] trappings of like a SAS application
[01:00:57] almost except like we're not paying you
[01:00:58] almost except like we're not paying you
[01:01:00] can this is all free knowledge and free
[01:01:02] freely available stuff but like
[01:01:05] &gt;&gt; is that an accident? Is that why do you
[01:01:08] think it's is that is that like unique?
[01:01:11] Is there some reason why a lot of your
[01:01:12] work
[01:01:15] &gt;&gt; I think a lot of database work is very
[01:01:17] app like it's very applicationsoriented
[01:01:20] like work in data research data systems
[01:01:22] research is all about like building
[01:01:24] systems that people can use for their
[01:01:26] data oriented tasks and like as you can
[01:01:28] see it's a trillion dollar industry so I
[01:01:31] think it's hard to like decouple the
[01:01:34] research from like having impact like or
[01:01:36] like being able to see it in a product I
[01:01:38] think what's like a double double whammy
[01:01:40] on my work that probably feels this way
[01:01:43] is like I'm also interested in HCI
[01:01:47] and a lot of HCI work is like having
[01:01:48] and a lot of HCI work is like having
[01:01:50] good product sense right how do you
[01:01:53] build better experiences for users and I
[01:01:54] think I'm more interested in the
[01:01:56] academic side of things around like what
[01:01:58] are the novel interface paradigms and
[01:02:01] the novel ways that AI and humans have
[01:02:04] to communicate and sure that's also very
[01:02:07] product friendly but I think it doesn't
[01:02:08] doesn't mean I personally am interested
[01:02:11] in all products and product development
[01:02:15] as a field. Um I don't I don't know if
[01:02:17] that answered your question of
[01:02:18] &gt;&gt; no
[01:02:21] &gt;&gt; I I appreciate the skills. I recognize
[01:02:23] that product development is a very
[01:02:25] important thing. I try to use good
[01:02:28] product mind all the time but I feel
[01:02:31] like I'm an academic at heart.
[01:02:34] that um on that point of kind of being
[01:02:36] academic at heart. So you're currently
[01:02:40] on like the CS faculty job market. So
[01:02:42] what kind of research program do you
[01:02:45] want to build that m maybe not maybe
[01:02:47] doesn't exist anywhere yet?
[01:02:51] &gt;&gt; Yeah, I really love working in like
[01:02:52] &gt;&gt; Yeah, I really love working in like
[01:02:54] grounded applications. So I think as you
[01:02:56] can see in my docl work like I build
[01:02:59] systems that people use and then I learn
[01:03:00] about things and then those become
[01:03:03] research papers. So I definitely want to
[01:03:05] like continue that way of doing
[01:03:06] research. I want to have an
[01:03:08] interdisciplinary lab. I want to do data
[01:03:09] systems work. I want to do HCI work. I
[01:03:12] want to do AI work and more. I imagine I
[01:03:14] will broaden hopefully will live a long
[01:03:18] life in career as a CS researcher. Um,
[01:03:20] but more concretely like in the
[01:03:21] short-term future, I I really want to
[01:03:24] see this unstructured data thing happen.
[01:03:26] Yeah. I just I feel like the road map is
[01:03:28] there and we just kind of got to build
[01:03:30] it.
[01:03:31] Well, I don't know how we're going to
[01:03:34] build it, but we got to build.
[01:03:36] From my perspective, this data
[01:03:39] processing,
[01:03:41] not even at scale, like data processing
[01:03:45] in general is is really is really an
[01:03:48] important problem. And I I don't hear
[01:03:52] about it as often as chat bots.
[01:03:53] &gt;&gt; Do you have an intuition like why that
[01:03:57] might be? because I feel like there is a
[01:04:00] sort of like what is out there let's say
[01:04:03] in terms of education and
[01:04:07] even yeah really like education around
[01:04:09] AI feels like it centers on a lot of
[01:04:12] like the chatbot kind of use case but
[01:04:14] when I work with companies seems like
[01:04:16] more there's like a lot more work in
[01:04:18] this data processing and like not as
[01:04:21] much as chatbot so it feels like flipped
[01:04:22] &gt;&gt; what why do you think that is yeah
[01:04:24] &gt;&gt; also the data management community is
[01:04:27] actually extremely small compared to
[01:04:29] other CS communities like the AI
[01:04:32] community is far larger and I think
[01:04:34] there there's still a startup culture
[01:04:36] for sure in data management but there's
[01:04:38] just fewer startups
[01:04:41] so I think that the the size thing is we
[01:04:44] can't we try to do our best we try to
[01:04:46] spread the gospel of data systems but
[01:04:49] but there's only so few of us I think
[01:04:50] looking forward I'm also very excited to
[01:04:52] do more of this kind of outreach and
[01:04:55] tell more people about docket and kind
[01:04:57] of the way of DOTTL thinking once I get
[01:04:59] a job kind of building new education
[01:05:03] around that. How to think in this way of
[01:05:05] like building scalable semantic data
[01:05:11] &gt;&gt; This is kind of a spicy question. It
[01:05:13] doesn't have to be like I say the
[01:05:15] perfect answer but okay if you could
[01:05:18] force every forcing is if you could what
[01:05:21] is one paper you would recommend
[01:05:23] reading that is not your own like
[01:05:26] whatever comes what comes to your mind
[01:05:28] that you think is maybe underrated
[01:05:30] &gt;&gt; so recently
[01:05:33] I don't read enough AI papers I should
[01:05:35] read more I've been reading a little bit
[01:05:38] about like these deepseek tech reports I
[01:05:40] find them very interesting specifically
[01:05:43] like tricks that they do to I don't know
[01:05:46] train their ML models, their LLMs.
[01:05:48] Another set of papers that I find
[01:05:51] interesting is just like how to do like
[01:05:54] RL training for agents that are
[01:05:55] specifically trying to do like
[01:05:57] retrieval. I think the closest thing to
[01:05:59] this kind of batch data processing that
[01:06:01] I see in the AI community is retrieval.
[01:06:02] It's a little bit different. The type of
[01:06:04] query is different like it's inherently
[01:06:06] like a semantic filter. it's just a
[01:06:08] semantic filter like we also think about
[01:06:11] other operations semantic operations but
[01:06:13] I find those papers interesting from an
[01:06:16] HCI perspective I think there there's a
[01:06:17] lot of work out there but I'm excited
[01:06:19] about some of this like human and AI
[01:06:23] collaboration work so specifically what
[01:06:26] are better methods or ways to benchmark
[01:06:29] how well AI collaborates with humans a
[01:06:30] how well AI collaborates with humans a
[01:06:31] lot of those are preprints so take them
[01:06:33] all with a grain of salt I try not to
[01:06:35] read into a paper too much until like
[01:06:38] it's been accepted to publication.
[01:06:40] Trying to think what else. My colleague
[01:06:43] and collaborator JD Sam Frescu Pereira
[01:06:47] has some great papers on kind of how end
[01:06:49] users interact with AI. There's like a
[01:06:51] paper he wrote called Why Johnny can
[01:06:55] prompt which is really fun um that I
[01:06:57] also recommend people read just to like
[01:07:01] get a taste of what are how are you
[01:07:02] going to end up bridging this gulf of
[01:07:05] specification? God knows. No, that
[01:07:08] that's that's really interesting. So the
[01:07:10] question has come up. So you're a data
[01:07:12] systems person and so I think this
[01:07:14] question is really relevant to you. So
[01:07:17] it always comes up in almost every
[01:07:19] conversation I have about AI.
[01:07:22] People love the idea of a graph database
[01:07:25] of like hey like can I use a knowledge
[01:07:27] graph?
[01:07:30] Now can you expand like what are your I
[01:07:31] get those questions a lot and like can
[01:07:34] you comment on like okay
[01:07:35] How do you like whether you should reach
[01:07:36] How do you like whether you should reach
[01:07:37] for these tools or not and what do you
[01:07:40] how do you think about it?
[01:07:42] &gt;&gt; Yeah, I think it's very often
[01:07:44] misleading. I think there are some cases
[01:07:46] where know there are very few cases
[01:07:50] where graph databases make sense to use.
[01:07:53] Um but I see more often that people use
[01:07:57] them and make their lives harder. And
[01:07:59] for most docket workloads, actually
[01:08:01] think of them as ETL style workloads. I
[01:08:03] have lots of data. I'm going to
[01:08:05] transform all of that data in some way
[01:08:09] and get some output of some shape. Like
[01:08:12] that shape is not always a graph. And
[01:08:15] often when it is a graph, I always ask,
[01:08:17] okay, why do you want a graph? Like what
[01:08:20] are you going to use that for? And
[01:08:22] people actually are like, oh, that's a
[01:08:24] good point. Like I just actually just
[01:08:27] wanted like entities extracted and I
[01:08:30] wanted summaries of the entities or I
[01:08:31] wanted groups of the entities. I didn't
[01:08:33] like necessarily need it to be
[01:08:35] represented as like all pairs of edges
[01:08:37] between all entities. Like that's not
[01:08:39] what I was looking for. I wanted to
[01:08:41] group by on like a particular attribute.
[01:08:44] And so I think okay like maybe graph is
[01:08:46] not the setting for you because when you
[01:08:48] use something like a graph database then
[01:08:50] like for any downstream task you want
[01:08:51] you have to figure out how to wrangle
[01:08:53] that into the shape that you want and
[01:08:55] that will maybe use something like
[01:08:57] docket. So you spend all this time
[01:08:59] putting something into graph database
[01:09:01] only to take it out to like
[01:09:03] run a tool like docu I don't know. Yeah.
[01:09:04] run a tool like docu I don't know. Yeah.
[01:09:05] So my advice is always like really think
[01:09:06] deeply about what you're going to use
[01:09:07] the graph for.
[01:09:09] &gt;&gt; There are some very specific let's say
[01:09:11] technical questions. So there's a
[01:09:13] question okay how do you handle multihop
[01:09:15] reasoning across multiple pages of a
[01:09:17] document.
[01:09:18] It was hard to figure out what is the
[01:09:21] right chunk size in our experience
[01:09:23] dealing with large contracts
[01:09:24] &gt;&gt; where the data might be very different
[01:09:26] in different parts of the document.
[01:09:29] &gt;&gt; Um how do you how do you tackle that
[01:09:30] kind of problem? Yeah, it's a good
[01:09:33] question. So, our optimizer searches
[01:09:35] over different chunk sizes and then
[01:09:37] tries to pick the chunk size that has
[01:09:40] the highest accuracy. The other things
[01:09:42] is like we have that gather operator
[01:09:44] that augments each chunk with context
[01:09:47] needed to make sense of that chunk. So
[01:09:50] to solve this like multihop problem like
[01:09:52] think about we have an LM scanning each
[01:09:56] chunk to do the task on it. All you have
[01:09:58] to do is kind of like retrieve what
[01:09:59] information is necessary to make sense
[01:10:02] of that chunk. So it's kind of a reverse
[01:10:03] of the multih hot problem incident.
[01:10:04] of the multih hot problem incident.
[01:10:09] You're not you're not going from like oh
[01:10:10] question and like I have to pick the
[01:10:14] right set of chunks for the answer. It's
[01:10:16] like I'm actually looking at every chunk
[01:10:19] in my data and
[01:10:21] then I'm going to run an LLM over each
[01:10:23] chunk to give me an answer and then
[01:10:25] aggregate those at the end to somehow
[01:10:28] give me so multihop I guess is that that
[01:10:30] pattern is like inherently captured in
[01:10:33] these like split map reduce um
[01:10:35] directives. Okay, because the reduce can
[01:10:38] see across multiple documents
[01:10:40] and just to make sure people can follow
[01:10:42] along like when we say accuracy and
[01:10:45] things like that we are
[01:10:47] very much saying that like people are
[01:10:49] labeling they're looking at their data
[01:10:52] doing some labeling you even presented I
[01:10:55] think some workflows in the doc wrangler
[01:10:57] interface that like allows this is that
[01:10:59] a correct understanding or
[01:11:00] a correct understanding or
[01:11:03] &gt;&gt; yeah so we in our optimizer users
[01:11:05] specify like an accuracy function to run
[01:11:07] on their sample. So they can label like
[01:11:11] a sample of 10 documents or whatever. Um
[01:11:13] or I think 40 is what we used in our
[01:11:15] experiments. In an early version of the
[01:11:18] optimizer, we actually use LLM judges to
[01:11:22] basically take plan outputs and rank
[01:11:26] them. Um the LLM judges are okay. I
[01:11:28] don't love LLM judges. I think like
[01:11:29] they're the best solution that we have
[01:11:30] they're the best solution that we have
[01:11:32] when we don't have labeled data. But
[01:11:33] it's definitely interesting work to like
[01:11:34] figure out how to connect like some of
[01:11:37] the e eval labeling kind of into like an
[01:11:40] interactive query optimizer. I think
[01:11:42] like that I would love someone's
[01:11:43] interested in working on that. Yeah,
[01:11:45] feel free to reach out.
[01:11:47] &gt;&gt; This question has come up three times
[01:11:49] already. So this one is good. Is there
[01:11:50] already. So this one is good. Is there
[01:11:52] any reason this wouldn't work to on
[01:11:53] multimodal data? Is there any
[01:11:56] complications or anything? Have you
[01:11:59] tried that? Yeah. So the systems at
[01:12:03] Stanford and MIT, Polyest and Lotus,
[01:12:05] those actually do semantic oper
[01:12:08] operators on multimodal data. I I just
[01:12:10] feel like we've focused on text because
[01:12:13] there's like so much immediate workloads
[01:12:15] in text that I've seen and a lot of
[01:12:18] problems to solve. So in the future, we
[01:12:21] definitely hope to look into images and
[01:12:24] um yeah, video, audio, and so forth.
[01:12:26] Yeah, I don't know what's I'm sure you
[01:12:28] can just like convert that to text or
[01:12:30] descriptions and like run semantic
[01:12:32] operators for text. I don't know what's
[01:12:33] going to be new and interesting about
[01:12:35] the other operators. So, I'm excited to
[01:12:36] find that out.
[01:12:39] &gt;&gt; Is there any reason we couldn't overload
[01:12:43] or create our own operators within the
[01:12:44] docket?
[01:12:45] &gt;&gt; Yeah. Yeah, you could definitely try to
[01:12:47] do like a image map operator. I I just
[01:12:49] simply don't know like what errors
[01:12:51] people are going to run into on real
[01:12:53] workloads. Like first of all like I I
[01:12:54] don't know what the queries are going to
[01:12:55] look like. Like what does it mean to
[01:12:56] look like. Like what does it mean to
[01:12:59] join images with
[01:13:02] text? Like okay why do people want to do
[01:13:04] that? Like maybe to do some sort of
[01:13:06] labeling on the images. Yeah. I would
[01:13:08] just want to probe into the workloads a
[01:13:11] little bit more before we learn more.
[01:13:13] &gt;&gt; Makes sense. There's a question about
[01:13:17] task cascade and the question was how is
[01:13:19] the confidence assessed to determine
[01:13:21] which path to take.
[01:13:24] &gt;&gt; So we use log probabilities and there
[01:13:26] are ways to convert log probabilities to
[01:13:29] like a probabilistic confidence score.
[01:13:31] You should read the paper to figure that
[01:13:35] out specifically. Um but yeah
[01:13:37] &gt;&gt; and if I recall correctly you have the
[01:13:40] log probabilities and then you kind of
[01:13:43] tune it you compare that to hand labels
[01:13:45] and figure out where you want to set the
[01:13:46] threshold and things like that.
[01:13:48] &gt;&gt; We compare that to the Oracle plan. So
[01:13:50] all of this is accuracy with respect to
[01:13:52] some other like powerful LLM oracle
[01:13:56] plan. So we compare those
[01:13:58] &gt;&gt; proxy labels to the oracle labels and
[01:14:00] then yeah we iterate through thresholds
[01:14:02] and figure out which threshold gives us
[01:14:07] &gt;&gt; Okay. Um
[01:14:09] &gt;&gt; thanks everyone. This was really great
[01:14:11] for me to get a chance to practice the
[01:14:13] content. So thank you.
[01:14:14] &gt;&gt; It was good.
[01:14:15] &gt;&gt; That was great.