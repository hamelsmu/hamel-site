# Reasoning Opens up New Retrieval Frontiers


## Introduction to New Frontiers in Information Retrieval

[00:00:00] 

[00:00:00] **Orion Weller:** Today, I'll be talking about new frontiers in retrieval or information retrieval ir, about instruction following and reasoning. If you are using language models today, like you're [00:00:10] talking the chat, GPT there's a couple things that have been huge for defining them and helping them be really useful for users. 


## The Power of Instruction Following in Language Models

[00:00:18] **Orion Weller:** Two of the biggest ones I think [00:00:20] are instruction following. and if you've used a language model before, you can, it does all sorts of things. You can just tell it what you want and it will go out and do it. So here I ask [00:00:30] chat, GBT to generate a haiku about information retrieval in the style of a pirate and to mention rag. And it can follow my instructions perfectly.

So here's this nice little haiku. [00:00:40] It mentions rag, it talks like a pirate. And this actually I feel like may be underwhelming to us today because we just expect them to do this, right? They're [00:00:50] so good at instruction following, you can just tell a language model what you want, and it'll give you what you want. But a few years ago, this was not the case. 


## Advancements in Reasoning Capabilities

[00:00:58] **Orion Weller:** The other is reasoning, and this is something [00:01:00] that's really hot in the community today. Pretty much any major player in language model space will have some reasoning model. And what sets these apart is that when you [00:01:10] ask it a question or type something in, it's going to give these thinking tokens. So here's one from Opening Eyes oh one, and here it thinks about how many Rs are in the word [00:01:20] strawberry.

It'll generate these sort of intermediate tokens. And then finally it'll end by telling you the final output after it thinks. so this is known as [00:01:30] reasoning, thinking, sometimes test time, compute all these sorts of things. And so reasoning and instruction following are two of the most major things that are making language [00:01:40] models so useful these days. 


## Challenges and Opportunities in Modern Search Engines

[00:01:41] **Orion Weller:** What I wanna talk about today is how can we use these in retrieval? It's like, how does this relate? have these really amazing language models. How can we bring them [00:01:50] over? If you look at Google in 1999, it looks like this, which is really actually quite similar to how [00:02:00] Google search looks today in 2025, So we have 26 years of development, it's still very much in that you are gonna type words into a [00:02:10] box. It's gonna go out and do some form of matching. Then it's gonna come back and give you your list of websites. We do have nice new things like search GPT [00:02:20] these days. So if you see this, it's a very nice ui. But what happens behind the scenes is it's going to send your query to a search engine. In fact, often like Bing or Google [00:02:30] itself, just normal search, and then it's gonna pass those results back to the language model, which then creates this very nice output. So [00:02:40] search itself really hasn't changed very much. Search, GPT is still using a normal search engine. despite the fact that these days we're using language [00:02:50] models, we're training models even from Llama to be for retrieval, they still work pretty much the same. So we're mostly just adding these [00:03:00] wrappers around the results of search. So what I wanna talk about today is pushing past this. Can we make retrieval use all the capabilities of the language model? How [00:03:10] can we unlock all these capabilities that we see that are going on in language models and bring them into retrieval? Lemme show some examples. 


## From Keyword Matching to Semantic Search

[00:03:23] **Orion Weller:** back in [00:03:20] 1999, they mostly worked on search. This was before semantic search and mostly was just keyword matching, also known as lexical matching. [00:03:30] So you might have a query, like find websites explaining data privacy. You might also have some collection of documents. This could be things like data encryption [00:03:40] standards from nist, a government website, maybe a blog post called The Wolves Outside Your Data. And then another document called digital protection from a think [00:03:50] tank called Clear Law. And so if you were gonna pass these to a search engine from 1999, they used exact keyword search. You're probably going to find the [00:04:00] first two documents, but not the third. And that's because the third one here is like a synonym. It's data and digital privacy and protection. So it wouldn't match exactly. [00:04:10] However, we have come a long way in 25 years. So now we have semantic search, here what we do is we match it in semantic space. So [00:04:20] you're going to go out and you're gonna look for things like paraphrases and in the same similar space there. A good semantic search engine shouldn't find all three of these. [00:04:30] So the next step I think is where we should be going with retrieval and where I feel like this new paradigm will really unlock a lot of great benefits. 


## Instruction-Based Search: A New Paradigm

[00:04:38] **Orion Weller:** Lemme start off by talking about [00:04:40] instruction based search. imagine you have the same query, but you're gonna add, you want a website that uses an extended metaphor to explain. [00:04:50] Here, there should only be one document that's relevant, the one's about wolves outside your data. But note here, you can't do any form of keyword matching to find this document, [00:05:00] right? It's not gonna say the word metaphor. It probably won't even say a synonym of the word metaphor, like allegory or something like that. really have to understand the whole [00:05:10] document itself to be able to do this reasoning, to see that, oh, this is using a metaphor. So this is where I think instruction based search opens up these new categories of retrieval that you couldn't [00:05:20] get before, any sort of meta document reasoning, But just to show how far you could push this I think you could move on. Oh, before I do that it's important to note here that you can't [00:05:30] solve this simply by using language models to reran. if you have a big collection, say a million documents. wanna find one with an extended metaphor. [00:05:40] If you just take the top a hundred or a thousand that could fit in a language model, you may not find them right because you're not gonna be able to keyword match metaphor. [00:05:50] So I think this is really important that we still need these sort of embedding retrieval models to be able to find these because this is not something we could just entirely throw to a language model. There's just so much [00:06:00] out there. So then the next one I think is out there, but I think really demonstrates how far you could push this, right? 


## Prompting-Based Search and Its Potential

[00:06:11] **Orion Weller:** And I'm gonna call this prompting based search or [00:06:10] reasoning based search. Here you could add on things like, I need you to have really high recall, or I'm going to lose my job. And so imagine you were just typing this into Google search, right? You're gonna [00:06:20] type into Google search. I need you to have a really high recall. It's definitely going to try to look for the word recall, It's gonna try to keyword match that. again, we want [00:06:30] the model, which is a language model, to understand the whole intent of the query and be able to go out and find it.

And this time it'll think, oh, I need to have really good recall. I need to like, [00:06:40] be really careful here and hopefully it does better. Some areas I think it could help the neuro like document attributes. So these days we pre-process things. You add attributes like date, length, [00:06:50] source, all these sorts of things we have to manually add to documents. But an instruction based retriever should just be able to look at it and know, because it understands these things.

[00:07:00] And so you don't have to do this manual pre-processing. Any sort of meta level reasoning, like natural language understanding, sentiment style. You want it a [00:07:10] positive document, you want a document in the style of a pirate, et cetera. I think they often include things that are multiple conditions you want in the style of a [00:07:20] pirate and you want a two page document or something like that.

So you're gonna have these and or not conditions. and many more really. I think if it's confusing to think about [00:07:30] instructions in Google search. I think the easiest thing to think about is that we're so used to prompting language models. Let's just treat our retrievers the exact same way. They use the [00:07:40] same underlying technology, we should be able to use all their capabilities. Okay, cool. 


## Introducing Prom Retriever: An Embedding Model

[00:07:47] **Orion Weller:** So for this talk, I wanna talk about two different models [00:07:50] that kind of show this in two different aspects. One is an embedding model, it's called prom reever. And I think this gets at this sort of fast, quick embeddable, [00:08:00] understand the whole meaning of what you're saying. second is a more recent work called Rank One. And this uses a thinking reasoning language model that we train to be specific for search [00:08:10] and to be fast. Although it's still much slower than of course an embedding model. So yeah, lemme talk about pro retriever. This was a work done [00:08:20] with Samaya AI and my collaborators at Johns Hopkins. And I wanted to start by briefly talking about these two categories of models. 'cause this is gonna come up a few [00:08:30] times. is this sort of buy encoder dense retriever, creates an embedding. So here you pass the text through the language model separately, like your query and document. [00:08:40] They're both gonna create an embedding. at inference time, you're gonna do some sort of quick dot product or cosign similarity to get your final score. So these are very scalable. [00:08:50] They're very fast, but they're not quite as expressive. On the other hand, we have these cross encoders. Sometimes we call them re rankers. It's basically just a language model that you [00:09:00] give your query and document to at the same time, and that's gonna output some score. Again very powerful, but it's much slower compared to these buying coders. [00:09:10] And so for this work, what we wanted to do was, can we make these buying coders, these inventors take instructions? Can we make them profitable? Can we make them reason and [00:09:20] follow instructions? The key intuition that we did in this. The only thing that makes us different, there's really only one thing that we added training [00:09:30] data for instruction following, and this is perhaps naive. You might think, oh, has no one really thought of that before. But it turns out that if you look at current [00:09:40] retrieval training data, it's pretty much things like bing search logs.

So people are taking bing search logs in a dataset called Ms. Marco, then you fine tune on that. [00:09:50] Bing doesn't take instructions, so no one is typing instructions into Bing. So we never learned this sort of capability. So what we did here is we created this [00:10:00] instruction training data so that you can take existing models that follow instructions like Llama and keep that instruction following ability. I'm not gonna talk really much about the [00:10:10] data. What we ended up doing is we had to synthetically generate it. So we took this query and positive document, passed it through a language model, and it generated this [00:10:20] instruction. And so we had to do this synthetically because there's really not any existing data for it. But these days it's not actually terribly hard to develop this sort of data. If you're interested, there's a [00:10:30] paper, the data's also open source, et cetera. But yeah, let me show you how this does. So to make this really simple for the community, we started from a [00:10:40] model called Rep Lama, trains llama for embeddings. And so if you're familiar with the mechanics of language models, what we actually did is, [00:10:50] Rep Lama does is they take the EOS token or the last token in the sequence and they fine tune the model to create a good sentence representation from that ES token. [00:11:00] We are going to use this same recipe that they did the same model everything for a direct comparison. We're going to just add these instructions 'cause we wanna see how these [00:11:10] instructions help. We're gonna evaluate on a lot of different types of data with instructions, data without instructions. And let me show you actually a few examples because I think that helps understand what the [00:11:20] problem is. 


## Evaluating Instruction Following in Retrieval Models

[00:11:22] **Orion Weller:** The first one's called Follower. And this is a data set that tests. If you're like a user, you type into Google, you then change your mind, make a [00:11:30] change to Google you type it in. Again, it should update the search results to be closer to what you want in that new instruction. here you can see in this theory about Teflon, [00:11:40] they have this instruction they typed in. It used to be can be of any means, but they updated it and now it has to be related to chemicals. So if your retrieval model can follow [00:11:50] instructions, it should have more stuff related to these chemicals and less of being at a by means. And you can see this range from not following the instructions, doing the opposite negative a hundred [00:12:00] to a hundred, where it follows instructions perfectly to zero, where it just gives you the same results. And up to this point, no buying coder embedding model scored above zero. They [00:12:10] were pretty much all negative. They do the opposite of what you want. There's also this other really cool data set called instructor. They have these different personas that they apply to the [00:12:20] query. I'm a student, my teacher wants me to look this up, et cetera.

To see if you can handle these different personas. So how does this model [00:12:30] do, I'm not gonna go too deep into results, but let me just share with you highlights here. So again, we're comparing to rep Lama and. Rep Lama gets a negative score for instruction following pretty much [00:12:40] like every other, embedding, following embedding previously, prom tre for the first time gets this positive score, though we can see for the first time that embedding models really can follow [00:12:50] instructions here. On the instructor benchmark, we see again, it's much better than the rep lama model that couldn't that wasn't trained with instructions. Let me show you the more interesting stuff. [00:13:00] What if you don't have instructions? What if you are applying your new model? You have some new customers, you want to be able to use this sort of instruction, but you don't really [00:13:10] know what to put there. So you could just use no prompt, like any existing retrieval model. That's a great option. other option might be you come up with these like generic [00:13:20] prompts and maybe you even optimize.

If you have some small dev set, you're gonna choose the best one there and apply it to your test set. Let me show you what we did when we came up with [00:13:30] these 10 prompts. Here are the actual prompts that we gave to the model. be careful when assigning relevance as your job is on the line. Think carefully about these conditions when determining relevance. [00:13:40] And so again, so we take any user query, we're gonna add this little prompt at the end. and if the model understands instructions, it should be like, oh, this is like really important for the user. I need to [00:13:50] give them a good result. And performance will go up. If the model's just trying to match a keyword performance will stay the same or get worse. And so it turns out if we do this on this [00:14:00] benchmark called beer, which Nandan talked about last time, you have no prompt, models perform about the same, which is a good sign, right? Like you wanna be able to perform well in [00:14:10] both settings. If you add this sort of generic prompt, we see, we get this nice gain. And rep lama that was trained without instructions. Doesn't see any benefit. In fact, it gets [00:14:20] slightly worse, right? So you can literally just tell the model what you want. You can say you really need it to do well, 

And now performance can go up. this may sound weird, but this [00:14:30] is the easiest way to show that this aligns retrieval models with the language model community, right? Because you can prompt hack language models, you can tell them all sorts of things. Now you can do the same thing [00:14:40] to retrieval models. And that means they can also understand what you mean, if you took these prompts and you paraphrase them, they should be able to do equally well, right? [00:14:50] 'cause it's still the same semantic meaning. And it turns out that if you take a keyword model like BM 25, of course you're gonna have this really large range because it's really sensitive [00:15:00] to keywords. Rep Lama is less sensitive to the keywords and prom retriever, which is trained to follow instructions, is much less sensitive. So these sorts of models understand the whole [00:15:10] meaning of what you're saying rather than trying to pick out keywords or trying to match to something in like a paraphrase like way. with the right data, you can have retrievers that are prompted just [00:15:20] like a language model. having the sort of right data enables these sorts of capabilities because they're already there in the language model.

You just have to keep them. And what's most exciting to me about [00:15:30] this is it unlocks these new types of queries. You can ask for these meta level reasoning type things on top of documents that you just couldn't ask before. Like you just couldn't ask Google [00:15:40] about metaphors because it's gonna try to keyword match it.

But now you have these sorts of systems that can do it. And you don't need to be picky about the keywords. So you don't need to [00:15:50] like try to help your users say the right things. You can just tell it what you want and the model will understand. And so that's pro. It's a fast [00:16:00] embedding model, and I think it's the way that embeddings are gonna go in the future. 


## Rank One: A Reasoning-Based Retrieval Model

[00:16:04] **Orion Weller:** The next one I wanted to talk about is rank one. And so this is the model that's very strong, [00:16:10] but it's slower because it's, as I've talked about before across encoder here on the right. So it takes in the text together, which means that it's gonna be slower [00:16:20] than these embedding models. So this is the type of thinking models. what the language model community really loves about these is that as you increase the amount of tokens, the amount [00:16:30] of words it does in its thinking performance goes up. So here's oh one on a math data set, and as you increase the compute performance on this math data set goes from 20 to [00:16:40] 80. So they've really shown that these models provide a lot of huge gains to, on these hard tasks like code or science or other sorts of math questions. [00:16:50] And so we wanna bring those same gains to retrieval. I think if you're not so familiar with these sort of thinking models, one way to think about this is it's like a [00:17:00] long chain of thought and it's pretty much used in every model these days.

Gemini, oh, one deep seek, they all use this sort of thing. Yeah. How would this [00:17:10] even look like in retrieval? So say you have a query and a document, do snow leopards change color? Your model is gonna output something like this. [00:17:20] it's actually quite long, right? It's long to read. Luckily, you don't actually have to read it. It can be given to a different language model. You can just take the final output. Or if you're really curious, you can read it. [00:17:30] so here, it thinks about whether. Leopards change colors. It even questions itself. You're in blue, but wait, like maybe the user says this and they mean something different. And then [00:17:40] finally at the end it's gonna tell you, oh, I actually don't think this document's relevant. It's false. we want this to be fast and personalized for retrieval. we have the [00:17:50] procedure in the paper. Again, it's actually quite simple.

It's all about the data. So you get some data that can teach the model. To do this, you don't even need to do any fancy reinforcement learning. It's pretty [00:18:00] basic training. But let me show you the type of evaluation data and the type of things this can do. And so this is gonna mainly focus on the bride data set, What they did is [00:18:10] they have all these very unique relevance definitions. So instead of just having relevance be, does this answer my question, It has all these different ones, here at the bottom we have [00:18:20] math. So it has a math question and you actually wanna find a different problem that uses the same theorem to solve it. So it's not trying to find the answer, it's trying to find a different [00:18:30] question that uses the same theorem. Maybe you have code and you wanna find a different document that uses an alternate function. Or at this top one, you wanna find some [00:18:40] supporting evidence. So it uses all these very cool, unique ways of relevance to test if your model can do this reasoning and think through this definition of [00:18:50] relevance. So lemme, I threw an example into our model to show you. And so this was about could you find a similar lead code problem? I gave it the input and you can see [00:19:00] highlighted in red here that the model says, oh, this is a, this is the max area problem, and it uses a two pointer approach to solve it. this other problem that you're giving me as a document [00:19:10] also uses a two pointer technique. So therefore, you know they are relevant to each other. They are similar. These models are really able to think about what you're doing to be [00:19:20] very instructable to do this reasoning and give you your final output. It's actually very impressive to me because I personally can't just look at some of these things and be like, oh, like that's a two pointer problem, and tell you off the top [00:19:30] of your head, but these models can, and so they're able to unlock that. Yeah. Let me briefly show you some results here. We evaluate on a bunch of [00:19:40] things bright, the one I just showed you, a negation benchmark called never and a multilingual version of the follower benchmark I showed you before. This model I'm using as a baseline [00:19:50] was trained on 10 times more data, 6 million instead of 600,000. But yet adding this thinking goes from 14 to 27, so almost double [00:20:00] on bright, which is huge negation, understanding more than double. Then on instruction following, again, more than double. So we were blown away actually when we [00:20:10] saw this because it was just so much more effective. so I thought maybe like the data, like our data is just so much better. So we tested it with the same model, same data, but [00:20:20] with or without thinking. So without this reasoning chain during training. And it turns out that you see this 10 point gain simply from having the thinking. So training it to think is [00:20:30] like hugely effective. Let me just end by telling one fun story about this.

So there's some old evaluation data that people use in retrieval. [00:20:40] It's called DL 19 from the Trek Treks. And it was created in 2019. initially when we evaluated, we were surprised to see some really low [00:20:50] scores. when we dug into why that could be we realized that the documents that we're finding had not been judged by humans. what that means is when IR researchers, [00:21:00] create these new evaluation sets. They take existing models, go out and find a bunch of documents, and then have humans go and annotate those documents, relevant or not, [00:21:10] until they run outta money there's just too many documents for a human to go through all of them.

So you take a top set and you have a human annotate it. And it turned out that the [00:21:20] documents these previous models were finding had pretty much all been seen by those humans from the old systems Our model had a lot less of these judged documents. [00:21:30] So what we did to make this fair is we personally went through and every document that had never been judged by human, we went through and judged. What I love about this story actually is [00:21:40] that these thinking retrieval models are actually finding new documents that previous systems hadn't found before. Which is really exciting to me because it means that it has this new, fresh [00:21:50] perspective.

And it also probably indicates that the community should move on from these older data sets which I think everyone agrees with. There's many more ones. This one that we were evaluating on was done before Bert, so [00:22:00] it's very old. I think there's growing consensus that we just shouldn't use it anymore. But yeah, in summary, using this test time compute, this thinking makes these [00:22:10] profitable and reasoning re rankers, you don't need any rl. It's actually really simple to create these. are slower, but they're much, much more powerful than previous approaches. [00:22:20] as just one example, we only trained on general web data. We didn't train on instruction data. We didn't train on multilingual data on any specific domains. So if you do [00:22:30] that, you're gonna see some like huge gains. Yeah. And so that's Frank one. 


## Conclusion: The Future of Retrieval Models

[00:22:38] **Orion Weller:** Let me just conclude by headed back to what I started with.

[00:22:40] So the goal is we want to have retrieval models that work just like language models, that we build our retrieval models these days on language models. They should have all of their [00:22:50] capabilities. They should understand what you mean. They should be able to reason, they should be able to follow your instructions. And so what does this actually mean for you if you're a downstream user? If you have some [00:23:00] new application, you wanna have some new users on a new dataset, a new area? What it means is that these new retrievers benefit from advances in language models. So the next time you [00:23:10] see some really cool thing coming out from language model community it should be easily accessible to you for search, for rag, for whatever you're doing.

It should be easily brought in. [00:23:20] And then the part I'm most excited about is all these new types of queries you can now give for rag and retrieval. You can just type anything you want in and it'll be able to go find it, [00:23:30] give it back to you. You don't need to try to keyword match. The language model will take care of it. And so I just wanna end by saying that all of these models are open data. They're open [00:23:40] source. You can train them yourself, their MIT license. So feel free to use them for whatever. Thanks. 


## Q&A Session

[00:23:45] **Hamel Husain:** So just to make sure I understand, like when you were talking about prompt retriever, [00:23:50] I believe I recall you mentioned that you applied that to the buy encoder. It's a, is that, did I recall correctly?


## Question 1: How are these special embeddings operationalized? 

[00:23:58] **Orion Weller:** Yeah, exactly.

[00:23:58] **Hamel Husain:** Okay.

[00:23:59] **Orion Weller:** Embeddings.

[00:23:59] **Hamel Husain:** [00:24:00] And if I understand correctly, If you provide instructions on, how you wanna search, like you have that meta kind of instruction it changes the kind of [00:24:10] embedding that will be produced by the buy encoder. Is that the right understanding?

[00:24:16] **Orion Weller:** Exactly. So you could give the query and the instruction as like one piece of [00:24:20] text and then it creates that single embedding. 

[00:24:22] **Hamel Husain:** Okay. so we have the buy coder. First question is, how do you. So like a lot of times with [00:24:30] Rag, you use a buy encoder and you like, you batch process a lot of your documents and you put them through, the buy encoder, you store the vectors of your [00:24:40] documents so that at inference time you can do that first pass with the buy encoder before you go to the cross encoder for the re-ranking.

How do you imagine like this would be [00:24:50] operationalized, let's say. Like on inference time 'cause I imagine like your queries, this meta instruction, is it the, is what's the idea? [00:25:00] Is it the idea that this meta instruction would be constant when you're doing the kind of this like batch processing to store your documents in the vector [00:25:10] database?

Or is there some other trick where, you know, you would. So like how do you actually operationalize this more fine-grained thing?

[00:25:19] **Orion Weller:** the way [00:25:20] that we set it up is that the documents don't get the instruction so you can. Batch process your documents just like you would any other retriever. And then at inference time, when you get a query [00:25:30] depending on your use case, you can either have the user type in a long query that can be its own instruction, or you can have some instruction in the backend that you append to that query. [00:25:40] And then it just creates that embedding. And you do the dot product with all the documents, Maybe the user has a specific instruction, so you wanna keep your documents instruction. They're not influenced by the [00:25:50] instruction. They're just separate in the date of soar. And then at inference time, the query gets the instruction and you do the DOT product.

[00:25:56] **Hamel Husain:** okay, so the instruction is applied only to the query in a way. the [00:26:00] way it's trained is like I. That's really interesting. And thenyou mentioned the buy encoder. Why not also, make this part of the cross encoder just outta curiosity. [00:26:10] Maybe there's a reason, but just wanted to ask.

[00:26:12] **Orion Weller:** Yeah. great question. We actually do have some work doing that. I just didn't choose to highlight it in this talk, but yeah, you totally can. 

[00:26:17] **Hamel Husain:** Sense. 

[00:26:18] **Orion Weller:** Yeah. I can also highlight, no, it's [00:26:20] actually already even out with all the data. It's part of the paper follow ir. It also has a benchmark, which we evaluated on this paper, but yeah it's all out there as well. So yeah, feel free to check that if you're interested [00:26:30] in a re ranker that can do that.

[00:26:32] **Hamel Husain:** The next question I have is this meta search kind of instruction is extremely interesting, like you're [00:26:40] giving. What are some nuances about the search that you should be if you're, you are like searching for it as like an expert, what do you think is gonna happen?

Do you think it's gonna be [00:26:50] humans will provide that full thing or do you think LMS will be. Writing it for you, the meta or like what is your feeling, like that [00:27:00] might happen. What's your like, 'cause you've been like working with this for some time.

[00:27:05] **Orion Weller:** Yeah. I think it depends on the application, but I think both are really actually exciting and interesting [00:27:10] areas. Say you have a deep research system and you're trying to go through it. I think having the deep research system know that it can add all these sorts of really precise [00:27:20] things will help it narrow in on exactly what it wants in sort of a rag application. on the other hand, if you're just typing into Google and you're not doing a deep research and you wanna be the power [00:27:30] user I think that's helpful. But I actually do think there's gonna be a ton of people where normal Google search works. But if you're the sort of power user where you really wanna dial in and you wanna find exactly what you [00:27:40] want, and then if the model can take that sort of thing, I think it'll really help them also.

[00:27:45] **Hamel Husain:** That's interesting. You mentioned deep research, like yeah, maybe you would have a UX where it [00:27:50] asks you follow up questions to help you build that meta prompt, to guide you. Okay, so I wanna ask you also about the other one, the more [00:28:00] expensive one. What was it called again?

[00:28:02] **Orion Weller:** Yeah. Rank one.

[00:28:03] **Hamel Husain:** Rank one. Okay. And so if I understand correctly, rank one basically is [00:28:10] like a reasoning model that you've trained to, basically. Be more powerful when it comes to dealing with [00:28:20] context and answering questions related to context. Is that correct 

[00:28:25] **Orion Weller:** Yeah. Finding document relevance. 

[00:28:27] **Hamel Husain:** how does it compare to reasoning models off the [00:28:30] shelf today? Like the frontier ones, let's say like whatever 2.5 Pro oh, three Pro, whatever, if you're going to if you put a prompt into those [00:28:40] reasoning models and say, Hey carefully consider if this document is relevant, blah, blah, blah, whatever.

Have you, do you have any intuition on the baseline against that? How [00:28:50] is this, I think you have trained specifically for this purpose. What is, yeah, what's the delta there? 

[00:28:55] **Orion Weller:** Also, yeah. Super interesting question. So we evaluated on some benchmarks [00:29:00] that O three has been evaluated on, and I think on those O three is like at 75 and our model is like at 69 ish. So there is a gap between the frontier [00:29:10] models there, but our model is again, like seven B. We have a 1.5 B version. And I think the models that we're having are most useful if you want to like, control the sort of data distribution [00:29:20] you're doing or you want it to be faster or something you control. If you are going for peak performance it's gonna be hard to beat open AI there. But ours is much faster in that way and much smaller.[00:29:30] 

[00:29:30] **Hamel Husain:** That's interesting. So perhaps, are you envisioning maybe like this smaller model would be more like in the rag pipeline itself and [00:29:40] you would then hand it off to O three? What is it like, I'm just guessing, but you tell me.

[00:29:45] **Orion Weller:** I think it could be done that way too. I imagine if you're dealing with a lot of queries, right? So I and [00:29:50] O three is really good at this sort of tool use. But I could see this sort of thing like Rank One model is being used as a tool that O three uses.

Hey, go do this. So you slowly build up, you [00:30:00] do your embedding, you do your re-ranking, then O three puts it all together. Or if it's something like you just simply can't use O three, like you have some government application, you have [00:30:10] some secret data, you can't pass to O three these sort of things can be done much cheaper and there you can run it yourself so it's secure in that way.

[00:30:19] **Hamel Husain:** [00:30:20] Gotcha. What's the easiest way for people? Okay. Actually before I get to that, is your intuition that we can use rank one kind of off the shelf for [00:30:30] across many domains. Do you think that people may want to, train it on their data sets? How easy is it to train on your data set? Can you talk about that a little bit?[00:30:40] 

[00:30:40] **Orion Weller:** Yeah, we were actually shocked at how well it worked without the training data for specific domains like it. Actually blew us away how good it generalized. However, I still think that means that if you give it the [00:30:50] data you want, it's just gonna like really kill it. Was honestly so easy to train.

It's just normal. Predict the next token loss. You just give it your data [00:31:00] predicts the next token, and it just. really good. So yeah, I, if you have something that you wanna use it for, I'd recommend just trying it off the shelf. It may just work amazing. If you wanna fine tune it [00:31:10] for your thing, it's also easy and probably would work really well too.

[00:31:13] **Hamel Husain:** Okay, so you're saying like you supervise fine tuning basically, off the shelf for [00:31:20] against your data. Now, why is that the case? If it's a reasoning model, wouldn't you just outta curiosity just to make sure I understand how is it that you're able to try and use the supervised fine tuning and why [00:31:30] not RL something or the other?

[00:31:32] **Orion Weller:** that's one thing that I actually really loved about that project. What did I have in the summary is that you don't need that rl. So I think the Quinn [00:31:40] paper showed a bit of this in that if you have a smaller model, it can learn that distillation from the reasoning chase really easy. that's, I think, the main reason.

I'm speculating here, but it seems [00:31:50] to me to be the main reason why. Open AI doesn't release the reasoning chains. Also, Gemini used to, I started actually gathering some from Gemini to train rank one, and then during [00:32:00] that process they turned it off. I think these companies have realized that it's just so effective to use them training that they've completely turned them off. 

[00:32:09] **Hamel Husain:** [00:32:10] Okay. So where are you getting the reasoning tokens from now that they turned it off? 

[00:32:14] **Orion Weller:** Yeah. Nowadays you have to choose an open source alternative, right? So it's

[00:32:18] **Hamel Husain:** okay.

[00:32:18] **Orion Weller:** gonna have to go to like deep [00:32:20] or something.

[00:32:21] **Hamel Husain:** Okay. And if people wanna fiddle with this and try it for themselves on their applications, what's like a minimal [00:32:30] setup that you recommend people do? Is this easy to wire up and Lance db and something? Is there a recipe that you recommend people look at?

[00:32:39] **Orion Weller:** No [00:32:40] specific constraints on framework. I will say V-L-V-L-L-M is really effective for it. There's actually a demo on hugging face right now for it. You can check it out. It has a GPU. You can test it out for [00:32:50] different queries you have, see how well it does. but otherwise it's just like a normal language model, so any sort of framework that handles language models, VLM works great.

And how can people find that [00:33:00] thing on hugging face? Rank one

[00:33:01] **Hamel Husain:** Okay.

name,

Okay. Got it. Thanks for entertaining my questions. This is very exciting and very interesting [00:33:10] of a presentation, so thank you so much for doing this.

[00:33:13] **Orion Weller:** Thank you so much for the opportunity, for the really great questions.

