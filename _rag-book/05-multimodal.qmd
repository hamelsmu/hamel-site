# RAG with Multiple Representations

*Based on a presentation by Bryan Bischof and Ayush Chaurasia*

[Bryan Bischof](https://www.linkedin.com/in/bryan-bischof/){target="_blank"} and [Ayush Chaurasia](https://www.linkedin.com/in/ayushchaurasia){target="_blank"} argued that effective retrieval lies not in finding a single, perfect data representation, but in creating and leveraging multiple, diverse representations with a router to better serve user intent.

## The Map is Not the Territory

![](../notes/llm/rag/p5-images/slide_1.png)

*([Timestamp: 01:00](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=60s){target="_blank"})*

The presentation's central theme is that a "map" (a data representation) is not the same as the "territory" (the real-world data). In machine learning, this distinction is an advantage. Models and embeddings are our maps, and we can create many different maps of the same territory to serve different purposes.

## Deconstructing RAG Buzzwords

The RAG landscape is filled with terms that can obscure fundamental principles. These terms can be deconstructed into simpler concepts.

![](../notes/llm/rag/p5-images/slide_3.png)

*([Timestamp: 02:37](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=157s){target="_blank"})*

**Naive RAG** is better understood as **Simple RAG**: the foundational approach of searching a vector store with a vector to find similar items.

![](../notes/llm/rag/p5-images/slide_4.png)

*([Timestamp: 04:04](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=244s){target="_blank"})*

**Agentic RAG** involves an LLM choosing *how* to search, giving the impression that the model can remove the engineer from designing the retrieval pipeline.

![](../notes/llm/rag/p5-images/slide_5.png)

*([Timestamp: 04:41](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=281s){target="_blank"})*

**Hybrid RAG** combines Simple RAG with classic retrieval techniques like keyword matching, allowing for searches with multiple signals simultaneously.

![](../notes/llm/rag/p5-images/slide_6.png)

*([Timestamp: 05:05](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=305s){target="_blank"})*

**Graph RAG** uses the relationships *between* objects to improve retrieval, such as identifying stores that sell "home goods" to find a coffee filter, also considering proximity.

![](../notes/llm/rag/p5-images/slide_7.png)

*([Timestamp: 06:06](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=366s){target="_blank"})*

**Multi-Modal RAG** has two meanings: searching with multiple data types (text and images) or searching across multiple locations ("modes") within the same latent space for a single item.

## A First-Principles View of RAG

Advanced RAG techniques can be reframed as core engineering pipelines.

![](../notes/llm/rag/p5-images/slide_10.png)

*([Timestamp: 07:58](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=478s){target="_blank"})*

**Hypothetical Document Embeddings (HyDE)** is a **document enrichment pipeline**. It uses an LLM to rewrite documents into the language that users are likely to search with. A dense, technical document can be rewritten into a simpler description, creating a new, more searchable "map" of the original.

![](../notes/llm/rag/p5-images/slide_11.png)

*([Timestamp: 10:14](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=614s){target="_blank"})*

**Agentic RAG** is a **query enrichment pipeline**. When a query is ambiguous, an agent decides how to search. For example, it determines whether "V60 filter" refers to a product or a restaurant, routing the query to the correct search process.

![](../notes/llm/rag/p5-images/slide_12.png)

*([Timestamp: 11:38](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=698s){target="_blank"})*

**Rank fusion** is **multi-stage processing**. It involves running multiple different searches and then combining, or "stitching," the results together in a subsequent stage.

## The Three Responsibilities of an IR Engineer

These advanced techniques can be derived by focusing on three core responsibilities.

![](../notes/llm/rag/p5-images/slide_14.png)

*([Timestamp: 12:43](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=763s){target="_blank"})*

1.  **Predict user intent:** What is the most likely representation of what the user is looking for?

![](../notes/llm/rag/p5-images/slide_15.png)

*([Timestamp: 13:08](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=788s){target="_blank"})*

2.  **Generate multiple representations (maps):** Create different views of the source data ahead of time (document enrichment).

![](../notes/llm/rag/p5-images/slide_16.png)

*([Timestamp: 13:39](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=819s){target="_blank"})*

3.  **Match intent to representation:** Correctly match the user's query with the appropriate pre-generated representation.

## Practical Application: Curving Space

"Curving space" means shaping data representations and indices to improve search.

![](../notes/llm/rag/p5-images/slide_18.png)

*([Timestamp: 13:58](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=838s){target="_blank"})*

For financial documents, one could create multiple "maps" from a single corpus, such as summaries, tables of data, lists of named entities, and form types. This is document enrichment.

![](../notes/llm/rag/p5-images/slide_19.png)

*([Timestamp: 16:34](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=994s){target="_blank"})*

Once multiple representations exist, the right indexing strategy must be chosen for each. This involves deciding between semantic search, keyword matching, pre-filters, and whether to use a single index or separate ones.

![](../notes/llm/rag/p5-images/slide_20.png)

*([Timestamp: 18:08](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=1088s){target="_blank"})*

Sometimes, a second retrieval step, informed by the first, is required. This is a form of staged processing.

## Agents as Routers

![](../notes/llm/rag/p5-images/slide_22.png)

*([Timestamp: 18:54](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=1134s){target="_blank"})*

Agents are **transformers** in their function: they transform incoming data and instructions into a structured output.

![](../notes/llm/rag/p5-images/slide_23.png)

*([Timestamp: 19:04](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=1144s){target="_blank"})*

An effective way to use agents is as **routers**. They take incoming data and route it to different indices or subsequent retrieval stages. This is the core idea behind both Agentic RAG and Multi-Agent RAG.

## Dynamic Representations

![](../notes/llm/rag/p5-images/slide_25.png)

*([Timestamp: 20:51](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=1251s){target="_blank"})*

A significant danger in RAG is that documents are dynamic. A static embedding will become outdated as the context of a document changes based on new business or world events.

![](../notes/llm/rag/p5-images/slide_26.png)

*([Timestamp: 22:49](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=1369s){target="_blank"})*

The solution is to design a system that can detect what has changed and re-index only those parts, requiring an architecture built for dynamic updates.

## Demo: Semantic Dot Art

*([Timestamp: 23:21](https://youtu.be/hf9B3knU9vc?t=1401s){target="_blank"})*

To make these concepts concrete, Ayush Chaurasia demonstrated `semanticdotart`, an application for discovering artworks. The demo shows how a system can serve diverse user intents by creating and searching over multiple representations of the same underlying data.

![](../notes/llm/rag/p5-images/2025-07-11-21-24-09.png)

A user can search for art using different "maps" of the data. For example, they can search with a literal description ("multiple clocks melting in a desert"), a poetic description, or even a similar image. The system retrieves not only the original artwork but also derivative pieces and other thematically related works. This is made possible by a rich document enrichment pipeline that creates multiple vector and keyword-based indices for each artwork, capturing everything from mood and style to literal object descriptions.

The retrieval process is agentic. The system routes the user's query to the most appropriate index or combination of indices. A poetic query might be routed to an index of artistic descriptions, while an image query would use a multimodal embedding. This dynamic routing, combined with multi-stage processing and rank fusion, allows the system to handle a wide variety of user needs and deliver more satisfying, diverse results.

## System Architecture

![](../notes/llm/rag/p5-images/slide_27.png)

*([Timestamp: 27:26](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=1642s){target="_blank"})*

The "Represent!" diagram visualizes the document enrichment pipeline. Data from various sources is processed to extract different features (poem captions, NL captions, mood keywords, image content). These are embedded into different vector types and stored, creating multiple "maps" for the same territory.

![](../notes/llm/rag/p5-images/slide_28.png)

*([Timestamp: 29:10](https://youtu.be/hf9B3knU9vc?si=KCrVC9MDwJXtq-iK&t=1750s){target="_blank"})*

The "Discover!" diagram shows the retrieval pipeline. User input is routed through various stages where it can be enriched (e.g., mood extraction, query rewriting). These enriched queries are then used in a multi-stage retrieval process involving pre-filtering and hybrid search before final reranking.

## Integration with Other Techniques

The multiple representations approach naturally integrates with other advanced RAG techniques:

**Reasoning Models** are a form of query enrichment, rewriting confusing queries with necessary context.

**Late-interaction models** like ColBERT create diversity *within the model itself* by generating multiple representations (a vector for each token) for a single document. This creates different "modes" in the latent space for more diverse and nuanced search results.

**Routing** is a retrieval stage where you decide which process or index to use based on the query. For a small number of routes, an LLM can act as a simple classifier. As the number of routes grows, a dedicated, trained classifier becomes more appropriate.

## Chapter Principles

The key insights from this approach:

1. **No Single Perfect Map**: Instead of seeking one perfect representation, build multiple specialized representations of your data
2. **Intent-Based Routing**: Use agents or classifiers to route queries to the most appropriate representation
3. **Dynamic Updates**: Design systems that can detect changes and re-index incrementally
4. **Multi-Stage Processing**: Combine results from different representations and processing stages
5. **Domain Specialization**: Create representations tailored to specific types of queries or user intents

This framework provides a principled way to think about advanced RAG techniques as variations on the theme of multiple representations and intelligent routing.



## Video

Here is the full video:

{{< video https://youtu.be/hf9B3knU9vc >}}
