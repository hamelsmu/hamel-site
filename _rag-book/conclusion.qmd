# Conclusion {.unnumbered}

RAG has moved past the simple "embed and search" approach from 2023. The presentations in this book show what that looks like in practice: richer representations, instruction-following retrievers, careful evaluation, and thoughtful infrastructure choices.

## Looking Forward

Rather than compressing all information into a single vector, we're seeing systems that maintain multi-faceted representations, reason about relevance, and combine classical techniques with modern ones.

The tooling is maturing. Libraries like PyLate, frameworks like RAGatouille, and vector databases with advanced retrieval support make these techniques accessible.

## Resources

**Watch the full presentations:**

- [Ben Clavi√©: "I don't use RAG, I just retrieve documents"](https://youtu.be/Evlk9J-B_uc)
- [Nandan Thakur: "Modern IR Evaluation for RAG"](https://youtu.be/Trps2swgeOg)
- [Orion Weller: "Reasoning and Retrieval"](https://youtu.be/YB3b-wPbSH8)
- [Antoine Chaffin: "Late Interaction Models"](https://youtu.be/1x3k0V2IITo)
- [Bryan Bischof & Ayush Chaurasia: "Multiple Representations"](https://youtu.be/hf9B3knU9vc)
- [Kelly Hong: "Context Rot"](https://youtu.be/3s_N60u0jEY)
- [Jo Kristian Bergum: "You Don't Need a Graph DB"](https://maven.com/p/933026/you-don-t-need-a-graph-db)

**Web version**: [hamel.dev/notes/llm/rag/not_dead.html](https://hamel.dev/notes/llm/rag/not_dead.html)

These talks are from our [AI Evals course](https://bit.ly/evals-ai), which covers LLM evaluation techniques beyond RAG. Readers of this book can use [this 25% discount](https://bit.ly/evals-ai).
