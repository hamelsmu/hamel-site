---
title: "An Open Course on LLMs, Led by Practitioners"
description: A free survey course on LLMs, taught by practitioners.
categories: [llms, courses]
css: index.css
author: Hamel Husain
date: 2024-07-29
image: course.png
margin-footer: <br>
---

Today, we are releasing [Mastering LLMs](https://parlance-labs.com/education/), a set of workshops and talks from practitioners on topics like evals, retrieval-augmented-generation (RAG), fine-tuning and more. This course is unique because it is:

- Taught by 25+ industry veterans who are experts in information retrieval, machine learning, recommendation systems, MLOps and data science. We discuss how this prior art can be applied to LLMs to give you a meaningful advantage.
- Focused on applied topics that are relevant to people building AI products.
- <ins>**Free and open to everyone**</ins>.

We have organized and annotated the talks from our popular paid course.[^1] This is a survey course for technical ICs (including engineers and data scientists) who have some experience with LLMs and need guidance on how to improve AI products.

[![_Speakers include Jeremy Howard, Sophia Yang, Simon Willison, JJ Allaire, Wing Lian, Mark Saroufim, Jane Xu, Jason Liu, Emmanuel Ameisen, Hailey Schoelkopf, Johno Whitaker, Zach Mueller, John Berryman, Ben Clavié, Abhishek Thakur, Kyle Corbitt, Ankur Goyal, Freddy Boulton, Jo Bergum, Eugene Yan, Shreya Shankar, Charles Frye, Hamel Husain, Dan Becker and more_](course.png)](https://parlance-labs.com/education/){target="_blank"}

## Getting The Most Value From The Course

### Prerequisites

The course assumes basic familiarity with LLMs. If you do not have any experience, we recommend watching [A Hacker’s Guide to LLMs](https://www.youtube.com/watch?v=jkrNMKz9pWU). We also recommend the tutorial [Instruction Tuning llama2](https://www.philschmid.de/instruction-tune-llama-2) if you are interested in fine-tuning [^2].

### Navigating The Material

The course has over 40 hours of content. To help you navigate this, we provide:

- **Organization by subject area**: evals, RAG, fine-tuning, building applications and prompt engineering.
- **Chapter summaries:** quickly peruse topics in each talk and skip ahead
- **Notes, slides, and resources**: these are resources used in the talk, as well as resources to learn more. Many times we have detailed notes as well!

To get started, [navigate to this page](https://parlance-labs.com/education) and explore topics that interest you. Feel free to skip sections that aren't relevant to you. We've organized the talks within each subject to enhance your learning experience. Be sure to review the chapter summaries, notes, and resources, which are designed to help you focus on the most relevant content and dive deeper when needed. This is a survey course, which means we focus on introducing topics rather than diving deeply into code. To solidify your understanding, we recommend applying what you learn to a personal project.

### What Students Are Saying

Here are some testimonials from students who have taken the course[^4]:

:::{.testimonial-section}
```{python}
#| output: asis
#| echo: false

from idx import generate_testimonials
testimonials = [
  {
    "image": "sanyam.jpeg",
    "name": "Sanyam Bhutani",
    "title": "Partner Engineer @ Meta",
    "quote": "There was a magical time in 2017 when fastai changed the deep learning world. This course does the same by extending very applied knowledge to LLMs Best in class teachers teach you their knowledge with no fluff"
  },
  {
    "image": "laurian.jpeg",
    "name": "Laurian",
    "title": "Full Stack Computational Linguist",
    "quote": "This course was legendary, still is, and the community on Discord is amazing. I've been through these lessons twice and I have to do it again as there are so many nuances you will get once you actually have those problems on your own deployment.!"
  },
  {
    "image": "andre.png",
    "name": "Andre",
    "title": "CTO",
    "quote": "Amazing! An opinionated view of LLMs, from tools to fine-tuning. Excellent speakers, giving some of the best lectures and advice out there! A lot of real-life experiences and tips you can’t find anywhere on the web packed into this amazing course/workshop/conference! Thanks Dan and Hamel for making this happen!"
  },
  {
    "image": "marcus.png",
    "name": "Marcus",
    "title": "Software Engineer",
    "quote": "The Mastering LLMs conference answered several key questions I had about when to fine-tune base models, building evaluation suits and when to use RAG. The sessions provided a valuable overview of the technical challenges and considerations involved in building and deploying custom LLMs."
  },
  {
  "image": "ali.png",
  "name": "Ali",
  "title": "Principal & Founder, SCTY",
  "quote": "The course that became a conference, filled with a lineup of renowned practitioners whose expertise (and contributions to the field) was only exceeded by their generosity of spirit."
  },
  {
  "image": "lukas.png",
  "name": "Lukas",
  "title": "Software Engineer",
  "quote": "The sheer amount of diverse speakers that cover the same topics from different approaches, both praising and/or degrading certain workflows makes this extremely valuable. Especially when a lot of information online, is produced by those, who are building a commercial product behind, naturally is biased towards a fine tune, a RAG, an open source LLM, an open ai LLM etc. It is rather extra ordinary to have a variety of opinions packed like this. Thank you!"
  },
]

# Generate and print the testimonials
print(generate_testimonials(testimonials))
```
<br>

<center>[Course Website](https://parlance-labs.com/education){target="_blank"}</center>

:::

## Stay Connected

I'm continuously learning about LLMs, and enjoy sharing my findings and thoughts. If you're interested in this journey, consider subscribing.

What to expect:

- Occasional emails with my latest insights on LLMs
- Early access to new content
- No spam, just honest thoughts and discoveries

<script async data-uid="6379a28bdb" src="https://hamel.ck.page/6379a28bdb/index.js"></script>


[^1]: https://maven.com/parlance-labs/fine-tuning. We had more than 2,000 students in our first cohort. The students who paid for the original course had early access to the material, office hours, generous compute credits, and a lively Discord community.
[^2]: We find that instruction tuning a model to be a very useful educational experience even if you never intend to fine-tune, because it familiarizes you with topics such as (1) working with open weights models (2) generating synthetic data (3) managing prompts (4) fine-tuning (5) and generating predictions.
[^3]: Eventually, tools become so good that they encapsulate good processes. However, this is often not true for nascent or emerging technologies. 
[^4]: These testimonials are taken from https://maven.com/parlance-labs/fine-tuning.
