---
title: "Q: How many people should annotate my LLM outputs?"
categories: [LLMs, evals, faq, faq-individual]
date: last-modified
image: images/eval_faq.png
aliases:
  - /evals-faq/how-many-people-should-annotate-my-llm-outputs
page-navigation: true
toc: true
toc-expand: 2
toc-depth: 3
toc-location: right
---

For most small to medium-sized companies, appointing a single domain expert as a "benevolent dictator" is the most effective approach. This person—whether it's a psychologist for a mental health chatbot, a lawyer for legal document analysis, or a customer service director for support automation—becomes the definitive voice on quality standards. 

A single expert eliminates annotation conflicts and prevents the paralysis that comes from "too many cooks in the kitchen". The benevolent dictator can incorporate input and feedback from others, but they drive the process. If you feel like you need five subject matter experts to judge a single interaction, it's a sign your product scope might be too broad. 

However, larger organizations or those operating across multiple domains (like a multinational company with different cultural contexts) may need multiple annotators. When you do use multiple people, you'll need to measure their agreement using metrics like Cohen's Kappa, which accounts for agreement beyond chance. However, use your judgment. Even in larger companies, a single expert is often enough.

Start with a benevolent dictator whenever feasible. Only add complexity when your domain demands it.

[↩ Back to main FAQ](/blog/posts/evals-faq/#q-how-many-people-should-annotate-my-llm-outputs){target="_blank" .faq-back-link}

{{< include _faq-context.qmd >}}
