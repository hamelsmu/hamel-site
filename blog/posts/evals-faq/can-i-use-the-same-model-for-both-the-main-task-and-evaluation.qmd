---
title: "Q: Can I use the same model for both the main task and evaluation?"
categories: [LLMs, evals, faq, faq-individual]
date: last-modified
image: images/eval_faq.png
aliases:
  - /evals-faq/can-i-use-the-same-model-for-both-the-main-task-and-evaluation
page-navigation: true
toc: true
toc-expand: 2
toc-depth: 3
toc-location: right
---

For LLM-as-Judge selection, using the same model is usually fine because the judge is doing a different task than your main LLM pipeline. While [research has shown](https://arxiv.org/pdf/2508.06709) that models can exhibit bias when evaluating their own outputs, what ultimately matters is how well your judge aligns with human judgments. The judges we recommend building do [scoped binary classification tasks](/blog/posts/evals-faq/why-do-you-recommend-binary-passfail-evaluations-instead-of-1-5-ratings-likert-scales.html){target="_blank"}.  We've found that iterative alignment with human labels is usually achievable on this constrained task. 

Focus on achieving high True Positive Rate (TPR) and True Negative Rate (TNR) with your judge on a held out labeled test set. If you struggle to achieve good alignment with human scores, then consider trying a different model. However onboarding new model providers may involve non-trivial effort in some organizations, which is why we don't advocate for using different models by default unless there's a specific alignment issue.

When selecting judge models, start with the most capable models available to establish strong alignment with human judgments. You can optimize for cost later once you've established reliable evaluation criteria.

[â†© Back to main FAQ](/blog/posts/evals-faq/#q-can-i-use-the-same-model-for-both-the-main-task-and-evaluation){target="_blank" .faq-back-link}

{{< include _faq-context.qmd >}}
