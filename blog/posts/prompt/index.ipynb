{
 "cells": [
  {
   "cell_type": "raw",
   "id": "55255c4c-2722-4494-adb5-32485356246c",
   "metadata": {},
   "source": [
    "---\n",
    "title: Fuck You, Show Me The Prompt.\n",
    "description: Quickly understand inscrutable LLM frameworks by intercepting API calls.\n",
    "categories: [llms, ml]\n",
    "author: Hamel Husain\n",
    "toc-location: right-body\n",
    "toc-title: Table Of Contents\n",
    "date: 2024-02-14\n",
    "image: slap_3.png\n",
    "aliases: [\"/prompt\"]\n",
    "website:\n",
    "  title: \"\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8161325f-53b9-4948-b3a5-69a0f1ca2cad",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "There are many libraries that aim to make the output of your LLMs better by **re-writing or constructing the prompt for you**.  These libraries purport to make the output of your LLMs:\n",
    "\n",
    "- safer [(ex: guardrails)](https://github.com/guardrails-ai/guardrails)\n",
    "- deterministic [(ex: guidance)](https://github.com/guidance-ai/guidance)\n",
    "- structured [(ex: instructor)](https://github.com/jxnl/instructor)\n",
    "- resilient [(ex: langchain)](https://www.langchain.com/)\n",
    "- ... or even optimized for an arbitrary metric [(ex: DSPy)](https://github.com/stanfordnlp/dspy).\n",
    "\n",
    "A common theme among _some_ of these tools is they encourage users to disintermediate themselves from prompting.\n",
    "\n",
    "> [DSPy](https://github.com/stanfordnlp/dspy): \"This is a new paradigm in which LMs and their prompts fade into the background .... you can compile your program again DSPy will create new effective prompts\"\n",
    "\n",
    "> [guidance](https://github.com/guidance-ai/guidance) \"guidance is a programming paradigm that offers superior control and efficiency compared to conventional prompting ... \"\n",
    "\n",
    "Even when tools don't discourage prompting, I've often found it difficult to retrieve the final prompt(s) these tools send to the language model.  **The prompts sent by these tools to the LLM is a natural language description of what these tools are doing, and is the fastest way to understand how they work.**  Furthermore, some tools have [dense terminology](https://github.com/stanfordnlp/dspy?tab=readme-ov-file#4-two-powerful-concepts-signatures--teleprompters) to describe internal constructs which can further obfuscate what they are doing.  \n",
    "\n",
    "For reasons I'll explain below, I think most people would benefit from the following mindset:\n",
    "\n",
    "![](slap_3.jpeg){fig-align=\"center\"}\n",
    "\n",
    "In this blog post, I'll show you how you can **intercept API calls w/prompts for any tool, without having to fumble through docs or read source code.**  I'll show you how to setup and operate [mitmproxy](https://mitmproxy.org/) with examples from the LLM the tools I previously mentioned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237e5439-b1eb-42bf-8de0-65fbf616345b",
   "metadata": {},
   "source": [
    "## Motivation: Minimize accidental complexity\n",
    "\n",
    "Before adopting an abstraction, its important to consider the dangers of taking on [accidental complexity](https://dev.to/alexbunardzic/software-complexity-essential-accidental-and-incidental-3i4d). This danger is acute for LLM abstractions relative to programming abstractions.  With LLM abstractions, we often force the user to regress towards writing code instead of conversing with the AI in natural language, which can run counter to the purpose of LLMs:\n",
    "\n",
    "<center>\n",
    "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Programming abstraction -&gt; a human-like language you can use to translate your task into machine code<br><br>LLM abstraction -&gt; an unintelligible framework you can use to translate your task into human language</p>&mdash; Hamel Husain (@HamelHusain) <a href=\"https://twitter.com/HamelHusain/status/1754315254413361553\">February 5, 2024</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "</center>\n",
    "\n",
    "While this is a cheeky comment, it's worth keeping this in mind while evaluating tools.  There are two primary types of automation that tools provide:\n",
    "\n",
    "- **Interleaving code and LLMs:** Expressing this automation is often best done through code, since code must be run to carry out the task.  Examples include routing, executing functions, retries, chaining, etc.\n",
    "- **Re-Writing and constructing prompts**:  Expressing your intent is often best done through natural language.  However, there are exceptions! For example, it is convenient to express a function definition or schema from code instead of natural language.\n",
    "\n",
    "Many frameworks offer both types of automation.  However, going too far with the second type can have negative consequences.  Seeing the prompt allows you decide:\n",
    "\n",
    "1. Is this framework really necessary?\n",
    "2. Should I just steal the final prompt (a string) and jettison the framework?\n",
    "3. Can we write a better prompt than this (shorter, aligned with your intent, etc)?\n",
    "4. Is this the best approach (do the # of API calls seem appropriate)?\n",
    "\n",
    "In my experience, seeing the prompts and API calls are essential to making informed decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbd182f-f8e9-40d8-a61e-c1383fcbcce4",
   "metadata": {},
   "source": [
    "## Intercepting LLM API calls\n",
    "\n",
    "There are many possible ways to intercept LLM API calls, such as monkey patching source code or finding a user-facing option.  I've found that those approaches take far too much time since the quality of source code and documentation can vary greatly.  After all, I just want to see API calls without worrying about how the code works!\n",
    "\n",
    "A framework agnostic way to see API calls is to setup a proxy that logs your outgoing API requests.  This is easy to do with [mitmproxy](https://mitmproxy.org/), an free, open-source HTTPS proxy.\n",
    "\n",
    "\n",
    "### Setting Up mitmproxy\n",
    "\n",
    "This is an opinionated way to setup `mitmproxy`that's beginner-friendly for our intended purposes:\n",
    "\n",
    "1. Follow the installation instructions [on the website](https://mitmproxy.org/)\n",
    "2. Start the interactive UI by running `mitmweb` in the terminal.  Pay attention to the url of the interactive UI in the logs which will look something like this: `Web server listening at http://127.0.0.1:8081/`\n",
    "3. Next, you need to configure your device (i.e. your laptop) to route all traffic through `mitproxy`, which listens on `http://localhost:8080`.  Per the documentation:\n",
    "\n",
    "    >  We recommend to simply search the web on how to configure an HTTP proxy for your system. Some operating system have a global settings, some browser have their own, other applications use environment variables, etc.\n",
    "\n",
    "    In my case, A [google search for \"set proxy for macos\"](https://www.google.com/search?q=set+proxy+for+macos&sca_esv=c51a80de1a7d45f0&rlz=1C5CHFA_enUS1048US1049&sxsrf=ACQVn0_ysjr6Kma2_lX8WbB06iPbDi5gUQ%3A1707764982232&ei=9mzKZYXoDcfy0PEPpJqb2Ao&ved=0ahUKEwiFu4CpwKaEAxVHOTQIHSTNBqsQ4dUDCBA&uact=5&oq=set+proxy+for+macos&gs_lp=Egxnd3Mtd2l6LXNlcnAiE3NldCBwcm94eSBmb3IgbWFjb3MyBBAjGCcyBhAAGBYYHjIGEAAYFhgeMgYQABgWGB4yBhAAGBYYHjILEAAYgAQYigUYhgMyCxAAGIAEGIoFGIYDSMk-UMU7WMU7cAd4AZABAJgBVaABVaoBATG4AQPIAQD4AQHCAgoQABhHGNYEGLAD4gMEGAAgQYgGAZAGCA&sclient=gws-wiz-serp) returned these results:\n",
    "\n",
    "    > choose Apple menu > System Settings, click Network in the sidebar, click a network service on the right, click Details, then click Proxies.\n",
    "\n",
    "    I then insert `localhost` and `8080` in the following places in the UI:\n",
    "\n",
    "    ![](mac.png){fig-align=\"center\"}\n",
    "\n",
    "4. Next, navigate to [http://mitm.it](http://mitm.it) and it will give you instructions on how to install the mitmproxy Certificate Authority (CA), which you will need for intercepting HTTPS requests.  (You can also do this manually [here](https://docs.mitmproxy.org/stable/concepts-certificates/#quick-setup).)  Also, take note of the location of the CA file as we will reference it later.\n",
    "\n",
    "5. You can test that everything works by browsing to a website like [https://mitmproxy.org/](https://mitmproxy.org/), and seeing the corresponding output in the mtimweb UI which for me is located at [http://127.0.0.1:8081/](http://127.0.0.1:8081/) (look at the logs in your terminal to get the URL).\n",
    "\n",
    "6. Now that you set everything up, you can disable the proxy that you previously enabled on your network.  I do this on my mac by toggling the proxy buttons in the screenshot I showed above.  This is because we want to scope the proxy to only the python program to eliminate unnecessary noise.\n",
    "\n",
    ":::{.callout-tip}\n",
    "\n",
    "Networking related software commonly allows you to proxy outgoing requests by setting environment variables.  This is the approach we will use to scope our proxy to specific Python programs.  However, I encourage you to play with other types of programs to see what you find after you are comfortable!\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be749f34-bab7-4081-964d-c971466aba53",
   "metadata": {},
   "source": [
    "### Environment variables for Python\n",
    "\n",
    "We need to set the following environment variables so that the `requests` and `httpx` libraries will direct traffic to the proxy and reference the CA file for HTTPS traffic: \n",
    "\n",
    ":::{.callout-important}\n",
    "\n",
    "Make sure you set these environment variables before running any of the code snippets in this blog post.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c4617c-1d52-4c99-9bed-645efd73ba71",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# The location of my CA File\n",
    "cert_file = '/Users/hamel/Downloads/mitmproxy-ca-cert.pem' \n",
    "os.environ['REQUESTS_CA_BUNDLE'] = cert_file\n",
    "os.environ['SSL_CERT_FILE'] = cert_file\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:8080'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a9753-a6a6-4d7b-895a-4059abcdfc7d",
   "metadata": {},
   "source": [
    "You can do a minimal test by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf4a70a-bde5-47c0-b649-3179c233c189",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.post('https://httpbin.org/post', \n",
    "              data={'key': 'value'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fb6c76-81b2-4193-9441-f586e9adcf8c",
   "metadata": {},
   "source": [
    "This will appear in the UI like so:\n",
    "\n",
    "![](mitm_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88267e7-4324-45dc-9401-8737f7a5b15a",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "Now for the fun part, let's run through some examples of LLM libraries and intercept their API calls!\n",
    "\n",
    "### Guardrails\n",
    "\n",
    "Guardrails allows you specify structure and types, which it uses to validate and correct the outputs of large language models.  This is a hello world example from the [`guardrails-ai/guardrails` README](https://github.com/guardrails-ai/guardrails):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c746dbe7-e96f-4ea0-89d5-ca9b0b0685e8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"pet_type\": \"dog\",\n",
      "    \"name\": \"Buddy\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from guardrails import Guard\n",
    "import openai\n",
    "\n",
    "class Pet(BaseModel):\n",
    "    pet_type: str = Field(description=\"Species of pet\")\n",
    "    name: str = Field(description=\"a unique pet name\")\n",
    "\n",
    "prompt = \"\"\"\n",
    "    What kind of pet should I get and what should I name it?\n",
    "\n",
    "    ${gr.complete_json_suffix_v2}\n",
    "\"\"\"\n",
    "guard = Guard.from_pydantic(output_class=Pet, prompt=prompt)\n",
    "\n",
    "validated_output, *rest = guard(\n",
    "    llm_api=openai.completions.create,\n",
    "    engine=\"gpt-3.5-turbo-instruct\"\n",
    ")\n",
    "\n",
    "print(f\"{validated_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e12fa0-dae1-4dcc-b71c-471dd1885b29",
   "metadata": {},
   "source": [
    "What is happening here?  How is this structured output and validation working?  Looking at the mitmproxy UI, I can see that the above code resulted in two LLM API calls, the first one with this prompt:\n",
    "\n",
    "```{.txt .code-overflow-wrap}\n",
    "What kind of pet should I get and what should I name it?\n",
    "\n",
    "    \n",
    "Given below is XML that describes the information to extract from this document and the tags to extract it into.\n",
    "\n",
    "<output>\n",
    "    <string name=\"pet_type\" description=\"Species of pet\"/>\n",
    "    <string name=\"name\" description=\"a unique pet name\"/>\n",
    "</output>\n",
    "\n",
    "\n",
    "ONLY return a valid JSON object (no other text is necessary), where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise.\n",
    "\n",
    "Here are examples of simple (XML, JSON) pairs that show the expected behavior:\n",
    "- `<string name='foo' format='two-words lower-case' />` => `{'foo': 'example one'}`\n",
    "- `<list name='bar'><string format='upper-case' /></list>` => `{\"bar\": ['STRING ONE', 'STRING TWO', etc.]}`\n",
    "- `<object name='baz'><string name=\"foo\" format=\"capitalize two-words\" /><integer name=\"index\" format=\"1-indexed\" /></object>` => `{'baz': {'foo': 'Some String', 'index': 1}}`\n",
    "```\n",
    "\n",
    "**Followed by another call with this prompt:**\n",
    "\n",
    "\n",
    "```{.txt .code-overflow-wrap}\n",
    "I was given the following response, which was not parseable as JSON.\n",
    "\n",
    "\"{\\n    \\\"pet_type\\\": \\\"dog\\\",\\n    \\\"name\\\": \\\"Buddy\"\n",
    "\n",
    "Help me correct this by making it valid JSON.\n",
    "\n",
    "Given below is XML that describes the information to extract from this document and the tags to extract it into.\n",
    "\n",
    "<output>\n",
    "    <string name=\"pet_type\" description=\"Species of pet\"/>\n",
    "    <string name=\"name\" description=\"a unique pet name\"/>\n",
    "</output>\n",
    "\n",
    "\n",
    "ONLY return a valid JSON object (no other text is necessary), where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter `null`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db068bea-97d8-4431-9bd0-6bfa7fa2f601",
   "metadata": {},
   "source": [
    "```{.json .code-overflow-wrap .content-hidden}\n",
    "{\n",
    "    \"model\": \"gpt-3.5-turbo-instruct\",\n",
    "    \"prompt\": \"\\n    What kind of pet should I get and what should I name it?\\n\\n    \\nGiven below is XML that describes the information to extract from this document and the tags to extract it into.\\n\\n<output>\\n    <string name=\\\"pet_type\\\" description=\\\"Species of pet\\\"/>\\n    <string name=\\\"name\\\" description=\\\"a unique pet name\\\"/>\\n</output>\\n\\n\\nONLY return a valid JSON object (no other text is necessary), where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise.\\n\\nHere are examples of simple (XML, JSON) pairs that show the expected behavior:\\n- `<string name='foo' format='two-words lower-case' />` => `{'foo': 'example one'}`\\n- `<list name='bar'><string format='upper-case' /></list>` => `{\\\"bar\\\": ['STRING ONE', 'STRING TWO', etc.]}`\\n- `<object name='baz'><string name=\\\"foo\\\" format=\\\"capitalize two-words\\\" /><integer name=\\\"index\\\" format=\\\"1-indexed\\\" /></object>` => `{'baz': {'foo': 'Some String', 'index': 1}}`\\n\\n\\n\\nJson Output:\\n\\n\",\n",
    "    \"temperature\": 0\n",
    "}\n",
    "```\n",
    "\n",
    "```{.json .code-overflow-wrap .content-hidden}\n",
    "{\n",
    "    \"model\": \"gpt-3.5-turbo-instruct\",\n",
    "    \"prompt\": \"\\nI was given the following response, which was not parseable as JSON.\\n\\n\\\"{\\\\n    \\\\\\\"pet_type\\\\\\\": \\\\\\\"dog\\\\\\\",\\\\n    \\\\\\\"name\\\\\\\": \\\\\\\"Buddy\\\"\\n\\nHelp me correct this by making it valid JSON.\\n\\nGiven below is XML that describes the information to extract from this document and the tags to extract it into.\\n\\n<output>\\n    <string name=\\\"pet_type\\\" description=\\\"Species of pet\\\"/>\\n    <string name=\\\"name\\\" description=\\\"a unique pet name\\\"/>\\n</output>\\n\\n\\nONLY return a valid JSON object (no other text is necessary), where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter `null`.\\n\\n\\nJson Output:\\n\\n\",\n",
    "    \"temperature\": 0\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d761ab6d-6210-4e96-b030-d51b530be265",
   "metadata": {},
   "source": [
    "Woof.  That's a whole lot of ceremony to get structured output!  We learned that this library's approach to structured output uses XML schemas (while others use function calling).  It's worth considering if you can fashion a better or simpler approach now that the magic has been lifted.  Either way, we now have insight into how it works without dragging you into unnecessary complexity, which is a win."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf336a7-b35b-4294-be25-0f321a39076b",
   "metadata": {},
   "source": [
    "### Guidance\n",
    "\n",
    "Guidance offers constrained generation and programming constructs for writing prompts. Let's dive into a [chat example from their tutorials](https://github.com/guidance-ai/guidance/blob/main/notebooks/tutorials/chat.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe6882f-e22c-4666-9a66-6ce41262c6ea",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import guidance\n",
    "gpt35 = guidance.models.OpenAI(\"gpt-3.5-turbo\")\n",
    "\n",
    "import re\n",
    "from guidance import gen, select, system, user, assistant\n",
    "\n",
    "@guidance\n",
    "def plan_for_goal(lm, goal: str):\n",
    "    \n",
    "    # This is a helper function which we will use below\n",
    "    def parse_best(prosandcons, options):\n",
    "        best = re.search(r'Best=(\\d+)', prosandcons)\n",
    "        if not best:\n",
    "            best =  re.search(r'Best.*?(\\d+)', 'Best= option is 3')\n",
    "        if best:\n",
    "            best = int(best.group(1))\n",
    "        else:\n",
    "            best = 0\n",
    "        return options[best]\n",
    "\n",
    "    # Some general instruction to the model\n",
    "    with system():\n",
    "        lm += \"You are a helpful assistant.\"\n",
    "\n",
    "    # Simulate a simple request from the user\n",
    "    # Note that we switch to using 'lm2' here, because these are intermediate steps (so we don't want to overwrite the current lm object)\n",
    "    with user():\n",
    "        lm2 = lm + f\"\"\"\\\n",
    "        I want to {goal}\n",
    "        Can you please generate one option for how to accomplish this?\n",
    "        Please make the option very short, at most one line.\"\"\"\n",
    "\n",
    "    # Generate several options. Note that this means several sequential generation requests\n",
    "    n_options = 5\n",
    "    with assistant():\n",
    "        options = []\n",
    "        for i in range(n_options):\n",
    "            options.append((lm2 + gen(name='option', temperature=1.0, max_tokens=50))[\"option\"])\n",
    "\n",
    "    # Have the user request pros and cons\n",
    "    with user():\n",
    "        lm2 += f\"\"\"\\\n",
    "        I want to {goal}\n",
    "        Can you please comment on the pros and cons of each of the following options, and then pick the best option?\n",
    "        ---\n",
    "        \"\"\"\n",
    "        for i, opt in enumerate(options):\n",
    "            lm2 += f\"Option {i}: {opt}\\n\"\n",
    "        lm2 += f\"\"\"\\\n",
    "        ---\n",
    "        Please discuss each option very briefly (one line for pros, one for cons), and end by saying Best=X, where X is the number of the best option.\"\"\"\n",
    "\n",
    "    # Get the pros and cons from the model\n",
    "    with assistant():\n",
    "        lm2 += gen(name='prosandcons', temperature=0.0, max_tokens=600, stop=\"Best=\") + \"Best=\" + gen(\"best\", regex=\"[0-9]+\") \n",
    "\n",
    "    # The user now extracts the one selected as the best, and asks for a full plan\n",
    "    # We switch back to 'lm' because this is the final result we want\n",
    "    with user():\n",
    "        lm += f\"\"\"\\\n",
    "        I want to {goal}\n",
    "        Here is my plan: {options[int(lm2[\"best\"])]}\n",
    "        Please elaborate on this plan, and tell me how to best accomplish it.\"\"\"\n",
    "\n",
    "    # The plan is generated\n",
    "    with assistant():\n",
    "        lm += gen(name='plan', max_tokens=500)\n",
    "\n",
    "    return lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbd50af-7689-426c-8779-1b0d5e9bfe7a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>system</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>You are a helpful assistant.</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>I want to read more books\n",
       "Here is my plan: Set aside 30 minutes of dedicated reading time each day.\n",
       "Please elaborate on this plan, and tell me how to best accomplish it.</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>Setting</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> aside</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> </span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>30</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> minutes</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> of</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> dedicated</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> time</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> each</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> day</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> is</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> great</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> plan</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> to</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> read</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> more</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> books</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Here</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> are</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> some</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> tips</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> to</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> help</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> you</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> accomplish</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> this</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> goal</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>:\n",
       "\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>1</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Establish</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> routine</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>:</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Choose</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> specific</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> time</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> of</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> day</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> that</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> works</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> best</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> for</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> you</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> whether</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> it</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>&#x27;s</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> in</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> the</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> morning</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> during</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> lunch</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> break</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> or</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> before</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> bed</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Cons</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>istency</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> is</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> key</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> to</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> forming</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> habit</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.\n",
       "\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>2</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Create</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>-friendly</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> environment</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>:</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Find</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> quiet</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> and</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> comfortable</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> spot</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> where</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> you</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> can</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> focus</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> on</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> your</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> without</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> distractions</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> It</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> could</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> be</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> cozy</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> corner</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> in</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> your</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> home</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> park</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> bench</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> or</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> local</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> library</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.\n",
       "\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>3</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Mini</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>mi</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>ze</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> distractions</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>:</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Put</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> away</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> your</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> phone</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> turn</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> off</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> the</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> TV</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> and</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> avoid</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> any</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> other</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> potential</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> interruptions</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> during</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> your</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> dedicated</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> time</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> This</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> will</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> help</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> you</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> stay</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> focused</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> and</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> fully</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> immer</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>se</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> yourself</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> in</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> the</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> book</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.\n",
       "\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>4</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Choose</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> books</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> that</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> interest</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> you</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>:</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Select</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> books</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> that</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> align</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> with</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> your</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> personal</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> interests</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> hobbies</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> or</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> goals</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> When</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> you</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>&#x27;re</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> genuinely</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> interested</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> in</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> the</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> subject</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> matter</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> you</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>&#x27;ll</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> be</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> more</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> motivated</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> to</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> read</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> regularly</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.\n",
       "\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>5</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Start</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> with</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> manageable</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> goals</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>:</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> If</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> you</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>&#x27;re</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> new</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> to</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> or</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> have</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> busy</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> schedule</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> start</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> with</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> smaller</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> time</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> commitment</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> such</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> as</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> </span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>15</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> minutes</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> and</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> gradually</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> increase</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> it</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> to</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> </span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>30</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> minutes</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> or</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> more</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> as</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> you</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> become</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> more</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> comfortable</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.\n",
       "\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>6</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Set</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> timer</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>:</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Use</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> timer</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> or</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> app</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> that</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> allows</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> you</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> to</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> track</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> your</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> time</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> This</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> will</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> help</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> you</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> stay</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> accountable</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> and</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> ensure</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> that</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> you</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> dedicate</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> the</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> full</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> </span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>30</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> minutes</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> to</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.\n",
       "\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>7</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Make</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> enjoyable</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>:</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Create</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> cozy</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> atmosphere</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> by</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> lighting</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> candle</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> sip</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>ping</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> cup</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> of</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> tea</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> or</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> playing</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> soft</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> background</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> music</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Eng</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>aging</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> all</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> your</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> senses</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> can</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> enhance</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> your</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> experience</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.\n",
       "\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>8</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Join</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> book</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> club</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> or</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> group</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>:</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Consider</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> joining</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> book</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> club</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> or</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> participating</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> in</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> group</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> to</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> connect</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> with</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> fellow</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> book</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> lovers</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> This</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> can</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> provide</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> additional</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> motivation</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> discussion</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> opportunities</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> and</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> book</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> recommendations</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.\n",
       "\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>9</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Keep</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> log</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>:</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Maintain</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> record</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> of</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> the</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> books</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> you</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>&#x27;ve</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> read</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> along</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> with</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> your</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> thoughts</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> and</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reflections</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> This</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> can</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> help</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> you</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> track</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> your</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> progress</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> discover</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> patterns</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> in</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> your</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> preferences</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> and</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> serve</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> as</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> source</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> of</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> inspiration</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> for</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> future</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.\n",
       "\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>10</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Be</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> flexible</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>:</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> While</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> it</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>&#x27;s</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> important</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> to</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> have</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> dedicated</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> time</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> be</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> flexible</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> and</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> adaptable</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Life</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> can</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> sometimes</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> get</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> busy</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> so</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> if</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> you</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> miss</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> day</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> don</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>&#x27;t</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> be</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> discouraged</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Simply</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> pick</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> up</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> where</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> you</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> left</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> off</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> and</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> continue</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> with</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> your</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> routine</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.\n",
       "\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>Remember</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>,</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> the</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> goal</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> is</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> to</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> enjoy</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> the</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> process</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> of</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> and</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> make</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> it</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> regular</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> part</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> of</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> your</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> life</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Happy</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reading</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>!</span></div></div></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = gpt35 + plan_for_goal(goal=\"read more books\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64feb9d7-b3f9-46a4-ab92-0023121e8eca",
   "metadata": {},
   "source": [
    "This looks pretty neat!  But what is it doing exactly?  **This makes a total of 7 calls to OpenAI**, which I have put in [this gist](https://gist.github.com/hamelsmu/d0d75bf702e56987f35cb715f7da4d6a).  **5 of 7 of these API calls are \"internal\" thoughts asking the LLM to generate ideas.**  Even though the temperature is set to 1.0, **these \"ideas\" are mostly redundant.**  The penultimate call to OpenAI enumerates these \"ideas\" which I've included below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a0664f-577d-4a0c-96e7-74527036a0be",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to read more books\n",
      "Can you please comment on the pros and cons of each of the following options, and then pick the best option?\n",
      "---\n",
      "Option 0: Set aside dedicated time each day for reading.\n",
      "Option 1: Set aside 30 minutes of dedicated reading time each day.\n",
      "Option 2: Set aside dedicated time each day for reading.\n",
      "Option 3: Set aside dedicated time each day for reading.\n",
      "Option 4: Join a book club.\n",
      "---\n",
      "Please discuss each option very briefly (one line for pros, one for cons), and end by saying Best=X, where X is the number of the best option.\n"
     ]
    }
   ],
   "source": [
    "#|echo: false\n",
    "print(\"I want to read more books\\nCan you please comment on the pros and cons of each of the following options, and then pick the best option?\\n---\\nOption 0: Set aside dedicated time each day for reading.\\nOption 1: Set aside 30 minutes of dedicated reading time each day.\\nOption 2: Set aside dedicated time each day for reading.\\nOption 3: Set aside dedicated time each day for reading.\\nOption 4: Join a book club.\\n---\\nPlease discuss each option very briefly (one line for pros, one for cons), and end by saying Best=X, where X is the number of the best option.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f8dd76-66d2-45bf-9b97-3153f56d8528",
   "metadata": {},
   "source": [
    "I know from experience that you are likely to get better results if you tell the language model to generate ideas in one shot.  That way, the LLM can reference previous ideas and achieve more diversity. This is a good example of accidental complexity: its very tempting to take this design pattern and apply it blindly.  This is less of a critique of this particular framework, since the code makes it clear that 5 independent calls will happen.  Either way, its good idea to check your work by inspecting API calls!."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a63654-f79d-4bbc-a5bc-24424edd8320",
   "metadata": {},
   "source": [
    "### Langchain\n",
    "\n",
    "Langchain is a multi-tool for all things LLM. Lots of people rely on Langchain when get started with LLMs.  The core LangChain library doesn't generally hide prompts from you, however there are experimental features that do.  Let's take a look at one of these features called [SmartLLMChain](https://api.python.langchain.com/en/latest/smart_llm/langchain_experimental.smart_llm.base.SmartLLMChain.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600b1e60-6c01-429e-834b-470730b5ea26",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_experimental.smart_llm import SmartLLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "hard_question = \"I have a 12 liter jug and a 6 liter jug.\\\n",
    "I want to measure 6 liters. How do I do it?\"\n",
    "prompt = PromptTemplate.from_template(hard_question)\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb002f1-5f1b-40a7-ad4f-c9052813ef1f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SmartLLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI have a 12 liter jug and a 6 liter jug.I want to measure 6 liters. How do I do it?\u001b[0m\n",
      "Idea 1:\n",
      "\u001b[36;1m\u001b[1;3m1. Fill the 12 liter jug completely.\n",
      "2. Pour the contents of the 12 liter jug into the 6 liter jug. This will leave you with 6 liters in the 12 liter jug.\n",
      "3. Empty the 6 liter jug.\n",
      "4. Pour the remaining 6 liters from the 12 liter jug into the now empty 6 liter jug.\n",
      "5. You now have 6 liters in the 6 liter jug.\u001b[0m\n",
      "Idea 2:\n",
      "\u001b[36;1m\u001b[1;3m1. Fill the 12 liter jug completely.\n",
      "2. Pour the contents of the 12 liter jug into the 6 liter jug. This will leave you with 6 liters in the 12 liter jug.\n",
      "3. Empty the 6 liter jug.\n",
      "4. Pour the remaining 6 liters from the 12 liter jug into the now empty 6 liter jug.\n",
      "5. You now have 6 liters in the 6 liter jug.\u001b[0m\n",
      "Critique:\n",
      "\u001b[33;1m\u001b[1;3mFlaws and faulty logic in Idea 1:\n",
      "1. The first step of filling the 12 liter jug completely assumes that the jug can hold exactly 12 liters without any overflow or measurement errors. This assumption may not be accurate in reality.\n",
      "2. Pouring the contents of the 12 liter jug into the 6 liter jug assumes that the 6 liter jug can hold all 12 liters without any spillage or measurement errors. Again, this assumption may not be accurate.\n",
      "3. Emptying the 6 liter jug assumes that it can be emptied completely without any residue or measurement errors. This assumption may not be accurate.\n",
      "4. Pouring the remaining 6 liters from the 12 liter jug into the now empty 6 liter jug assumes that the remaining 6 liters can be accurately measured and transferred without any spillage or measurement errors. This assumption may not be accurate.\n",
      "5. The conclusion that you now have 6 liters in the 6 liter jug assumes that all the measurements and transfers were accurate and error-free, which may not be the case.\n",
      "\n",
      "Flaws and faulty logic in Idea 2:\n",
      "1. The first step of filling the 12 liter jug completely assumes that the jug can hold exactly 12 liters without any overflow or measurement errors. This assumption may not be accurate in reality.\n",
      "2. Pouring the contents of the 12 liter jug into the 6 liter jug assumes that the 6 liter jug can hold all 12 liters without any spillage or measurement errors. Again, this assumption may not be accurate.\n",
      "3. Emptying the 6 liter jug assumes that it can be emptied completely without any residue or measurement errors. This assumption may not be accurate.\n",
      "4. Pouring the remaining 6 liters from the 12 liter jug into the now empty 6 liter jug assumes that the remaining 6 liters can be accurately measured and transferred without any spillage or measurement errors. This assumption may not be accurate.\n",
      "5. The conclusion that you now have 6 liters in the 6 liter jug assumes that all the measurements and transfers were accurate and error-free, which may not be the case.\n",
      "\n",
      "In both ideas, there are several assumptions made about the accuracy and precision of the measurements and transfers, which may not hold true in practice. Additionally, there is no consideration given to the possibility of spillage or measurement errors, which can significantly affect the final result.\u001b[0m\n",
      "Resolution:\n",
      "\u001b[32;1m\u001b[1;3mIdea 1: 1. Fill the 12 liter jug completely.\n",
      "2. Pour the contents of the 12 liter jug into the 6 liter jug. This will leave you with 6 liters in the 12 liter jug.\n",
      "3. Empty the 6 liter jug.\n",
      "4. Pour the remaining 6 liters from the 12 liter jug into the now empty 6 liter jug.\n",
      "5. You now have 6 liters in the 6 liter jug.\n",
      "\n",
      "Idea 2: 1. Fill the 12 liter jug completely.\n",
      "2. Pour the contents of the 12 liter jug into the 6 liter jug. This will leave you with 6 liters in the 12 liter jug.\n",
      "3. Empty the 6 liter jug.\n",
      "4. Pour the remaining 6 liters from the 12 liter jug into the now empty 6 liter jug.\n",
      "5. You now have 6 liters in the 6 liter jug.\n",
      "\n",
      "Improved Answer:\n",
      "1. Fill the 12 liter jug completely.\n",
      "2. Pour the contents of the 12 liter jug into the 6 liter jug until the 6 liter jug is full. This will leave you with 6 liters in the 12 liter jug and the 6 liter jug completely filled.\n",
      "3. Empty the 6 liter jug.\n",
      "4. Pour the remaining 6 liters from the 12 liter jug into the now empty 6 liter jug.\n",
      "5. You now have 6 liters in the 6 liter jug.\n",
      "\n",
      "Full Answer:\n",
      "To measure 6 liters using a 12 liter jug and a 6 liter jug, follow these steps:\n",
      "1. Fill the 12 liter jug completely.\n",
      "2. Pour the contents of the 12 liter jug into the 6 liter jug until the 6 liter jug is full. This will leave you with 6 liters in the 12 liter jug and the 6 liter jug completely filled.\n",
      "3. Empty the 6 liter jug.\n",
      "4. Pour the remaining 6 liters from the 12 liter jug into the now empty 6 liter jug.\n",
      "5. You now have 6 liters in the 6 liter jug.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#| warning: false\n",
    "#| output: false\n",
    "chain = SmartLLMChain(llm=llm, prompt=prompt, \n",
    "                      n_ideas=2, \n",
    "                      verbose=True)\n",
    "result = chain.run({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be7600-e9eb-4ed2-91d9-a8182858ca83",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idea 1: 1. Fill the 12 liter jug completely.\n",
      "2. Pour the contents of the 12 liter jug into the 6 liter jug. This will leave you with 6 liters in the 12 liter jug.\n",
      "3. Empty the 6 liter jug.\n",
      "4. Pour the remaining 6 liters from the 12 liter jug into the now empty 6 liter jug.\n",
      "5. You now have 6 liters in the 6 liter jug.\n",
      "\n",
      "Idea 2: 1. Fill the 12 liter jug completely.\n",
      "2. Pour the contents of the 12 liter jug into the 6 liter jug. This will leave you with 6 liters in the 12 liter jug.\n",
      "3. Empty the 6 liter jug.\n",
      "4. Pour the remaining 6 liters from the 12 liter jug into the now empty 6 liter jug.\n",
      "5. You now have 6 liters in the 6 liter jug.\n",
      "\n",
      "Improved Answer:\n",
      "1. Fill the 12 liter jug completely.\n",
      "2. Pour the contents of the 12 liter jug into the 6 liter jug until the 6 liter jug is full. This will leave you with 6 liters in the 12 liter jug and the 6 liter jug completely filled.\n",
      "3. Empty the 6 liter jug.\n",
      "4. Pour the remaining 6 liters from the 12 liter jug into the now empty 6 liter jug.\n",
      "5. You now have 6 liters in the 6 liter jug.\n",
      "\n",
      "Full Answer:\n",
      "To measure 6 liters using a 12 liter jug and a 6 liter jug, follow these steps:\n",
      "1. Fill the 12 liter jug completely.\n",
      "2. Pour the contents of the 12 liter jug into the 6 liter jug until the 6 liter jug is full. This will leave you with 6 liters in the 12 liter jug and the 6 liter jug completely filled.\n",
      "3. Empty the 6 liter jug.\n",
      "4. Pour the remaining 6 liters from the 12 liter jug into the now empty 6 liter jug.\n",
      "5. You now have 6 liters in the 6 liter jug.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4511fd01-3bec-45a4-aac1-e19373b83e09",
   "metadata": {},
   "source": [
    "Neat!  So what happened exactly?  While this API emits logs that show you a lot of information (available on [this gist](https://gist.github.com/hamelsmu/abfb14b0af4c70e8532f9d4e0ef3e54e)), the API request pattern is interesting:\n",
    "\n",
    "1. Two _seperate_ api calls for each \"idea\".\n",
    "2. Another API call that incorporates the two ideas as context, with the prompt:\n",
    "   \n",
    "   > You are a researcher tasked with investigating the 2 response options provided. List the flaws and faulty logic of each answer options. Let'w work this out in a step by step way to be sure we have all the errors:\"\n",
    "\n",
    "4. A final API call that that takes the critique from step 2 and generates an answer.\n",
    "   \n",
    "Its not clear that this approach is optimal.  I am not sure it should take 4 separate API calls to accomplish this task.  Perhaps the critique and the final answer could be generated in one step?  Furthermore, the prompt has a spelling error (`Let'w`) and also overly focuses on the negative about identifying errors - which makes me skeptical that this prompt has been optimized or tested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a9c56e-b033-43c0-9d23-1088bd3bda3f",
   "metadata": {},
   "source": [
    "### Instructor\n",
    "\n",
    "[Instructor](https://github.com/jxnl/instructor) is a framework for structured outputs.  \n",
    "\n",
    "#### Structred data extraction with Pydantic\n",
    "\n",
    "Here is a basic example from the project's [README](https://github.com/jxnl/instructor) that allows you to extract structured data by using Pydantic to define your schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8469f9f6-6998-4de7-8551-c073929e385c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "class UserDetail(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "user = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=UserDetail,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b90a4e-7060-4676-b77a-757089e62855",
   "metadata": {},
   "source": [
    "We can see how this works by inspecting the API call logged to mitmproxy:\n",
    "\n",
    "```{.json .code-overflow-wrap}\n",
    "{\n",
    "    \"function_call\": {\n",
    "        \"name\": \"UserDetail\"\n",
    "    },\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"description\": \"Correctly extracted `UserDetail` with all the required parameters with correct types\",\n",
    "            \"name\": \"UserDetail\",\n",
    "            \"parameters\": {\n",
    "                \"properties\": {\n",
    "                    \"age\": {\n",
    "                        \"title\": \"Age\",\n",
    "                        \"type\": \"integer\"\n",
    "                    },\n",
    "                    \"name\": {\n",
    "                        \"title\": \"Name\",\n",
    "                        \"type\": \"string\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"age\",\n",
    "                    \"name\"\n",
    "                ],\n",
    "                \"type\": \"object\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"content\": \"Extract Jason is 25 years old\",\n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "    ],\n",
    "    \"model\": \"gpt-3.5-turbo\"\n",
    "}\n",
    "```\n",
    "\n",
    "This is great. For structured output - **It does exactly what I want, and it correctly uses the OpenAI API the way I would use it** if I were writing this manually (by defining a function schema).  I would consider this specific API a zero-cost abstraction, meaning it does exactly what I expect it to with a minimal surface area.\n",
    "\n",
    "#### Validation\n",
    "\n",
    "However, instructor has other APIs that are more agressive and write prompts for you.  For example, consider this [validation example](https://python.useinstructor.com/tutorials/4-validation/).  Running through that example should trigger similar questions to the exploration of [Langchain's SmartLLMChain](#SmartLLMChain) above.  In this example, you will observe 3 LLM API calls to get the right answer, with the final payload looking like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"function_call\": {\n",
    "        \"name\": \"Validator\"\n",
    "    },\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"description\": \"Validate if an attribute is correct and if not,\\nreturn a new value with an error message\",\n",
    "            \"name\": \"Validator\",\n",
    "            \"parameters\": {\n",
    "                \"properties\": {\n",
    "                    \"fixed_value\": {\n",
    "                        \"anyOf\": [\n",
    "                            {\n",
    "                                \"type\": \"string\"\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"null\"\n",
    "                            }\n",
    "                        ],\n",
    "                        \"default\": null,\n",
    "                        \"description\": \"If the attribute is not valid, suggest a new value for the attribute\",\n",
    "                        \"title\": \"Fixed Value\"\n",
    "                    },\n",
    "                    \"is_valid\": {\n",
    "                        \"default\": true,\n",
    "                        \"description\": \"Whether the attribute is valid based on the requirements\",\n",
    "                        \"title\": \"Is Valid\",\n",
    "                        \"type\": \"boolean\"\n",
    "                    },\n",
    "                    \"reason\": {\n",
    "                        \"anyOf\": [\n",
    "                            {\n",
    "                                \"type\": \"string\"\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"null\"\n",
    "                            }\n",
    "                        ],\n",
    "                        \"default\": null,\n",
    "                        \"description\": \"The error message if the attribute is not valid, otherwise None\",\n",
    "                        \"title\": \"Reason\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [],\n",
    "                \"type\": \"object\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"content\": \"You are a world class validation model. Capable to determine if the following value is valid for the statement, if it is not, explain why and suggest a new value.\",\n",
    "            \"role\": \"system\"\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"Does `According to some perspectives, the meaning of life is to find purpose, happiness, and fulfillment. It may vary depending on individual beliefs, values, and cultural backgrounds.` follow the rules: don't say objectionable things\",\n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "    ],\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"temperature\": 0\n",
    "}\n",
    "```\n",
    "\n",
    "Concretely, I'm curious if these steps could be collapsed into two LLM calls instead of three.  Furthermore, I wonder if generic validation functions (as supplied in the above payload) are the right way to critique output?  I don't know the answer, but this is an interesting design pattern that is worth poking at.\n",
    "\n",
    ":::{.callout-note}\n",
    "As far as LLM frameworks go, I really like this one.  The core functionality of defining schemas with Pydantic is very convenient.  The code is also very readable and easy to understand.  Despite this, I still found it helpful to intercept instructor's API calls to get another perspective.  \n",
    "\n",
    "There is a way to set a logging level in instructor to see the raw API calls, however, I like using a framework agnostic approach :)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f418d1-dc1e-45b0-b3b8-1647f59658cf",
   "metadata": {},
   "source": [
    "### DSPy\n",
    "\n",
    "[DSPy](https://github.com/stanfordnlp/dspy) is the framework that helps you optimize your prompts to optimize any arbitrary metric.  There is a fairly steep learning curve to DSPy, partly because it introduces many new technical terms specific to its framework like compilers and teleprompters.  However, we can quickly peel back the complexity by looking at the API calls that it makes!\n",
    "\n",
    "Let's run the [minimal working example](https://dspy-docs.vercel.app/docs/quick-start/minimal-example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e9870b-741b-4b48-8dd4-c7b619fe8693",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 7473/7473 [00:00<00:00, 46440.90it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████| 1319/1319 [00:00<00:00, 13480.23it/s]\n"
     ]
    }
   ],
   "source": [
    "#|output: false\n",
    "import time\n",
    "import dspy\n",
    "from dspy.datasets.gsm8k import GSM8K, gsm8k_metric\n",
    "start_time = time.time()\n",
    "\n",
    "# Set up the LM\n",
    "turbo = dspy.OpenAI(model='gpt-3.5-turbo-instruct', max_tokens=250)\n",
    "dspy.settings.configure(lm=turbo)\n",
    "\n",
    "# Load math questions from the GSM8K dataset\n",
    "gms8k = GSM8K()\n",
    "trainset, devset = gms8k.train, gms8k.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba9a01d-da36-43ba-a2be-2c6801f9154e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class CoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prog = dspy.ChainOfThought(\"question -> answer\")\n",
    "    \n",
    "    def forward(self, question):\n",
    "        return self.prog(question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f7feaf-0ad0-4691-9488-a6214abc2bcd",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 8 traces per predictor.\n",
      "Will attempt to train 10 candidate sets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 164 / 300  (54.7): 100%|██████████████████████████████████| 300/300 [00:00<00:00, 754.58it/s]\n",
      "/Users/hamel/mambaforge/lib/python3.10/site-packages/dspy/evaluate/evaluate.py:137: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 164 / 300  (54.7%)\n",
      "Score: 54.67 for set: [0]\n",
      "New best score: 54.67 for seed -3\n",
      "Scores so far: [54.67]\n",
      "Best score: 54.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 203 / 300  (67.7): 100%|██████████████████████████████████| 300/300 [00:00<00:00, 743.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 203 / 300  (67.7%)\n",
      "Score: 67.67 for set: [8]\n",
      "New best score: 67.67 for seed -2\n",
      "Scores so far: [54.67, 67.67]\n",
      "Best score: 67.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                   | 9/200 [00:00<00:00, 763.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 8 full traces after 10 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 215 / 300  (71.7): 100%|██████████████████████████████████| 300/300 [00:00<00:00, 673.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 215 / 300  (71.7%)\n",
      "Score: 71.67 for set: [8]\n",
      "New best score: 71.67 for seed -1\n",
      "Scores so far: [54.67, 67.67, 71.67]\n",
      "Best score: 71.67\n",
      "Average of max per entry across top 1 scores: 0.7166666666666667\n",
      "Average of max per entry across top 2 scores: 0.8533333333333334\n",
      "Average of max per entry across top 3 scores: 0.9033333333333333\n",
      "Average of max per entry across top 5 scores: 0.9033333333333333\n",
      "Average of max per entry across top 8 scores: 0.9033333333333333\n",
      "Average of max per entry across top 9999 scores: 0.9033333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                   | 9/200 [00:00<00:00, 722.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 7 full traces after 10 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 229 / 300  (76.3): 100%|██████████████████████████████████| 300/300 [00:00<00:00, 577.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 229 / 300  (76.3%)\n",
      "Score: 76.33 for set: [8]\n",
      "New best score: 76.33 for seed 0\n",
      "Scores so far: [54.67, 67.67, 71.67, 76.33]\n",
      "Best score: 76.33\n",
      "Average of max per entry across top 1 scores: 0.7633333333333333\n",
      "Average of max per entry across top 2 scores: 0.8433333333333334\n",
      "Average of max per entry across top 3 scores: 0.8966666666666666\n",
      "Average of max per entry across top 5 scores: 0.9266666666666666\n",
      "Average of max per entry across top 8 scores: 0.9266666666666666\n",
      "Average of max per entry across top 9999 scores: 0.9266666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▍                                                                     | 4/200 [00:00<00:00, 595.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 238 / 300  (79.3): 100%|██████████████████████████████████| 300/300 [00:00<00:00, 623.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 238 / 300  (79.3%)\n",
      "Score: 79.33 for set: [8]\n",
      "New best score: 79.33 for seed 1\n",
      "Scores so far: [54.67, 67.67, 71.67, 76.33, 79.33]\n",
      "Best score: 79.33\n",
      "Average of max per entry across top 1 scores: 0.7933333333333333\n",
      "Average of max per entry across top 2 scores: 0.8866666666666667\n",
      "Average of max per entry across top 3 scores: 0.9133333333333333\n",
      "Average of max per entry across top 5 scores: 0.95\n",
      "Average of max per entry across top 8 scores: 0.95\n",
      "Average of max per entry across top 9999 scores: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                      | 1/200 [00:00<00:00, 656.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 218 / 300  (72.7): 100%|██████████████████████████████████| 300/300 [00:00<00:00, 639.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 218 / 300  (72.7%)\n",
      "Score: 72.67 for set: [8]\n",
      "Scores so far: [54.67, 67.67, 71.67, 76.33, 79.33, 72.67]\n",
      "Best score: 79.33\n",
      "Average of max per entry across top 1 scores: 0.7933333333333333\n",
      "Average of max per entry across top 2 scores: 0.8866666666666667\n",
      "Average of max per entry across top 3 scores: 0.9266666666666666\n",
      "Average of max per entry across top 5 scores: 0.9566666666666667\n",
      "Average of max per entry across top 8 scores: 0.9633333333333334\n",
      "Average of max per entry across top 9999 scores: 0.9633333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▊                                                                    | 8/200 [00:00<00:00, 477.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 234 / 300  (78.0): 100%|██████████████████████████████████| 300/300 [00:00<00:00, 576.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 234 / 300  (78.0%)\n",
      "Score: 78.0 for set: [8]\n",
      "Scores so far: [54.67, 67.67, 71.67, 76.33, 79.33, 72.67, 78.0]\n",
      "Best score: 79.33\n",
      "Average of max per entry across top 1 scores: 0.7933333333333333\n",
      "Average of max per entry across top 2 scores: 0.9033333333333333\n",
      "Average of max per entry across top 3 scores: 0.93\n",
      "Average of max per entry across top 5 scores: 0.9633333333333334\n",
      "Average of max per entry across top 8 scores: 0.97\n",
      "Average of max per entry across top 9999 scores: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                     | 5/200 [00:00<00:00, 560.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 228 / 300  (76.0): 100%|██████████████████████████████████| 300/300 [00:00<00:00, 814.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 228 / 300  (76.0%)\n",
      "Score: 76.0 for set: [8]\n",
      "Scores so far: [54.67, 67.67, 71.67, 76.33, 79.33, 72.67, 78.0, 76.0]\n",
      "Best score: 79.33\n",
      "Average of max per entry across top 1 scores: 0.7933333333333333\n",
      "Average of max per entry across top 2 scores: 0.9033333333333333\n",
      "Average of max per entry across top 3 scores: 0.93\n",
      "Average of max per entry across top 5 scores: 0.96\n",
      "Average of max per entry across top 8 scores: 0.97\n",
      "Average of max per entry across top 9999 scores: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▊                                                                    | 8/200 [00:00<00:00, 535.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 234 / 300  (78.0): 100%|██████████████████████████████████| 300/300 [00:00<00:00, 801.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 234 / 300  (78.0%)\n",
      "Score: 78.0 for set: [8]\n",
      "Scores so far: [54.67, 67.67, 71.67, 76.33, 79.33, 72.67, 78.0, 76.0, 78.0]\n",
      "Best score: 79.33\n",
      "Average of max per entry across top 1 scores: 0.7933333333333333\n",
      "Average of max per entry across top 2 scores: 0.9033333333333333\n",
      "Average of max per entry across top 3 scores: 0.9266666666666666\n",
      "Average of max per entry across top 5 scores: 0.95\n",
      "Average of max per entry across top 8 scores: 0.97\n",
      "Average of max per entry across top 9999 scores: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                     | 5/200 [00:00<00:00, 639.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 222 / 300  (74.0): 100%|██████████████████████████████████| 300/300 [00:00<00:00, 798.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 222 / 300  (74.0%)\n",
      "Score: 74.0 for set: [8]\n",
      "Scores so far: [54.67, 67.67, 71.67, 76.33, 79.33, 72.67, 78.0, 76.0, 78.0, 74.0]\n",
      "Best score: 79.33\n",
      "Average of max per entry across top 1 scores: 0.7933333333333333\n",
      "Average of max per entry across top 2 scores: 0.9033333333333333\n",
      "Average of max per entry across top 3 scores: 0.9266666666666666\n",
      "Average of max per entry across top 5 scores: 0.95\n",
      "Average of max per entry across top 8 scores: 0.9733333333333334\n",
      "Average of max per entry across top 9999 scores: 0.9733333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|███▊                                                                  | 11/200 [00:00<00:00, 799.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 6 full traces after 12 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 228 / 300  (76.0): 100%|██████████████████████████████████| 300/300 [00:00<00:00, 489.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 228 / 300  (76.0%)\n",
      "Score: 76.0 for set: [8]\n",
      "Scores so far: [54.67, 67.67, 71.67, 76.33, 79.33, 72.67, 78.0, 76.0, 78.0, 74.0, 76.0]\n",
      "Best score: 79.33\n",
      "Average of max per entry across top 1 scores: 0.7933333333333333\n",
      "Average of max per entry across top 2 scores: 0.9033333333333333\n",
      "Average of max per entry across top 3 scores: 0.9266666666666666\n",
      "Average of max per entry across top 5 scores: 0.95\n",
      "Average of max per entry across top 8 scores: 0.9666666666666667\n",
      "Average of max per entry across top 9999 scores: 0.9733333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▍                                                                   | 7/200 [00:00<00:00, 1007.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 240 / 300  (80.0): 100%|██████████████████████████████████| 300/300 [00:00<00:00, 732.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 240 / 300  (80.0%)\n",
      "Score: 80.0 for set: [8]\n",
      "New best score: 80.0 for seed 8\n",
      "Scores so far: [54.67, 67.67, 71.67, 76.33, 79.33, 72.67, 78.0, 76.0, 78.0, 74.0, 76.0, 80.0]\n",
      "Best score: 80.0\n",
      "Average of max per entry across top 1 scores: 0.8\n",
      "Average of max per entry across top 2 scores: 0.89\n",
      "Average of max per entry across top 3 scores: 0.93\n",
      "Average of max per entry across top 5 scores: 0.9533333333333334\n",
      "Average of max per entry across top 8 scores: 0.96\n",
      "Average of max per entry across top 9999 scores: 0.9733333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                   | 9/200 [00:00<00:00, 829.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 8 full traces after 10 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 207 / 300  (69.0): 100%|███████████████████████████████████| 300/300 [01:03<00:00,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 207 / 300  (69.0%)\n",
      "Score: 69.0 for set: [8]\n",
      "Scores so far: [54.67, 67.67, 71.67, 76.33, 79.33, 72.67, 78.0, 76.0, 78.0, 74.0, 76.0, 80.0, 69.0]\n",
      "Best score: 80.0\n",
      "Average of max per entry across top 1 scores: 0.8\n",
      "Average of max per entry across top 2 scores: 0.89\n",
      "Average of max per entry across top 3 scores: 0.93\n",
      "Average of max per entry across top 5 scores: 0.9533333333333334\n",
      "Average of max per entry across top 8 scores: 0.96\n",
      "Average of max per entry across top 9999 scores: 0.9766666666666667\n",
      "13 candidate programs found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/hamel/mambaforge/lib/python3.10/site-packages/dspy/evaluate/evaluate.py:137: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    }
   ],
   "source": [
    "#|output: false\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# Set up the optimizer: we want to \"bootstrap\" (i.e., self-generate) 8-shot examples of our CoT program.\n",
    "# The optimizer will repeat this 10 times (plus some initial attempts) before selecting its best attempt on the devset.\n",
    "config = dict(max_bootstrapped_demos=8, max_labeled_demos=8, num_candidate_programs=10, num_threads=4)\n",
    "\n",
    "# Optimize! Use the `gms8k_metric` here. In general, the metric is going to tell the optimizer how well it's doing.\n",
    "teleprompter = BootstrapFewShotWithRandomSearch(metric=gsm8k_metric, **config)\n",
    "optimized_cot = teleprompter.compile(CoT(), trainset=trainset, valset=devset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6736e94f-c8d7-4c11-b551-d83fbcb50f2b",
   "metadata": {},
   "source": [
    ":::{.callout-warning}\n",
    "\n",
    "# This was not very minimal\n",
    "\n",
    "Despite this being the official [quick-start/minimal working](https://dspy-docs.vercel.app/docs/quick-start/minimal-example) example, this code took **more than 30 minutes to run, and made hundreds of calls to OpenAI!**  This cost non-trivial time (and money), especially as an entry-point to the library for someone trying to take a look.  There was no prior warning that this would happen.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193faa0c-c710-47ab-97f9-6b5999b3776b",
   "metadata": {},
   "source": [
    "DSPy made 100s of API calls because it was iteratively sampling examples for a few-shot prompt and selecting the best ones according to the `gsm8k_metric` on a validation set.  I was able to quickly understand this by scanning through the API requests logged to mitmproxy.\n",
    "\n",
    "DSPy offers an `inspect_history` method which allows you to see the the last `n` prompts and their completions:\n",
    "\n",
    "```python\n",
    "turbo.inspect_history(n=1)\n",
    "```\n",
    "\n",
    "I was able to verify that these prompts matched the last few API calls being made in mitmproxy.  Overall, I would be motivated to potentially keep the prompt and and jettison the library.  That being said, I think I am curious to see how this library evolves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51d7b7f-dd87-4291-83a7-a67c583a4d14",
   "metadata": {},
   "source": [
    "## My Personal Experience\n",
    "\n",
    "Do I hate LLM libraries?  No!  I think many of the libraries in this blog post could be helpful if used thoughtfully in the right situations.  However, I've witnessed too many people fall into the trap of using these libraries without understanding what they are doing.\n",
    "\n",
    "One thing I focus on as an independent consultant is to make sure my clients don't take on accidental complexity. It's very tempting to adopt additional tools given all the excitement around LLMs.  Looking at prompts is one way to mitigate that temptation. \n",
    "\n",
    "I'm wary of frameworks that distance the human too far from LLMs. By whispering _\"Fuck you, show me the prompt!\"_ when using these tools, you are empowered to decide for yourself.[^3]\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    ":::{.acknowledgments}\n",
    "_Acknowledgments: Thanks to [Jeremy Howard](https://twitter.com/jeremyphoward) and [Ben Clavie](https://twitter.com/bclavie) for thoughtfully reviewing this post._\n",
    ":::\n",
    "\n",
    "[^3]: You don't have to whisper.  Saying it out loud is fine too - let others know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5319ef3b-16e5-4875-8535-022371c1dab0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
