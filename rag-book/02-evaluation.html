<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>evaluation – Hamel's Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-8ef56b68f8fa1e9d2ba328e99e439f80.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-473cd3fdae26158324e3fa026112ebdf.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-5c21931d6ed7008fd1b1d77c416f53fd.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZSZXL3KFR5"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-ZSZXL3KFR5', { 'anonymize_ip': true});
</script>
<!-- Custom head content for all pages -->
<meta name="msvalidate.01" content="F9BFAF34FB8220973415C67CA60EB1A0">
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-PKGWQMKL');</script>
<!-- End Google Tag Manager -->


<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="Hamel’s Blog">
<meta property="og:description" content="A collection of blogs and talks on machine learning and data science.">
<meta property="og:image" content="https://hamel.dev/notes/llm/rag/p2-images/slide_1.png">
<meta property="og:site_name" content="Hamel's Blog">
<meta property="og:image:height" content="1125">
<meta property="og:image:width" content="1500">
<meta name="twitter:title" content="Hamel’s Blog">
<meta name="twitter:description" content="A collection of blogs and talks on machine learning and data science.">
<meta name="twitter:image" content="https://hamel.dev/notes/llm/rag/p2-images/slide_1.png">
<meta name="twitter:creator" content="@HamelHusain">
<meta name="twitter:site" content="@HamelHusain">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image-height" content="1125">
<meta name="twitter:image-width" content="1500">
</head>

<body class="nav-fixed quarto-dark"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = true;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
          <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" target="_blank"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../notes/index.html" target="_blank"> 
<span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://parlance-labs.com/" target="_blank"> 
<span class="menu-text">Hire Me</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../oss/opensource.html" target="_blank"> 
<span class="menu-text">OSS</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../talks.html" target="_blank"> 
<span class="menu-text">Teaching</span></a>
  </li>  
</ul>
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
            <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#modern-ir-evaluation-for-rag" id="toc-modern-ir-evaluation-for-rag" class="nav-link active" data-scroll-target="#modern-ir-evaluation-for-rag">Modern IR Evaluation for RAG</a>
  <ul class="collapse">
  <li><a href="#introduction-and-speaker-background" id="toc-introduction-and-speaker-background" class="nav-link" data-scroll-target="#introduction-and-speaker-background">Introduction and Speaker Background</a></li>
  <li><a href="#the-history-of-information-retrieval" id="toc-the-history-of-information-retrieval" class="nav-link" data-scroll-target="#the-history-of-information-retrieval">The History of Information Retrieval</a></li>
  <li><a href="#the-cranfield-paradigm" id="toc-the-cranfield-paradigm" class="nav-link" data-scroll-target="#the-cranfield-paradigm">The Cranfield Paradigm</a></li>
  <li><a href="#the-beir-benchmark" id="toc-the-beir-benchmark" class="nav-link" data-scroll-target="#the-beir-benchmark">The BEIR Benchmark</a></li>
  <li><a href="#problems-with-current-benchmarks" id="toc-problems-with-current-benchmarks" class="nav-link" data-scroll-target="#problems-with-current-benchmarks">Problems with Current Benchmarks</a></li>
  <li><a href="#the-rag-era-changes-everything" id="toc-the-rag-era-changes-everything" class="nav-link" data-scroll-target="#the-rag-era-changes-everything">The RAG Era Changes Everything</a></li>
  <li><a href="#different-users-different-goals" id="toc-different-users-different-goals" class="nav-link" data-scroll-target="#different-users-different-goals">Different Users, Different Goals</a></li>
  <li><a href="#the-evaluation-mismatch" id="toc-the-evaluation-mismatch" class="nav-link" data-scroll-target="#the-evaluation-mismatch">The Evaluation Mismatch</a></li>
  <li><a href="#introducing-freshstack" id="toc-introducing-freshstack" class="nav-link" data-scroll-target="#introducing-freshstack">Introducing FreshStack</a></li>
  <li><a href="#freshstack-data-sources" id="toc-freshstack-data-sources" class="nav-link" data-scroll-target="#freshstack-data-sources">FreshStack Data Sources</a></li>
  <li><a href="#the-freshstack-pipeline" id="toc-the-freshstack-pipeline" class="nav-link" data-scroll-target="#the-freshstack-pipeline">The FreshStack Pipeline</a></li>
  <li><a href="#freshstack-evaluation-metrics" id="toc-freshstack-evaluation-metrics" class="nav-link" data-scroll-target="#freshstack-evaluation-metrics">FreshStack Evaluation Metrics</a></li>
  <li><a href="#key-results-and-findings" id="toc-key-results-and-findings" class="nav-link" data-scroll-target="#key-results-and-findings">Key Results and Findings</a></li>
  <li><a href="#chapter-reflections" id="toc-chapter-reflections" class="nav-link" data-scroll-target="#chapter-reflections">Chapter Reflections</a></li>
  <li><a href="#video" id="toc-video" class="nav-link" data-scroll-target="#video">Video</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/hamelsmu/hamel-site/edit/master/rag-book/02-evaluation.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>

<!-- Content inserted at the beginning of body tag -->
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-PKGWQMKL" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->




<section id="modern-ir-evaluation-for-rag" class="level1">
<h1>Modern IR Evaluation for RAG</h1>
<p><em>Based on a presentation by Nandan Thakur</em></p>
<p><a href="https://thakur-nandan.github.io/" target="_blank">Nandan Thakur</a> is a researcher at the University of Waterloo and a key contributor to major Information Retrieval (IR) benchmarks, including BEIR and the new FreshStack. His talk explains why traditional IR evals designed for search engines may be insufficient for RAG systems. He argues that LLM-generated answers often carry different retrieval goals which necessitate different IR metrics.</p>
<section id="introduction-and-speaker-background" class="level2">
<h2 class="anchored" data-anchor-id="introduction-and-speaker-background">Introduction and Speaker Background</h2>
<p><img src="../notes/llm/rag/p2-images/slide_1.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=0s">Timestamp: 00:00:00</a>)</em></p>
<p>The title slide for Nandan’s talk, “Modern IR Evaluation in the RAG Era.”</p>
<p><img src="../notes/llm/rag/p2-images/slide_2.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=14s">Timestamp: 00:00:14</a>)</em></p>
<p>Nandan introduces himself as a fourth-year Ph.D.&nbsp;student at the University of Waterloo. He outlines his background, including research at UKP-TU and internships at Google Research and Databricks. He highlights his work on the BEIR, MIRACL, and FreshStack benchmarks, and the TREC RAG track.</p>
<p><img src="../notes/llm/rag/p2-images/slide_3.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=69s">Timestamp: 00:01:09</a>)</em></p>
<p>Nandan outlines the presentation’s three parts: a history of traditional IR evaluation, an explanation of why evaluation needs to change for RAG, and a deep dive into the FreshStack benchmark as a modern solution.</p>
</section>
<section id="the-history-of-information-retrieval" class="level2">
<h2 class="anchored" data-anchor-id="the-history-of-information-retrieval">The History of Information Retrieval</h2>
<p><img src="../notes/llm/rag/p2-images/slide_4.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=105s">Timestamp: 00:01:45</a>)</em></p>
<p>While RAG is new, Information Retrieval is a field with over 60 years of history. The slide contrasts an early Google interface with a modern one to show the evolution of web search.</p>
<p><img src="../notes/llm/rag/p2-images/slide_5.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=110s">Timestamp: 00:01:50</a>)</em></p>
<p>Nandan emphasizes IR’s history by showing a 1965 paper on the SMART Retrieval System, an early automated document retrieval system. He also introduces the Text Retrieval Conference (TREC), an influential conference since the 1990s that continues to produce IR benchmarks and standards.</p>
<p><img src="../notes/llm/rag/p2-images/slide_6.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=180s">Timestamp: 00:03:00</a>)</em></p>
<p>A diagram from NIST illustrates the breadth of TREC’s evaluation tasks from 1992 to 2020. These tracks range from classic ad-hoc retrieval to specialized areas like multilingual search and human-in-the-loop evaluation, demonstrating the field’s ongoing evolution.</p>
</section>
<section id="the-cranfield-paradigm" class="level2">
<h2 class="anchored" data-anchor-id="the-cranfield-paradigm">The Cranfield Paradigm</h2>
<p><img src="../notes/llm/rag/p2-images/slide_7.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=234s">Timestamp: 00:03:54</a>)</em></p>
<p>Nandan introduces the <strong>Cranfield Paradigm</strong>, the foundation of traditional IR evaluation developed in the 1960s. It established the concept of a <strong>test collection</strong>, comprising three components:</p>
<ol type="1">
<li><strong>Topics:</strong> A fixed set of user queries.</li>
<li><strong>Corpus:</strong> A fixed collection of documents.</li>
<li><strong>Relevance Judgments:</strong> Human-annotated labels indicating which documents are relevant to which queries.</li>
</ol>
<p>This three-part structure remains the basis for most IR benchmarks today.</p>
<p><img src="../notes/llm/rag/p2-images/slide_8.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=360s">Timestamp: 00:06:00</a>)</em></p>
<p>Nandan shows examples of modern test collections. He highlights <strong>BEIR</strong> for its diversity of tasks, <strong>MIRACL</strong> for multilingual retrieval, and the typical <strong>TREC</strong> query structure, which includes a <code>title</code>, <code>description</code>, and detailed <code>narrative</code>.</p>
</section>
<section id="the-beir-benchmark" class="level2">
<h2 class="anchored" data-anchor-id="the-beir-benchmark">The BEIR Benchmark</h2>
<p><img src="../notes/llm/rag/p2-images/slide_9.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=440s">Timestamp: 00:07:20</a>)</em></p>
<p>This slide introduces the BEIR (Benchmarking-IR) benchmark, which was among the first to popularize zero-shot evaluation for retrieval models.</p>
<p><img src="../notes/llm/rag/p2-images/slide_10.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=458s">Timestamp: 00:07:38</a>)</em></p>
<p>Nandan explains <strong>zero-shot evaluation</strong>, where a model is tested on a domain or task it has not seen during training. This contrasts with <em>in-domain</em> evaluation (training and testing on similar data). Zero-shot evaluation is more realistic because high-quality, labeled training data for niche use cases is scarce and expensive to create.</p>
</section>
<section id="problems-with-current-benchmarks" class="level2">
<h2 class="anchored" data-anchor-id="problems-with-current-benchmarks">Problems with Current Benchmarks</h2>
<p><img src="../notes/llm/rag/p2-images/slide_11.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=609s">Timestamp: 00:10:09</a>)</em></p>
<p>Nandan explains the motivation for BEIR. Around 2020-2021, the field focused heavily on the MSMARCO dataset, leading to <strong>saturation</strong> (performance plateaus) and <strong>overfitting</strong>. BEIR was created to combat this by providing a diverse set of datasets to test a model’s generalization ability beyond a single domain.</p>
<p><img src="../notes/llm/rag/p2-images/slide_12.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=670s">Timestamp: 00:11:10</a>)</em></p>
<p>Nandan explains that BEIR is no longer a truly “zero-shot” benchmark. Researchers now often include BEIR’s training sets in their model development pipelines. This, along with private models using unknown training data, repeats the overfitting problem that BEIR was designed to solve.</p>
<p><img src="../notes/llm/rag/p2-images/slide_13.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=800s">Timestamp: 00:13:20</a>)</em></p>
<p>Nandan highlights a practical issue: leaderboards are now too crowded to be useful. The MTEB leaderboard contains over 400 models, with the top contenders separated by marginal scores. This makes it difficult for practitioners to select a model and raises the question of how these models perform on other, more specialized tasks.</p>
<p><img src="../notes/llm/rag/p2-images/slide_14.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=883s">Timestamp: 00:14:43</a>)</em></p>
<p>This slide summarizes the limitations of existing test collections like BEIR. They are often static, leading to data contamination risk. They can suffer from incomplete “shallow labeling” from human annotators. They may also lack realistic question distributions, prompting even the creators of benchmarks like HotpotQA to advise against their use for modern agentic systems.</p>
</section>
<section id="the-rag-era-changes-everything" class="level2">
<h2 class="anchored" data-anchor-id="the-rag-era-changes-everything">The RAG Era Changes Everything</h2>
<p><img src="../notes/llm/rag/p2-images/slide_15.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=1048s">Timestamp: 00:17:28</a>)</em></p>
<p>Nandan contrasts the old and new search paradigms. “Search back then” shows a ranked list of links, while “Search now” shows a generated answer block with citations, characteristic of RAG systems.</p>
<p><img src="../notes/llm/rag/p2-images/slide_16.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=1100s">Timestamp: 00:18:20</a>)</em></p>
<p>This slide diagrams the architectural shift. Before RAG, a search model returned a ranked list of documents to the user. In the RAG era, the search model provides retrieved documents as context to an LLM, which then generates a response for the user.</p>
</section>
<section id="different-users-different-goals" class="level2">
<h2 class="anchored" data-anchor-id="different-users-different-goals">Different Users, Different Goals</h2>
<p><img src="../notes/llm/rag/p2-images/slide_17.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=1150s">Timestamp: 00:19:10</a>)</em></p>
<p>Nandan contrasts the two user types. A traditional search user is impatient, asks short queries, and scans a ranked list to click the first relevant link. A modern RAG user is patient, asks longer queries, and waits for a synthesized summary with citations, which they may use for verification.</p>
</section>
<section id="the-evaluation-mismatch" class="level2">
<h2 class="anchored" data-anchor-id="the-evaluation-mismatch">The Evaluation Mismatch</h2>
<p><img src="../notes/llm/rag/p2-images/slide_18.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=1268s">Timestamp: 00:21:08</a>)</em></p>
<p>This slide presents the talk’s central argument. Traditional metrics like <strong>MRR</strong> (Mean Reciprocal Rank) and <strong>NDCG</strong> (Normalized Discounted Cumulative Gain) were designed for the traditional objective: “Did we rank the relevant page at #1?” The new RAG objective is: “Did we fetch <em>every piece of evidence</em> needed for the LLM to answer this question?” For this new goal, MRR and NDCG may be insufficient on their own, as they do not measure comprehensive evidence collection or redundancy.</p>
<p><img src="../notes/llm/rag/p2-images/slide_19.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=1400s">Timestamp: 00:23:20</a>)</em></p>
<p>The argument is not to discard traditional relevance but to expand the evaluation criteria for RAG. While <strong>Relevancy is [still] important</strong>, it must now be balanced with new goals like finding a <strong>minimal spanning document set</strong>. This concept captures the need for a set of documents that is not only relevant but also comprehensively covers all aspects of an answer without being redundant.</p>
</section>
<section id="introducing-freshstack" class="level2">
<h2 class="anchored" data-anchor-id="introducing-freshstack">Introducing FreshStack</h2>
<p><img src="../notes/llm/rag/p2-images/slide_20.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=1490s">Timestamp: 00:24:50</a>)</em></p>
<p>Nandan introduces <strong>FreshStack</strong>, a modern IR benchmark developed with Databricks. It is designed to evaluate retrieval for RAG on technical documents.</p>
<p><img src="../notes/llm/rag/p2-images/slide_21.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=1500s">Timestamp: 00:25:00</a>)</em></p>
<p>The motivation for FreshStack was to create a realistic RAG benchmark that overcomes the limitations of existing academic benchmarks, which are often static and artificially easy. The framework was designed to use real user questions, ground answers in real-time documents, be scalable, and be new to avoid data contamination.</p>
</section>
<section id="freshstack-data-sources" class="level2">
<h2 class="anchored" data-anchor-id="freshstack-data-sources">FreshStack Data Sources</h2>
<p><img src="../notes/llm/rag/p2-images/slide_22.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=1576s">Timestamp: 00:26:16</a>)</em></p>
<p>FreshStack sources its queries from <strong>Stack Overflow</strong>, an ideal source for long, complex, real-world questions with community-vetted answers. To mitigate data contamination, the benchmark uses questions from five recent and niche topics asked primarily in 2023 and 2024.</p>
<p><img src="../notes/llm/rag/p2-images/slide_23.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=1650s">Timestamp: 00:27:30</a>)</em></p>
<p>The document corpus comes from the <strong>GitHub Repositories</strong> of the corresponding topics. This provides a constantly updated source of technical documentation and code. An interesting finding is that for technical queries, the questions can be significantly longer than the answers.</p>
</section>
<section id="the-freshstack-pipeline" class="level2">
<h2 class="anchored" data-anchor-id="the-freshstack-pipeline">The FreshStack Pipeline</h2>
<p><img src="../notes/llm/rag/p2-images/slide_24.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=1698s">Timestamp: 00:28:18</a>)</em></p>
<p>Nandan explains the three-step automated pipeline for building FreshStack:</p>
<ol type="1">
<li><strong>Nuggetization:</strong> A Stack Overflow answer is broken down by GPT-4o into essential, atomic facts or “nuggets.”</li>
<li><strong>Oracle Retrieval:</strong> A diverse pool of candidate documents is retrieved from the corpus using a hybrid of models.</li>
<li><strong>Support w/ Nuggets:</strong> A GPT-4o judge checks which retrieved document chunks support each individual nugget, creating fine-grained relevance judgments.</li>
</ol>
<p><img src="../notes/llm/rag/p2-images/slide_25.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=1790s">Timestamp: 00:29:50</a>)</em></p>
<p>This slide shows a concrete example of nuggetization. An answer to a <code>Chroma.from_documents</code> error is broken down into four key facts: the cause of the error, the required import, the initialization step, and the function call.</p>
<p><img src="../notes/llm/rag/p2-images/slide_26.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=1850s">Timestamp: 00:30:50</a>)</em></p>
<p>This slide illustrates the final steps. After a document is retrieved, the system checks which of the four nuggets it supports. This process creates nugget-level relevance labels, forming the basis for the new evaluation metrics.</p>
</section>
<section id="freshstack-evaluation-metrics" class="level2">
<h2 class="anchored" data-anchor-id="freshstack-evaluation-metrics">FreshStack Evaluation Metrics</h2>
<p><img src="../notes/llm/rag/p2-images/slide_27.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=1886s">Timestamp: 00:31:26</a>)</em></p>
<p>Nandan introduces the three metrics used in FreshStack, which provide a holistic view of RAG retrieval performance:</p>
<ol type="1">
<li><strong>Diversity (alpha-nDCG@10):</strong> Measures non-redundancy, penalizing the retrieval of multiple documents that support the same fact.</li>
<li><strong>Grounding (Coverage@20):</strong> Measures the percentage of unique nuggets supported by the retrieved documents, directly evaluating evidence collection.</li>
<li><strong>Relevance (Recall@50):</strong> A traditional metric that serves as a foundational check on whether the retrieved documents are on-topic.</li>
</ol>
<p>This multi-faceted approach augments traditional relevance with metrics tailored to the specific goals of RAG.</p>
</section>
<section id="key-results-and-findings" class="level2">
<h2 class="anchored" data-anchor-id="key-results-and-findings">Key Results and Findings</h2>
<p><img src="../notes/llm/rag/p2-images/slide_28.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=1999s">Timestamp: 00:33:19</a>)</em></p>
<p>Nandan presents results from the benchmark. Key findings include that current retrieval techniques struggle on these realistic tasks, and no single model performs best across all topics. The large gap between current model performance and the theoretical “Oracle” maximum indicates significant room for improvement.</p>
<p><img src="../notes/llm/rag/p2-images/slide_29.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=2095s">Timestamp: 00:34:55</a>)</em></p>
<p>Nandan shares the public FreshStack leaderboard and a Google Colab notebook. The notebook provides a script for users to evaluate their own models on FreshStack using its multi-dimensional metrics.</p>
<p><img src="../notes/llm/rag/p2-images/slide_30.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=2161s">Timestamp: 00:36:01</a>)</em></p>
<p>This slide summarizes the talk’s main points. Traditional IR evaluation may be insufficient for RAG depending on the use case. Benchmarks like BEIR are now suffering from overfitting. Often, the goal of RAG retrieval is evidence collection, requiring metrics that evaluate diversity, informativeness, and correctness in addition to relevance.</p>
<p><img src="../notes/llm/rag/p2-images/slide_31.png" class="img-fluid"></p>
<p><em>(<a href="https://www.youtube.com/watch?v=Trps2swgeOg&amp;t=2235s">Timestamp: 00:37:15</a>)</em></p>
<p>Nandan concludes by thanking his collaborators. The slide’s meme reinforces his message: good evaluations are essential for developing better models.</p>
</section>
<section id="chapter-reflections" class="level2">
<h2 class="anchored" data-anchor-id="chapter-reflections">Chapter Reflections</h2>
<p>Nandan’s message was to consider other retrieval metrics beyond relevance based on your product’s needs. He argued that we must sometimes reconsider what “good” retrieval means. For the stack overflow use case, he considered multiple dimensions of performance:</p>
<ul>
<li><strong>Grounding (or Coverage):</strong> Did the retrieval system fetch <em>all</em> the evidence needed to construct a complete and accurate answer? A missing fact can lead to an incomplete or incorrect generation, even if the retrieved documents are otherwise highly relevant.</li>
<li><strong>Diversity:</strong> Are the retrieved documents efficiently informative? Retrieving multiple documents that repeat the same information is less valuable than retrieving a set of documents that each contribute a unique and essential fact.</li>
<li><strong>Relevance:</strong> Is the retrieved information on-topic? This remains a fundamental check. A diverse and well-grounded set of documents is useless if it pertains to the wrong subject.</li>
</ul>
<p>This is not a call to discard traditional metrics but to <strong>augment</strong> them. The FreshStack benchmark, with its blend of Recall, Coverage, and Diversity metrics, is an example of this.</p>
</section>
<section id="video" class="level2">
<h2 class="anchored" data-anchor-id="video">Video</h2>
<p>Here is the full video:</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/Trps2swgeOg" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/hamel\.dev\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/hamelhusain/">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/HamelHusain">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/hamelsmu">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/hamelsmu/hamel-site/edit/master/rag-book/02-evaluation.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>