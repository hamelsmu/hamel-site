<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-09-10">
<meta name="description" content="Kelly Hong from Chroma explains ‚ÄòContext Rot,‚Äô a phenomenon where LLM performance degrades with longer inputs, and why thoughtful context engineering is critical for reliable AI applications.">

<title>P6: Context Rot ‚Äì Hamel‚Äôs Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-8ef56b68f8fa1e9d2ba328e99e439f80.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-473cd3fdae26158324e3fa026112ebdf.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-5c21931d6ed7008fd1b1d77c416f53fd.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZSZXL3KFR5"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-ZSZXL3KFR5', { 'anonymize_ip': true});
</script>
<!-- Custom head content for all pages -->
<meta name="msvalidate.01" content="F9BFAF34FB8220973415C67CA60EB1A0">
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-PKGWQMKL');</script>
<!-- End Google Tag Manager -->


<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="P6: Context Rot ‚Äì Hamel‚Äôs Blog">
<meta property="og:description" content="Kelly Hong from Chroma explains ‚ÄòContext Rot,‚Äô a phenomenon where LLM performance degrades with longer inputs, and why thoughtful context engineering is critical for reliable AI applications.">
<meta property="og:image" content="https://hamel.dev/rag-book/p6-images/crot_cover.png">
<meta property="og:site_name" content="Hamel's Blog">
<meta property="og:image:height" content="790">
<meta property="og:image:width" content="1189">
<meta name="twitter:title" content="P6: Context Rot ‚Äì Hamel‚Äôs Blog">
<meta name="twitter:description" content="Kelly Hong from Chroma explains ‚ÄòContext Rot,‚Äô a phenomenon where LLM performance degrades with longer inputs, and why thoughtful context engineering is critical for reliable AI applications.">
<meta name="twitter:image" content="https://hamel.dev/rag-book/p6-images/crot_cover.png">
<meta name="twitter:creator" content="@HamelHusain">
<meta name="twitter:site" content="@HamelHusain">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image-height" content="790">
<meta name="twitter:image-width" content="1189">
</head>

<body class="nav-fixed quarto-dark"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = true;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
          <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" target="_blank"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../notes/index.html" target="_blank"> 
<span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://parlance-labs.com/" target="_blank"> 
<span class="menu-text">Hire Me</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../oss/opensource.html" target="_blank"> 
<span class="menu-text">OSS</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../talks.html" target="_blank"> 
<span class="menu-text">Teaching</span></a>
  </li>  
</ul>
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
            <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#annotated-presentation" id="toc-annotated-presentation" class="nav-link active" data-scroll-target="#annotated-presentation">Annotated Presentation</a></li>
  <li><a href="#qa-session" id="toc-qa-session" class="nav-link" data-scroll-target="#qa-session">Q&amp;A Session</a></li>
  <li><a href="#video" id="toc-video" class="nav-link" data-scroll-target="#video">Video</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/hamelsmu/hamel-site/edit/master/rag-book/06-context-rot.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<!-- Content inserted at the beginning of body tag -->
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-PKGWQMKL" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">P6: Context Rot</h1>
</div>

<div>
  <div class="description">
    Kelly Hong from Chroma explains ‚ÄòContext Rot,‚Äô a phenomenon where LLM performance degrades with longer inputs, and why thoughtful context engineering is critical for reliable AI applications.
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">September 10, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>As part of our <a href="https://bit.ly/evals-ai">LLM Evals course</a>, I hosted Kelly Hong, a researcher at Chroma, to discuss <a href="https://research.trychroma.com/context-rot">her research</a> on ‚ÄúContext Rot.‚Äù Despite the narrative that RAG is dead because of large context windows (e.g.&nbsp;1 million tokens), Kelly‚Äôs research shows that performance is not uniform. As you add more information, models become increasingly unreliable, even on simple tasks. This phenomenon, which Kelly coined as ‚ÄúContext Rot,‚Äù is worth paying attention to if you are building AI applications. Kelly‚Äôs talk breaks down the experiments that uncovered this issue and highlights why thoughtful context engineering and retrieval is more important than ever.</p>
<p>Below is an annotated version of her presentation.</p>
<hr>
<div class="cta" style="text-align: center;">
<p><strong>üëâ <em>These are the kinds of things we cover in our <a href="https://bit.ly/evals-ai">AI Evals course</a>. You can learn more about <a href="https://bit.ly/evals-ai">the course here</a>.</em> üëà</strong></p>
</div>
<hr>
<section id="annotated-presentation" class="level2">
<h2 class="anchored" data-anchor-id="annotated-presentation">Annotated Presentation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="p6-images/slide_1.png" class="img-fluid figure-img"></p>
<figcaption>Title Slide</figcaption>
</figure>
</div>
<p><em>(<a href="https://youtu.be/3s_N60u0jEY?t=0s" target="_blank">Timestamp: 00:00:00</a>)</em></p>
<p>This slide introduces the concept of ‚ÄúContext Rot,‚Äù a term coined by Chroma to describe how an LLM‚Äôs performance becomes increasingly unreliable as the length of its input context grows. The research evaluates 18 state-of-the-art LLMs and finds that, contrary to the assumption of uniform context processing, performance degrades significantly with longer inputs.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="p6-images/slide_2.png" class="img-fluid figure-img"></p>
<figcaption>The Rise of Long Context Windows</figcaption>
</figure>
</div>
<p><em>(<a href="https://youtu.be/3s_N60u0jEY?t=107s" target="_blank">Timestamp: 01:47</a>)</em></p>
<p>Major LLM providers prominently advertise massive context windows‚Äîoften 1 million tokens or more‚Äîas a key feature of their frontier models like Gemini, Claude, and GPT-4.1. This marketing suggests that models can effectively process and utilize vast amounts of information.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="p6-images/slide_3.png" class="img-fluid figure-img"></p>
<figcaption>The Common Assumption: More Context is Better</figcaption>
</figure>
</div>
<p><em>(<a href="https://youtu.be/3s_N60u0jEY?t=127s" target="_blank">Timestamp: 02:07</a>)</em></p>
<p>The availability of large context windows has led to the common assumption that providing more context is always beneficial. This has inspired new use cases, such as large-scale code analysis and extensive document synthesis. Benchmarks like the ‚Äúneedle in a haystack‚Äù test, which often show near-perfect retrieval accuracy across the entire context window, appear to reinforce this assumption, creating a potentially misleading picture of model capabilities.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="p6-images/slide_4.png" class="img-fluid figure-img"></p>
<figcaption>Explaining the ‚ÄúNeedle in a Haystack‚Äù (NIAH) Benchmark</figcaption>
</figure>
</div>
<p><em>(<a href="https://youtu.be/3s_N60u0jEY?t=213s" target="_blank">Timestamp: 03:33</a>)</em></p>
<p>The Needle in a Haystack (NIAH) test is a simple retrieval task where a specific fact (the ‚Äúneedle‚Äù) is placed within a long document (the ‚Äúhaystack‚Äù), and the model is asked to retrieve it. Kelly explains that this benchmark primarily assesses direct <strong>lexical matching</strong>. As seen in the example, the query and the needle share many of the same words (‚Äúbest writing advice,‚Äù ‚Äúcollege classmate‚Äù). This makes the task relatively easy and not representative of real-world scenarios, which often require more complex <strong>semantic</strong> understanding where direct word overlap is minimal.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="p6-images/slide_5.png" class="img-fluid figure-img"></p>
<figcaption>Experiment 1: Adding Ambiguity (Semantic vs.&nbsp;Lexical Matching)</figcaption>
</figure>
</div>
<p><em>(<a href="https://youtu.be/3s_N60u0jEY?t=289s" target="_blank">Timestamp: 04:49</a>)</em></p>
<p>To test performance on more realistic tasks, Chroma‚Äôs first experiment introduced ambiguity. They compared a <strong>lexical matching</strong> task (similar to the original NIAH) with a <strong>semantic matching</strong> task, where the answer contained the same core information but was phrased differently, requiring the model to understand meaning beyond direct word overlap. The results show a clear trend: while performance on lexical matching remains relatively high, performance on the more complex semantic matching task degrades significantly as the input context grows longer.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="p6-images/slide_6.png" class="img-fluid figure-img"></p>
<figcaption>Implications of Ambiguity in Real-World Applications</figcaption>
</figure>
</div>
<p><em>(<a href="https://youtu.be/3s_N60u0jEY?t=488s" target="_blank">Timestamp: 08:08</a>)</em></p>
<p>This slide illustrates the real-world implications of the previous experiment using a financial report analysis example. A user is unlikely to know the exact phrasing in a document to formulate a perfect lexical query. Instead, they will ask a more ambiguous, semantic question like ‚ÄúHow is our overseas expansion going?‚Äù This requires the model to connect ‚Äúoverseas expansion‚Äù to specific countries and revenue figures. As Experiment 1 showed, this is precisely the kind of task where performance degrades with longer contexts.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="p6-images/slide_7.png" class="img-fluid figure-img"></p>
<figcaption>Experiment 2: Adding Distractors</figcaption>
</figure>
</div>
<p><em>(<a href="https://youtu.be/3s_N60u0jEY?t=579s" target="_blank">Timestamp: 09:39</a>)</em></p>
<p>The second experiment investigates how performance is affected by <strong>distractors</strong>‚Äîpieces of information that are semantically similar to the correct answer but are incorrect. In the example, the correct ‚Äúneedle‚Äù is writing advice from a ‚Äúcollege classmate.‚Äù The distractors include similar advice from a ‚Äúcollege professor‚Äù or advice about writing essays in different styles. These distractors mimic the kind of noise often found in real-world documents.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="p6-images/slide_8.png" class="img-fluid figure-img"></p>
<figcaption>Visualizing the Distractor Setup</figcaption>
</figure>
</div>
<p>This slide provides a simple visual model of the experiment. The researchers tested the LLM‚Äôs performance under three conditions: with no distractors, with one distractor, and with four distractors placed in the context alongside the correct needle.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="p6-images/slide_9.png" class="img-fluid figure-img"></p>
<figcaption>Results: Performance Degrades with More Distractors</figcaption>
</figure>
</div>
<p><em>(<a href="https://youtu.be/3s_N60u0jEY?t=660s" target="_blank">Timestamp: 11:00</a>)</em></p>
<p>The results of the distractor experiment show two clear trends. First, across all model groups, performance degrades as the input length increases. Second, performance also degrades as the number of distractors increases. The combination of long context and distracting information proves particularly challenging for LLMs, causing a significant drop in accuracy.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="p6-images/slide_10.png" class="img-fluid figure-img"></p>
<figcaption>Implications of Distractors in Domain-Specific Contexts</figcaption>
</figure>
</div>
<p><em>(<a href="https://youtu.be/3s_N60u0jEY?t=703s" target="_blank">Timestamp: 11:43</a>)</em></p>
<p>This experiment is highly relevant to real-world applications, especially in domain-specific contexts like finance or law. Documents in these fields often contain highly similar, templated information where only small details (like a year or a name) differ. These similar pieces of information act as natural distractors, making it difficult for the model to retrieve the correct fact, a problem that is exacerbated by longer contexts.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="p6-images/slide_11.png" class="img-fluid figure-img"></p>
<figcaption>Analyzing Failure Modes: Model Hallucinations vs.&nbsp;Abstention</figcaption>
</figure>
</div>
<p><em>(<a href="https://youtu.be/3s_N60u0jEY?t=775s" target="_blank">Timestamp: 12:55</a>)</em></p>
<p>When the models failed in the 4-distractor condition, the researchers analyzed <em>how</em> they failed. A key finding was that models often <strong>hallucinate</strong> by confidently providing an answer based on one of the distractors, rather than <strong>abstaining</strong> (stating ‚ÄúI don‚Äôt know‚Äù). This tendency varies by model family: Claude models are more likely to abstain when uncertain, whereas GPT models have the highest rate of hallucination, confidently returning an incorrect answer.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="p6-images/slide_12.png" class="img-fluid figure-img"></p>
<figcaption>Experiment 3: Shuffling Haystack Content</figcaption>
</figure>
</div>
<p><em>(<a href="https://youtu.be/3s_N60u0jEY?t=852s" target="_blank">Timestamp: 14:12</a>)</em></p>
<p>This experiment tested whether models process context in a structured, order-sensitive manner. A ‚Äúneedle‚Äù (a sentence about writing advice) was placed in a coherent essay. Because the needle disrupts the essay‚Äôs logical flow, it stands out. The same needle was also placed in a ‚Äúhaystack‚Äù of randomly shuffled, unrelated sentences, where it should logically blend in more. The hypothesis was that the model would find it easier to retrieve the needle from the coherent essay where it was an anomaly.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="p6-images/slide_13.png" class="img-fluid figure-img"></p>
<figcaption>Surprising Results: Models Perform Better on Shuffled Context</figcaption>
</figure>
</div>
<p><em>(<a href="https://youtu.be/3s_N60u0jEY?t=934s" target="_blank">Timestamp: 15:34</a>)</em></p>
<p>Counter-intuitively, the results showed that models performed slightly <em>better</em> when the haystack was randomly shuffled. This surprising finding suggests that LLMs do not necessarily process context in the linear, structured way humans do and that a disruption in logical flow can actually make a key piece of information harder, not easier, to find.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="p6-images/slide_14.png" class="img-fluid figure-img"></p>
<figcaption>Experiment 4: Conversational Memory</figcaption>
</figure>
</div>
<p><em>(<a href="https://youtu.be/3s_N60u0jEY?t=1074s" target="_blank">Timestamp: 17:54</a>)</em></p>
<p>This experiment tested conversational memory using the LongMemEval benchmark. Models were tested under two conditions: a ‚Äúfocused‚Äù condition with only the relevant conversational history (around 100 tokens), and a ‚Äúfull‚Äù condition where the context was padded with irrelevant conversations up to 120k tokens. The results clearly show that all Claude models perform significantly better in the focused condition, demonstrating that irrelevant information degrades performance quickly.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="p6-images/slide_15.png" class="img-fluid figure-img"></p>
<figcaption>Experiment 5: Text Replication Task</figcaption>
</figure>
</div>
<p><em>(<a href="https://youtu.be/3s_N60u0jEY?t=1160s" target="_blank">Timestamp: 19:20</a>)</em></p>
<p>This experiment involved a very simple task: replicating a given text of repeated words. Despite the simplicity, all models showed a significant drop in performance as the input length increased. Some models exhibited strange failure modes; for example, at long input lengths, Claude models would refuse to generate the output, citing concerns about copyrighted material, while Gemini models would produce completely random outputs.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="p6-images/slide_16.png" class="img-fluid figure-img"></p>
<figcaption>Key Takeaways</figcaption>
</figure>
</div>
<p><em>(<a href="https://youtu.be/3s_N60u0jEY?t=1215s" target="_blank">Timestamp: 20:15</a>)</em></p>
<p>The research provides three takeaways:</p>
<ol type="1">
<li>LLM performance is not uniform across input lengths, even for simple tasks.</li>
<li>Simply having the right information in the context is not enough; <em>how</em> that information is presented matters significantly.</li>
<li>As a result, thoughtful <strong>context engineering</strong> is critical for building reliable AI applications.</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="p6-images/slide_17.png" class="img-fluid figure-img"></p>
<figcaption>Context Engineering Example: Orchestrator and Subagents</figcaption>
</figure>
</div>
<p><em>(<a href="https://youtu.be/3s_N60u0jEY?t=1267s" target="_blank">Timestamp: 21:07</a>)</em></p>
<p>Kelly provides a practical example of context engineering for a coding agent with a long-running task.</p>
<ul>
<li><strong>Naive Approach:</strong> Append the entire conversation history, including every tool call and output, to the context. This causes the context to grow quickly and become bloated with irrelevant information (e.g., the full content of a file read), leading to context rot.</li>
<li><strong>Better Approach:</strong> Use a main ‚Äúorchestrator‚Äù agent that breaks the task into subtasks and spawns ‚Äúsubagents‚Äù for each one. Each subagent operates with its own clean, focused context. It completes its subtask and returns only the most relevant information to the orchestrator, which maintains a concise, filtered history. This prevents context overload and improves reliability.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="p6-images/slide_18.png" class="img-fluid figure-img"></p>
<figcaption>Further Reading</figcaption>
</figure>
</div>
<p><em>(<a href="https://youtu.be/3s_N60u0jEY?t=1367s" target="_blank">Timestamp: 22:47</a>)</em></p>
<p>The presentation concludes by directing the audience to the full technical report and other related research on Chroma‚Äôs website, <a href="https://research.trychroma.com/">research.trychroma.com</a>.</p>
<hr>
</section>
<section id="qa-session" class="level2">
<h2 class="anchored" data-anchor-id="qa-session">Q&amp;A Session</h2>
<ul>
<li><p><strong>Is the Needle in a Haystack (NIAH) benchmark pointless?</strong> <em>(<a href="https://youtu.be/3s_N60u0jEY?t=414s" target="_blank">Timestamp: 06:54</a>)</em> It‚Äôs not pointless, but its utility has diminished. It was useful for evaluating older models, which did show performance degradation on the task. However, modern frontier models can now perform very well on this simple, lexically-driven task, which makes the benchmark unrepresentative of real-world use cases that require deeper semantic reasoning.</p></li>
<li><p><strong>Did the research find that one model consistently resists context rot better than others across all tasks?</strong> <em>(<a href="https://youtu.be/3s_N60u0jEY?t=1437s" target="_blank">Timestamp: 23:57</a>)</em> No, performance was ‚Äúall over the place‚Äù and highly task-dependent. There was no single model that ranked first across all experiments. For example, Claude Sonnet 4 performed best on the repeated words task, while GPT-4.1 was the top performer on the Needle in a Haystack task. Each model has different strengths, and no model currently excels at all long-context tasks.</p></li>
<li><p><strong>What is your advice for developers trying to find and mitigate context rot in their applications?</strong> <em>(<a href="https://youtu.be/3s_N60u0jEY?t=1652s" target="_blank">Timestamp: 27:32</a>)</em> Start by qualitatively analyzing your system. Run a few examples with both short, focused context and long context bloated with irrelevant information. Compare the outputs: what did the model miss with the long context? What irrelevant information could be removed? There‚Äôs no single, generalizable solution, as optimal context engineering is highly application-dependent. A good starting point is to carefully examine the data you‚Äôre providing to the model and how you can make it more concise and relevant.</p></li>
<li><p><strong>Prior research found a U-shaped retrieval curve, where information at the very beginning and very end of the context is recalled best. Does that still hold true?</strong> <em>(<a href="https://youtu.be/3s_N60u0jEY?t=1746s" target="_blank">Timestamp: 29:06</a>)</em> In Chroma‚Äôs experiments, they did not observe this U-shaped pattern. They tested placing the ‚Äúneedle‚Äù at various positions throughout the context‚Äîfrom the beginning to the middle to the end‚Äîand found no consistent performance advantage for any particular position. While putting important information at the start or end is a common piece of advice, this research suggests it may not be a reliable solution for mitigating context rot.</p></li>
</ul>
<hr>
<div class="cta" style="text-align: center;">
<p><strong>üëâ <em>These are the kinds of things we cover in our <a href="https://bit.ly/evals-ai">AI Evals course</a>. You can learn more about <a href="https://bit.ly/evals-ai">the course here</a>.</em> üëà </strong></p>
</div>
<hr>
</section>
<section id="video" class="level2">
<h2 class="anchored" data-anchor-id="video">Video</h2>
<p>Here is the full video:</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/3s_N60u0jEY" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/hamel\.dev\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/hamelhusain/">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/HamelHusain">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/hamelsmu">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/hamelsmu/hamel-site/edit/master/rag-book/06-context-rot.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>